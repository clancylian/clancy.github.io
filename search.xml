<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[NVIDIA NPP LIBRARY SDK]]></title>
    <url>%2F2019%2F04%2F29%2FNVIDIA-NPP-LIBRARY-SDK%2F</url>
    <content type="text"><![CDATA[CUDA NPP库使用NPP库是英伟达提供的可用在实现GPU加速图像处理，详细SDK文档可以参考链接，主要包含的库如下： 12345678910111213141516171819202122//图像处理基础库，类似opencv corenppc NPP core library which MUST be included when linking any application, functions are listed in nppCore.h//算术逻辑操作nppial arithmetic and logical operation functions in nppi_arithmetic_and_logical_operations.h//颜色转换操作nppicc color conversion and sampling functions in nppi_color_conversion.h//图像压缩和解压nppicom JPEG compression and decompression functions in nppi_compression_functions.h//数据转换及初始化nppidei data exchange and initialization functions in nppi_data_exchange_and_initialization.h//滤波操作nppif filtering and computer vision functions in nppi_filter_functions.h//几何变换nppig geometry transformation functions found in nppi_geometry_transforms.h//形态学操作nppim morphological operation functions found in nppi_morphological_operations.h//统计及线性变换nppist statistics and linear transform in nppi_statistics_functions.h and nppi_linear_transforms.h//内存支持函数nppisu memory support functions in nppi_support_functions.h//阈值及比较操作nppitc threshold and compare operation functions in nppi_threshold_and_compare_operations.h 由于项目需求，这里主要介绍一些常用的操作，主要是opencv中基本图像处理操作，比如颜色空间转换，图像伸缩变换等等。 RESIZEresize操作支持单通道、３通道、４通道。8u、16u、16s、32f，接口一般是nppiResizeSqrPixel_ _ ，其中可以选择对感兴趣区域进行resize。这里需要注意的是resize的一些插值方式，和opencv不太一样，并且官方文档没有详细说明，导致有一些坑在里面。比如之前使用NPPI_INTER_SUPER插值方式的时候发现factor大于１的时候会出错。后面找到答案说NPPI_INTER_SUPER只支持降采样操作，参考链接。这里举个BGR进行通道转换的栗子： 12345678910111213141516171819202122232425262728293031323334353637383940bool imageResize_8u_C3R(void *src, int srcWidth, int srcHeight, void *dst, int dstWidth, int dstHeight)&#123; NppiSize oSrcSize; oSrcSize.width = srcWidth; oSrcSize.height = srcHeight; int nSrcStep = srcWidth * 3; NppiRect oSrcROI; oSrcROI.x = 0; oSrcROI.y = 0; oSrcROI.width = srcWidth; oSrcROI.height = srcHeight; int nDstStep = dstWidth * 3; NppiRect oDstROI; oDstROI.x = 0; oDstROI.y = 0; oDstROI.width = dstWidth; oDstROI.height = dstHeight; // Scale Factor double nXFactor = double(dstWidth) / (oSrcROI.width); double nYFactor = double(dstHeight) / (oSrcROI.height); // Scaled X/Y Shift double nXShift = - oSrcROI.x * nXFactor ; double nYShift = - oSrcROI.y * nYFactor; int eInterpolation = NPPI_INTER_SUPER; if (nXFactor &gt;= 1.f || nYFactor &gt;= 1.f) eInterpolation = NPPI_INTER_LANCZOS; NppStatus ret = nppiResizeSqrPixel_8u_C3R((const Npp8u *)src, oSrcSize, nSrcStep, oSrcROI, (Npp8u *)dst, nDstStep, oDstROI, nXFactor, nYFactor, nXShift, nYShift, eInterpolation ); if(ret != NPP_SUCCESS) &#123; printf("imageResize_8u_C3R failed %d.\n", ret); return false; &#125; return true;&#125; resize库包含在nppig库里面，其中还有各种操作，包括mirror、remap、rotate、warp等等，这些在平常使用过程中比较少用到，需要用的时候再参考文档。 ## 颜色转换 自己实现一些操作padding123456789101112131415161718192021222324252627__global__ void imagePaddingKernel(float3 *ptr, float3 *dst, int width, int height, int top, int bottom, int left, int right)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if(x &lt; left || x &gt;= (width - right) || y &lt; top || y &gt; (height - bottom)) &#123; return; &#125; float3 color = ptr[(y - top) * (width - top - right) + (x - left)]; dst[y * width + x] = color;&#125;void imagePadding(const void *src, void *dst, int width, int height, int top, int bottom, int left, int right)&#123; int dstW = width + left + right; int dstH = height + top + bottom; cudaMemset(dst, 0, dstW * dstH * sizeof(float3)); dim3 grids((dstW + 31) / 32, (dstH + 31) / 32); dim3 blocks(32, 32); imagePaddingKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (float3 *)dst, dstW, dstH, top, bottom, left, right);&#125; split123456789101112131415161718192021__global__ void imageSplitKernel(float3 *ptr, float *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; float3 color = ptr[y * width + x]; dst[y * width + x] = color.x; dst[y * width + x + width * height] = color.y; dst[y * width + x + width * height * 2] = color.z;&#125;void imageSplit(const void *src, float *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); imageSplitKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (float *)dst, width, height);&#125; normalization12345678910111213141516171819202122__global__ void imageNormalizationKernel(float3 *ptr, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; float3 color = ptr[y * width + x]; color.x = (color.x - 127.5) * 0.0078125; color.y = (color.y - 127.5) * 0.0078125; color.z = (color.z - 127.5) * 0.0078125; ptr[y * width + x] = make_float3(color.x, color.y, color.z);&#125;void imageNormalization(void *ptr, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); imageNormalizationKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)ptr, width, height);&#125; BGR2RGBfloat123456789101112131415161718__global__ void convertBGR2RGBfloatKernel(uchar3 *src, float3 *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar3 color = src[y * width + x]; dst[y * width + x] = make_float3(color.z, color.y, color.x);&#125;void convertBGR2RGBfloat(void *src, void *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); convertBGR2RGBfloatKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((uchar3 *)src, (float3 *)dst, width, height);&#125; ## 参考链接 官网地址]]></content>
      <categories>
        <category>NVIDIA</category>
      </categories>
      <tags>
        <tag>NPP</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch学习之路]]></title>
    <url>%2F2019%2F04%2F13%2FPyTorch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[参考文档 1. 基础概念PyTorch类似于Numpy。它的优点在于可以充分利用GPU资源。它是一个深度学习框架，提供最大的灵活性和速度。 1.1 张量概念12345678910111213141516171819202122232425262728from __future__ import print_functionimport torch# 构造未初始化5x3的矩阵x = torch.empty(5, 3)print(x)# 构造随机初始化矩阵x = torch.rand(5, 3)print(x)# 构造0矩阵，数据类型为longx = torch.zeros(5, 3, dtype=torch.long)print(x)# 直接用数据构造一个张量x = torch.tensor([5.5, 3])print(x)# 基于存在的张量构造，可以使用存在的张量的一些属性，比如数据类型，数据纬度，除非手动修改x = x.new_ones(5, 3, dtype=torch.double) # new_* methods take in sizesprint(x)x = torch.randn_like(x, dtype=torch.float) # override dtype!print(x) # result has the same size# 获取张量大小.实际上torch.Size是一个元组类型，支持元组所有操作print(x.size()) 1.2 张量操作关于张量的操作有100多种，包括转置、索引、切片、数值计算、线性代数、随机数等等。 123456789101112131415161718192021222324252627282930# 加法1y = torch.rand(5, 3)print(x + y)# 加法2print(torch.add(x, y))# 输出张量作为参数result = torch.empty(5, 3)torch.add(x, y, out=result)print(result)# 原地（in-place）加法# adds x to yy.add_(x)print(y)# 以 _ 作为后缀将会改变操作数，比如x.copy_(y), x.t_(),都会改变x的值# 可以像Numpy一样索引print(x[:, 1])# resize和reshape操作可以使用torch.viewx = torch.randn(4, 4)y = x.view(16)z = x.view(-1, 8) # the size -1 is inferred from other dimensionsprint(x.size(), y.size(), z.size())# 如果你有一个只有一个元素的张量，可以使用.item()获取数值x = torch.randn(1)print(x)print(x.item()) 1.3 与Numpy互操作1234567891011121314# tensor转为Numpya = torch.ones(5)print(a)b = a.numpy()print(b)# Numpy转为tensorimport numpy as npa = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a)print(a)print(b) 1.4 CUDA 张量可以使用 .to 方法把张量拷贝到设备内存(GPU) 123456789# let us run this cell only if CUDA is available# We will use ``torch.device`` objects to move tensors in and out of GPUif torch.cuda.is_available():device = torch.device("cuda") # a CUDA device objecty = torch.ones_like(x, device=device) # directly create a tensor on GPUx = x.to(device) # or just use strings ``.to("cuda")``z = x + yprint(z)print(z.to("cpu", torch.double)) # ``.to`` can also change dtype together! 1.5 自动微分技术PyTorch中的反向传播中求导都是使用autograd包完成的。它提供了张量求导所有操作，它是一个define-by-run框架，意味着每一次反向传播都取决于你的代码是如何跑的，每一次迭代都可能不同。 torch.Tensor 是pytorch一个最基础的类。如果你设置其属性 .requires_grad 为 True, 它将会跟踪它所有的操作，当你调用.backward()时，会自动计算梯度，可以使用 .grad 获取梯度值。可以使用.detach()来停止跟踪历史或者阻止将来的操作。也可以使用with torch.no_grad():。 除了torch.Tensor 还有一个很重要的类来实现自动求导——Fucction。每一个张量（除了用户创建的之外）都有.grad_fn属性。 当想要计算导数的时候只要调用.backward()。当输出张量是一个标量的时候，不需要特别指明参数，然而如果是一个向量就需要指明gradient参数。 12345678910111213141516# 设置requires_grad为truex = torch.ones(2, 2, requires_grad=True)print(x)y = x + 2print(y)# 因为y是由操作得来的结果，所以有grad_fn属性print(y.grad_fn)z = y * y * 3out = z.mean()print(z, out)# 因为out输出为标量，相当于out.backward(torch.tensor(1.))out.backward()print(x.grad) 1.6 神经网络1.6.1 定义网络结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):def __init__(self):super(Net, self).__init__()# 1 input image channel, 6 output channels, 5x5 square convolution# kernelself.conv1 = nn.Conv2d(1, 6, 5)self.conv2 = nn.Conv2d(6, 16, 5)# an affine operation: y = Wx + bself.fc1 = nn.Linear(16 * 5 * 5, 120)self.fc2 = nn.Linear(120, 84)self.fc3 = nn.Linear(84, 10)def forward(self, x):# Max pooling over a (2, 2) windowx = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))# If the size is a square you can only specify a single numberx = F.max_pool2d(F.relu(self.conv2(x)), 2)x = x.view(-1, self.num_flat_features(x))x = F.relu(self.fc1(x))x = F.relu(self.fc2(x))x = self.fc3(x)return xdef num_flat_features(self, x):size = x.size()[1:] # all dimensions except the batch dimensionnum_features = 1for s in size:num_features *= sreturn num_featuresnet = Net()# 输出网络结构print(net)# 模型参数存在net.parameters()中params = list(net.parameters())print(len(params))print(params[0].size()) # conv1's .weight# 测试输入input = torch.randn(1, 1, 32, 32)out = net(input)print(out)# 模型梯度置0然后反向传播net.zero_grad()out.backward(torch.randn(1, 10)) 注：torch.nn只支持最小批量 1.6.2 损失函数1234567output = net(input)target = torch.randn(10) # a dummy target, for exampletarget = target.view(1, -1) # make it the same shape as outputcriterion = nn.MSELoss()loss = criterion(output, target)print(loss) 由此可以得出计算图： 1234input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d-&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear-&gt; MSELoss-&gt; loss 1.6.3 反向传播123456789net.zero_grad() # zeroes the gradient buffers of all parametersprint('conv1.bias.grad before backward')print(net.conv1.bias.grad)loss.backward()print('conv1.bias.grad after backward')print(net.conv1.bias.grad) 1.6.4 更新权重1234567891011import torch.optim as optim# create your optimizeroptimizer = optim.SGD(net.parameters(), lr=0.01)# in your training loop:optimizer.zero_grad() # zero the gradient buffersoutput = net(input)loss = criterion(output, target)loss.backward()optimizer.step() # Does the update 注：每次optimizer.zero_grad()需要手动置0，因为梯度是累积的。 1.7 训练一个分类器1.7.1 加载数据1234567891011121314151617181920import torchimport torchvisionimport torchvision.transforms as transformstransform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=2)classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck') 1.7.2 定义卷积神经网络12345678910111213141516171819202122232425import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):def __init__(self):super(Net, self).__init__()self.conv1 = nn.Conv2d(3, 6, 5)self.pool = nn.MaxPool2d(2, 2)self.conv2 = nn.Conv2d(6, 16, 5)self.fc1 = nn.Linear(16 * 5 * 5, 120)self.fc2 = nn.Linear(120, 84)self.fc3 = nn.Linear(84, 10)def forward(self, x):x = self.pool(F.relu(self.conv1(x)))x = self.pool(F.relu(self.conv2(x)))x = x.view(-1, 16 * 5 * 5)x = F.relu(self.fc1(x))x = F.relu(self.fc2(x))x = self.fc3(x)return xnet = Net() 1.7.3 定义损失函数和优化器1234import torch.optim as optimcriterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 1.7.4 训练网络123456789101112131415161718192021222324for epoch in range(2): # loop over the dataset multiple timesrunning_loss = 0.0for i, data in enumerate(trainloader, 0):# get the inputsinputs, labels = data# zero the parameter gradientsoptimizer.zero_grad()# forward + backward + optimizeoutputs = net(inputs)loss = criterion(outputs, labels)loss.backward()optimizer.step()# print statisticsrunning_loss += loss.item()if i % 2000 == 1999: # print every 2000 mini-batchesprint('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))running_loss = 0.0print('Finished Training') 1.7.5 测试1234567891011121314151617class_correct = list(0. for i in range(10))class_total = list(0. for i in range(10))with torch.no_grad():for data in testloader:images, labels = dataoutputs = net(images)_, predicted = torch.max(outputs, 1)c = (predicted == labels).squeeze()for i in range(4):label = labels[i]class_correct[label] += c[i].item()class_total[label] += 1for i in range(10):print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i])) 12345678910Accuracy of plane : 72 %Accuracy of car : 47 %Accuracy of bird : 41 %Accuracy of cat : 32 %Accuracy of deer : 42 %Accuracy of dog : 49 %Accuracy of frog : 70 %Accuracy of horse : 62 %Accuracy of ship : 46 %Accuracy of truck : 76 % 1.7.6 GPU训练12345678device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# Assuming that we are on a CUDA machine, this should print a CUDA device:print(device)net.to(device)inputs, labels = inputs.to(device), labels.to(device) 1.8 数据并行1234567891011# cuda设备device = torch.device("cuda:0")# 将模型移到GPUmodel.to(device)# 输入拷贝到GPUmytensor = my_tensor.to(device)# 设置数据并行model = nn.DataParallel(model) 2. 数据3. 模型4. 策略（损失函数）5. 算法]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>深度学习框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量配置]]></title>
    <url>%2F2019%2F04%2F02%2FLinux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[设置文件为:123456//全局设置文件/etc/profile//针对某个用户设置~/.bashrc` 设置PATH:1export PATH=/your/bin/path:$PATH 注意： PATH=中间不能有空格。 设置LD_LIBRARY_PATH:1export LD_LIBRARY_PATH=/your/lib/path:$LD_LIBRARY_PATH 另：也可以在/etc/ld.so.conf.d/ 下设置目录，然后调用ldconfig生效。 生效：123source ~/.bashrcorsource /etc/profile]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件之自定义数据结构]]></title>
    <url>%2F2019%2F04%2F01%2FGStreamer%E6%8F%92%E4%BB%B6%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[GstMeta当我们需要添加自定义的数据结构到GstBuffer中时，需要使用GstMeta自定义数据结构。GstMeta数据结构为：1234struct _GstMeta &#123; GstMetaFlags flags; const GstMetaInfo *info; /* tag and info for the meta item */&#125;; 其中 info 结构体为：123456789struct _GstMetaInfo &#123; GType api; //api 类型 GType type; //具体实现类型 gsize size; //自定义数据结构体大小 GstMetaInitFunction init_func; //初始化函数 GstMetaFreeFunction free_func; //释放函数 GstMetaTransformFunction transform_func; //转换函数&#125;; 其中api成员需要由gst_meta_api_type_register()函数注册生成，具体看下文实施例。 GstMeta是我们自定义数据结构体的公共头，比如gstreamer自带时间信息结构体：12345678struct _GstMetaTiming &#123; GstMeta meta; /* common meta header */ GstClockTime dts; /* decoding timestamp */ GstClockTime pts; /* presentation timestamp */ GstClockTime duration; /* duration of the data */ GstClockTime clock_rate; /* clock rate for the above values */&#125;; 自定义的数据结构体由字段或者方法组成。一个典型的buffer可能是如以下结构：1234567891011121314151617181920212223242526272829 +----------------------------------+GstMiniObject | GType (GstBuffer) | | refcount, flags, copy/disp/free | +----------------------------------+GstBuffer | pool,pts,dts,duration,offsets | | &lt;private data&gt; | +..................................+ | next ---+ +- | info ------&gt; GstMetaInfoGstMetaTiming | | | | | | dts | | | | pts | | | | duration | | +- | clock_rate | | + . . . . . . . . . . . . . . . . + | | next &lt;--+GstVideoMeta +- +- | info ------&gt; GstMetaInfo | | | | | | | | flags | | | | | n_planes | | | | | planes[] | | | | | map | | | | | unmap | | +- | | | | | | private fields | |GstVideoMetaImpl | | ... | | | | ... | | +- | | | + . . . . . . . . . . . . . . . . + . 自定义meta实现头文件123456789101112131415161718192021222324252627282930313233343536373839404142#ifndef GSTFACEPARAMMETA_H#define GSTFACEPARAMMETA_H#include "gst/gst.h"/** Defines GStreamer metadata types. *///定义枚举类型，用来指定meta_data指针所指向的数据类型typedef enum&#123; META_INIT = 0x0, FACE_PARAM,&#125; Meta_type;typedef struct _FaceParamMeta FaceParamMeta;//该结构体为要附加的元数据结构体struct _FaceParamMeta &#123; //公共头 GstMeta meta; //存储各种需要的自定义结构体，方便扩展 void *meta_data; //meta_data指针指向的结构体类型 int meta_type; //类似回调函数指针，在buffer销毁的时候会调用 GDestroyNotify destroy;&#125;;//注册api type的接口，返回api用于注册metaGType face_param_meta_api_get_type(void);#define FACE_PARAM_META_API_TYPE (face_param_meta_api_get_type())//注册meta的时候返回GstMetaInfoconst GstMetaInfo *face_param_meta_get_info(void);#define FACE_PARAM_META_INFO (face_param_meta_get_info())//往buffer中添加数据，返回FaceParamMeta*指针指向添加位置FaceParamMeta *gst_buffer_add_face_param_meta(GstBuffer *buffer, void *metadata, int metatype, GDestroyNotify destroy);//从buffer中获取自定义meta数据FaceParamMeta *gst_buffer_get_face_param_meta(GstBuffer *buffer);#endif // GSTFACEPARAMMETA_H 实现文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include "gstfaceparammeta.h"GType face_param_meta_api_get_type(void)&#123; static volatile GType type; //可以往api type加入标签，使用gst_meta_api_type_has_tag查找是否由我们自定义结构体 static const gchar *tags[] = &#123;"face", "detect", NULL&#125;; if(g_once_init_enter(&amp;type)) &#123; //注册api type GType _type = gst_meta_api_type_register("FaceParamMetaAPI", tags); g_once_init_leave(&amp;type, _type); &#125; return type;&#125;//初始化函数实现static gboolean face_param_meta_init(GstMeta *meta, gpointer params, GstBuffer *buffer)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; emeta-&gt;meta_type = META_INIT; emeta-&gt;meta_data = NULL; emeta-&gt;destroy = NULL; return TRUE;&#125;//转换函数实现，具体复杂情况下怎么用还需琢磨static gboolean face_param_meta_transform(GstBuffer *transbuf, GstMeta *meta, GstBuffer *buffer, GQuark type, gpointer data)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; gst_buffer_add_face_param_meta(transbuf, emeta-&gt;meta_data, emeta-&gt;meta_type, emeta-&gt;destroy); return TRUE;&#125;//释放函数static void face_param_meta_free(GstMeta *meta, GstBuffer *buffer)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; emeta-&gt;meta_type = META_INIT; //回调函数 emeta-&gt;destroy(emeta-&gt;meta_data);&#125;//注册我们的meta函数const GstMetaInfo *face_param_meta_get_info(void)&#123; static const GstMetaInfo *meta_info = NULL; if(g_once_init_enter(&amp;meta_info)) &#123; //注册返回GstMetaInfo //第二个参数可以在gst_meta_get_info（）函数使用 const GstMetaInfo *mi = gst_meta_register(FACE_PARAM_META_API_TYPE, "FaceParamMeta", sizeof(FaceParamMeta), face_param_meta_init, face_param_meta_free, face_param_meta_transform); g_once_init_leave(&amp;meta_info, mi); &#125; return meta_info;&#125;//增加数据FaceParamMeta *gst_buffer_add_face_param_meta(GstBuffer *buffer, void *metadata, int metatype, GDestroyNotify destroy)&#123; FaceParamMeta *meta; g_return_val_if_fail(GST_IS_BUFFER(buffer), NULL); meta = (FaceParamMeta *)gst_buffer_add_meta(buffer, FACE_PARAM_META_INFO, NULL); //指针简单赋值，需要注意外面传进来的指针必须不是局部变量，否则会自动释放 meta-&gt;meta_data = metadata; //meta_data指向类型 meta-&gt;meta_type = metatype; //回调函数，在free的时候使用 meta-&gt;destroy = destroy; return meta;&#125;//获取数据FaceParamMeta *gst_buffer_get_face_param_meta(GstBuffer *buffer)&#123; FaceParamMeta *meta; meta = (FaceParamMeta *)gst_buffer_get_meta(buffer, FACE_PARAM_META_API_TYPE); return meta;&#125; 具体使用调用添加数据函数1faceParamMeta = gst_buffer_add_face_param_meta(outbuf, metadata, FACE_PARAM, free_face_param_meta); 释放函数为：12345678910/** * Free the metadata allocated in attach_metadata_full_frame */static voidfree_face_param_meta (gpointer meta_data)&#123; g_print ("free output buffer, free output buffer.\n"); MtcnnPluginOutput *output = (MtcnnPluginOutput *)meta_data; g_free(output);&#125; 获取数据可以使用如下方法：方法1：直接调用我们自己定义的函数1metadata = gst_buffer_get_face_param_meta(); 方法2：因为我们可能在不同的element中添加很多个自定义数据结构，使用方法1只能取到最后一个添加的，需要使用以下方法进行遍历：123456static GQuark _ivameta_quark = 0;if (!_ivameta_quark) &#123; //注意参数时我们注册api type时添加的tag //类似键值对 _ivameta_quark = g_quark_from_static_string ("face");&#125; 1234567891011121314151617181920212223GstMeta *gst_meta;// Standard way of iterating through buffer metadatawhile ((gst_meta = gst_buffer_iterate_meta (outbuf, &amp;state)) != NULL) &#123; //可以获取GstMetaInfo，注意参数需要和注册时一致 const GstMetaInfo *info = gst_meta_get_info("FaceParamMeta"); //查询是否有我们想要的api type if (!gst_meta_api_type_has_tag (gst_meta-&gt;info-&gt;api, _ivameta_quark)) &#123; continue; &#125; //如果是，转成我们的结构体 ivameta = (FaceParamMeta *) gst_meta; // Check if the metadata of IvaMeta contains object bounding boxes if (ivameta-&gt;meta_type != FACE_PARAM) continue; //根据meta_type获取具体数据 meta_data = (MtcnnPluginOutput *) ivameta-&gt;meta_data;&#125; 参考官网链接:GstMetaMemory allocation]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019学习计划]]></title>
    <url>%2F2019%2F03%2F31%2F2019%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件编写学习]]></title>
    <url>%2F2019%2F03%2F29%2FGStreamer%E6%8F%92%E4%BB%B6%E7%BC%96%E5%86%99%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[下载插件模板1234567shell $ git clone https://gitlab.freedesktop.org/gstreamer/gst-template.gitInitialized empty Git repository in /some/path/gst-template/.git/remote: Counting objects: 373, done.remote: Compressing objects: 100% (114/114), done.remote: Total 373 (delta 240), reused 373 (delta 240)Receiving objects: 100% (373/373), 75.16 KiB | 78 KiB/s, done.Resolving deltas: 100% (240/240), done. 以上方案有点过时，可到github下载gst-plugins-bad模块，使用里面的工具生成模板。 使用make_element生成模板12cd gst-template/gst-plugin/src../tools/make_element MyFilter &lt;基类文件如:gsttransform&gt; 修改makefile.am文件12345678910111213141516171819202122# Note: plugindir is set in configure############################################################################### TODO: change libgstplugin.la to something else, e.g. libmysomething.la ###############################################################################plugin_LTLIBRARIES = libgstplugin.la libgstaudiofilterexample.la############################################################################### TODO: for the next set of variables, name the prefix if you named the .la, ## e.g. libmysomething.la =&gt; libmysomething_la_SOURCES ## libmysomething_la_CFLAGS ## libmysomething_la_LIBADD ## libmysomething_la_LDFLAGS ################################################################################# Plugin 1# sources used to compile this plug-inlibgstplugin_la_SOURCES = gstplugin.c gstplugin.h# compiler and linker flags used to compile this plugin, set in configure.aclibgstplugin_la_CFLAGS = $(GST_CFLAGS)libgstplugin_la_LIBADD = $(GST_LIBS)libgstplugin_la_LDFLAGS = $(GST_PLUGIN_LDFLAGS)libgstplugin_la_LIBTOOLFLAGS = --tag=disable-static# headers we need but don&apos;t want installednoinst_HEADERS = gstplugin.h 生成makefile文件123./autogen.shmakesudo make install 注意：需要修改configure.ac文件里面安装的路径，不然插件会被安装到/usr/local/lib/gstreamer-1.0中 Example Demo1234567891011121314151617181920212223242526#include &lt;gst/gst.h&gt;/* Definition of structure storing data for this element. */typedef struct _GstMyFilter &#123; GstElement element; GstPad *sinkpad, *srcpad; gboolean silent;&#125; GstMyFilter; /* Standard definition defining a class for this element. */typedef struct _GstMyFilterClass &#123; GstElementClass parent_class;&#125; GstMyFilterClass;/* Standard macros for defining types for this element. */#define GST_TYPE_MY_FILTER (gst_my_filter_get_type())#define GST_MY_FILTER(obj) \ (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_MY_FILTER,GstMyFilter))#define GST_MY_FILTER_CLASS(klass) \ (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_MY_FILTER,GstMyFilterClass))#define GST_IS_MY_FILTER(obj) \ (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_MY_FILTER))#define GST_IS_MY_FILTER_CLASS(klass) \ (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_MY_FILTER)) /* Standard function returning type information. */GType gst_my_filter_get_type (void); Element metadata元素元数据提供额外的元素信息，使用gst_element_class_set_metadata或者gst_element_class_set_static_metadata函数来设置，其参数包含： A long, English, name for the element. The type of the element, see the docs/design/draft-klass.txt documentin the GStreamer core source tree for details and examples. A brief description of the purpose of the element. The name of the author of the element, optionally followed by acontact email address in angle brackets.例如：12345gst_element_class_set_static_metadata (klass,"An example plugin","Example/FirstExample","Shows the basic structure of a plugin","your name &lt;your.name@your.isp&gt;"); 以上函数在初始化_class_init ()插件的时候调用123456789101112static voidgst_my_filter_class_init (GstMyFilterClass * klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_set_static_metadata (element_klass, "An example plugin", "Example/FirstExample", "Shows the basic structure of a plugin", "your name &lt;your.name@your.isp&gt;");&#125; GstStaticPadTemplateGstStaticPadTemplate是用来描述将要创建的pad的信息，包含: A short name for the pad. Pad direction. Existence property. This indicates whether the pad exists always (an “always” pad), only in some cases (a “sometimes” pad) or only if the application requested such a pad (a “request” pad). Supported types by this element (capabilities).例如：1234567static GstStaticPadTemplate sink_factory =GST_STATIC_PAD_TEMPLATE ( "sink", //名称 GST_PAD_SINK, //方向sink or src GST_PAD_ALWAYS, //availability GST_STATIC_CAPS ("ANY") //capability); 同样该sink_factory也是在初始化时候使用，通过gst_element_class_add_pad_template ()和gst_static_pad_template_get ()来调用1234567891011121314static GstStaticPadTemplate sink_factory = [..], src_factory = [..];static voidgst_my_filter_class_init (GstMyFilterClass * klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;src_factory)); gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;sink_factory));&#125; 该pad将在构造函数_init ()函数中使用gst_pad_new_from_static_template ()来创建。 注：对于每个element来说，有两个构造函数，其中_class_init()函数只调用一次，用来说明类所拥有的信号、参数、虚函数以及设置全局状态；_init()函数则用在初始化实例特定的实例。 插件初始化函数当我们写完插件的所有部件之后，需要编写插件的初始化函数，这个函数在插件加载的时候调用，需要返回TRUE or FALSE来觉得是否正确加载。在这个函数中，任何支持的element插件应该被注册。12345678910111213141516171819static gbooleanplugin_init (GstPlugin *plugin)&#123; return gst_element_register (plugin, "my_filter", GST_RANK_NONE, GST_TYPE_MY_FILTER);&#125;GST_PLUGIN_DEFINE ( GST_VERSION_MAJOR, GST_VERSION_MINOR, my_filter, "My filter plugin", plugin_init, VERSION, "LGPL", "GStreamer", "http://gstreamer.net/") pads具体说明PADS是数据流进出每个element的端口，在初始化_init ()函数中，你从pad template中创建了一个pad，这个pad template是在_class_init ()函数中注册的，创建了pad之后，你必须在sinkpad设置_chain ()函数指针用来接收和处理数据。可选的，你也可以设置_event ()和_query ()指针；pad亦可以使用循环模式，这意味着它们可以自己拉取数据。1234567891011121314151617181920static voidgst_my_filter_init (GstMyFilter *filter)&#123; /* pad through which data comes in to the element */ filter-&gt;sinkpad = gst_pad_new_from_static_template ( &amp;sink_template, "sink"); /* pads are configured here with gst_pad_set_*_function () */ gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;sinkpad); /* pad through which data goes out of the element */ filter-&gt;srcpad = gst_pad_new_from_static_template ( &amp;src_template, "src"); /* pads are configured here with gst_pad_set_*_function () */ gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;srcpad); /* properties initial value */ filter-&gt;silent = FALSE; &#125; Sometimes PadSometimes pad 只有在一些特定情况下才创建，这取决于流内容。比如demuxers解析流头。每个element可以创建多个sometimes pad，唯一限制就是都要有唯一的名字。当流数据被销毁时（比如从PAUSED到READY状态），pad也应该被销毁，但是在EOS状态不应该被销毁。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146typedef struct _GstMyFilter &#123;[..] gboolean firstrun; GList *srcpadlist;&#125; GstMyFilter;//静态目标类型sometimesstatic GstStaticPadTemplate src_factory =GST_STATIC_PAD_TEMPLATE ( "src_%u", GST_PAD_SRC, GST_PAD_SOMETIMES, GST_STATIC_CAPS ("ANY"));static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..]//注册pad gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;src_factory));[..]&#125;static voidgst_my_filter_init (GstMyFilter *filter)&#123;[..] filter-&gt;firstrun = TRUE; filter-&gt;srcpadlist = NULL;&#125;/* * Get one line of data - without newline. */static GstBuffer *gst_my_filter_getline (GstMyFilter *filter)&#123; guint8 *data; gint n, num; /* max. line length is 512 characters - for safety */ for (n = 0; n &lt; 512; n++) &#123; num = gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n + 1); if (num != n + 1) return NULL; /* newline? */ if (data[n] == '\n') &#123; GstBuffer *buf = gst_buffer_new_allocate (NULL, n + 1, NULL); gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n); gst_buffer_fill (buf, 0, data, n); gst_buffer_memset (buf, n, '\0', 1); gst_bytestream_flush_fast (filter-&gt;bs, n + 1); return buf; &#125; &#125;&#125;static voidgst_my_filter_loopfunc (GstElement *element)&#123; GstMyFilter *filter = GST_MY_FILTER (element); GstBuffer *buf; GstPad *pad; GstMapInfo map; gint num, n; /* parse header */ if (filter-&gt;firstrun) &#123; gchar *padname; guint8 id; if (!(buf = gst_my_filter_getline (filter))) &#123; gst_element_error (element, STREAM, READ, (NULL), ("Stream contains no header")); return; &#125; gst_buffer_extract (buf, 0, &amp;id, 1); num = atoi (id); gst_buffer_unref (buf); /* for each of the streams, create a pad */ //根据头的流个数，创建num个pad for (n = 0; n &lt; num; n++) &#123; padname = g_strdup_printf ("src_%u", n); pad = gst_pad_new_from_static_template (src_factory, padname); g_free (padname); /* here, you would set _event () and _query () functions */ /* need to activate the pad before adding */ gst_pad_set_active (pad, TRUE); gst_element_add_pad (element, pad); filter-&gt;srcpadlist = g_list_append (filter-&gt;srcpadlist, pad); &#125; &#125; /* and now, simply parse each line and push over */ if (!(buf = gst_my_filter_getline (filter))) &#123; GstEvent *event = gst_event_new (GST_EVENT_EOS); GList *padlist; for (padlist = srcpadlist; padlist != NULL; padlist = g_list_next (padlist)) &#123; pad = GST_PAD (padlist-&gt;data); gst_pad_push_event (pad, gst_event_ref (event)); &#125; gst_event_unref (event); /* pause the task here */ return; &#125; /* parse stream number and go beyond the ':' in the data */ gst_buffer_map (buf, &amp;map, GST_MAP_READ); num = atoi (map.data[0]); if (num &gt;= 0 &amp;&amp; num &lt; g_list_length (filter-&gt;srcpadlist)) &#123; //取第N个pad塞数据 pad = GST_PAD (g_list_nth_data (filter-&gt;srcpadlist, num); /* magic buffer parsing foo */ for (n = 0; map.data[n] != ':' &amp;&amp; map.data[n] != '\0'; n++) ; if (map.data[n] != '\0') &#123; GstBuffer *sub; /* create region copy that starts right past the space. The reason * that we don't just forward the data pointer is because the * pointer is no longer the start of an allocated block of memory, * but just a pointer to a position somewhere in the middle of it. * That cannot be freed upon disposal, so we'd either crash or have * a memleak. Creating a region copy is a simple way to solve that. */ sub = gst_buffer_copy_region (buf, GST_BUFFER_COPY_ALL, n + 1, map.size - n - 1); gst_pad_push (pad, sub); &#125; &#125; gst_buffer_unmap (buf, &amp;map); gst_buffer_unref (buf);&#125; Request padRequest pad 只有在外部需要的时候才创建而不是element内部。比如tee element可以根据需要拷贝多份数据到不同的分支。需要实现request_new_pad和release_pad两个虚函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static GstPad * gst_my_filter_request_new_pad (GstElement *element, GstPadTemplate *templ, const gchar *name, const GstCaps *caps);static void gst_my_filter_release_pad (GstElement *element, GstPad *pad);static GstStaticPadTemplate sink_factory =GST_STATIC_PAD_TEMPLATE ( "sink_%u", GST_PAD_SINK, GST_PAD_REQUEST, GST_STATIC_CAPS ("ANY"));static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_add_pad_template (klass, gst_static_pad_template_get (&amp;sink_factory));[..] element_class-&gt;request_new_pad = gst_my_filter_request_new_pad; element_class-&gt;release_pad = gst_my_filter_release_pad;&#125;static GstPad *gst_my_filter_request_new_pad (GstElement *element, GstPadTemplate *templ, const gchar *name, const GstCaps *caps)&#123; GstPad *pad; GstMyFilterInputContext *context; context = g_new0 (GstMyFilterInputContext, 1); pad = gst_pad_new_from_template (templ, name); gst_pad_set_element_private (pad, context); /* normally, you would set _chain () and _event () functions here */ gst_element_add_pad (element, pad); return pad;&#125;static voidgst_my_filter_release_pad (GstElement *element, GstPad *pad)&#123; GstMyFilterInputContext *context; context = gst_pad_get_element_private (pad); g_free (context); gst_element_remove_pad (element, pad);&#125; The chain functionchain函数是处理数据的地方，记住buffers并不总是可写的。123456789101112131415161718192021222324252627282930static GstFlowReturn gst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf);[..]static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] /* configure chain function on the pad before adding * the pad to the element */ gst_pad_set_chain_function (filter-&gt;sinkpad, gst_my_filter_chain);[..]&#125;static GstFlowReturngst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); if (!filter-&gt;silent) g_print ("Have data of size %" G_GSIZE_FORMAT" bytes!\n", gst_buffer_get_size (buf)); return gst_pad_push (filter-&gt;srcpad, buf);&#125; The event function在一些高级的element中，需要设置event处理函数。它通知一些发生在数据流中的特定事件，比如（caps, end-of-stream, newsegment, tags, etc.），事件可以传播到上游和下游，所以你可以在sink pads和source pads接收到。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] gst_pad_set_event_function (filter-&gt;sinkpad, gst_my_filter_sink_event);[..]&#125;static gbooleangst_my_filter_sink_event (GstPad *pad, GstObject *parent, GstEvent *event)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); switch (GST_EVENT_TYPE (event)) &#123; case GST_EVENT_CAPS: /* we should handle the format here */ break; case GST_EVENT_EOS: /* end-of-stream, we should close down all stream leftovers here */ gst_my_filter_stop_processing (filter); break; default: break; &#125; return gst_pad_event_default (pad, parent, event);&#125;static GstFlowReturngst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); GstBuffer *outbuf; outbuf = gst_my_filter_process_data (filter, buf); gst_buffer_unref (buf); if (!outbuf) &#123; /* something went wrong - signal an error */ GST_ELEMENT_ERROR (GST_ELEMENT (filter), STREAM, FAILED, (NULL), (NULL)); return GST_FLOW_ERROR; &#125; return gst_pad_push (filter-&gt;srcpad, outbuf);&#125; The query function通过query函数，element可以接收查询事件并作出回复，比如（position, duration，supported formats，scheduling modes）。查询同样可以传播到上下游，你可以在sink pads和source pads接收到。123456789101112131415161718192021222324252627282930313233343536373839404142434445static gboolean gst_my_filter_src_query (GstPad *pad, GstObject *parent, GstQuery *query);[..]static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] /* configure event function on the pad before adding * the pad to the element */ gst_pad_set_query_function (filter-&gt;srcpad, gst_my_filter_src_query);[..]&#125;static gbooleangst_my_filter_src_query (GstPad *pad, GstObject *parent, GstQuery *query)&#123; gboolean ret; GstMyFilter *filter = GST_MY_FILTER (parent); switch (GST_QUERY_TYPE (query)) &#123; case GST_QUERY_POSITION: /* we should report the current position */ [...] break; case GST_QUERY_DURATION: /* we should report the duration here */ [...] break; case GST_QUERY_CAPS: /* we should report the supported caps here */ [...] break; default: /* just call the default handler */ ret = gst_pad_query_default (pad, parent, query); break; &#125; return ret;&#125; element状态状态可以用来描述element是否初始化，是否准备传送数据，是否正在处理数据。 GST_STATE_NULL element默认状态，不分配任何资源，不加载任何库。 GST_STATE_READY 分配默认资源(runtime-libraries, runtime-memory)，不分配或者定义stream-specific相关的资源，当状态从NULL到READY时，分配任何non-stream-specific资源，加载运行时库。当状态从READY转到NULL时，卸载相关资源，比如硬件设备。注意文件也是流，所以在READY状态下不会分配。 GST_STATE_PAUSED element准备接收和处理数据，对于大部分elements来说PAUSED和PLAYING是一样的，唯一的区别是sink elements，它只接收一次数据然后阻塞住，这时候pipeline处于’prerolled’状态，准备渲染数据。 GST_STATE_PLAYING 在播放状态下sink elements渲染接收的数据，其他elements和PAUSED状态一样。 管理filter状态一般来说，elements继承一些基类，比如sources, sinks and filter/transformation elements。如果是继承这些基类，你就不需要亲自处理状态的改变。你只需继承基类的虚函数start()和stop()。如果不是继承基类，而是继承GstElement，你就必须自己处理状态的改变，比如像demuxer和muxer这种插件。通过虚函数，element可以被通知状态的改变然后初始化必要数据，也可以选择状态改变失败。 注意，向上（NULL =&gt; READY，READY =&gt; PAUSED，PAUSED =&gt; PLAYING）和向下（PLAYING =&gt; PAUSED，PAUSED =&gt; READY，READY =&gt; NULL）状态更改在两个单独的块中处理，向下状态发生变化只有在我们链接到父类的状态更改函数之后才会处理。这是为了安全地处理多个线程的并发访问所必需的。123456789101112131415161718192021222324252627282930313233343536373839404142static GstStateChangeReturngst_my_filter_change_state (GstElement *element, GstStateChange transition);static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass); element_class-&gt;change_state = gst_my_filter_change_state;&#125;static GstStateChangeReturngst_my_filter_change_state (GstElement *element, GstStateChange transition)&#123; GstStateChangeReturn ret = GST_STATE_CHANGE_SUCCESS; GstMyFilter *filter = GST_MY_FILTER (element); switch (transition) &#123; case GST_STATE_CHANGE_NULL_TO_READY: if (!gst_my_filter_allocate_memory (filter)) return GST_STATE_CHANGE_FAILURE; break; default: break; &#125; ret = GST_ELEMENT_CLASS (parent_class)-&gt;change_state (element, transition); if (ret == GST_STATE_CHANGE_FAILURE) return ret; switch (transition) &#123; case GST_STATE_CHANGE_READY_TO_NULL: gst_my_filter_free_memory (filter); break; default: break; &#125; return ret;&#125; 增加属性通过属性可以控制element的行为。属性在_class_init ()函数中定义，在_get_property ()和a _set_property ()函数中设置或者获取。可以在_init ()构造函数中初始化属性值。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/* properties */enum &#123; PROP_0, PROP_SILENT /* FILL ME */&#125;;static void gst_my_filter_set_property (GObject *object, guint prop_id, const GValue *value, GParamSpec *pspec);static void gst_my_filter_get_property (GObject *object, guint prop_id, GValue *value, GParamSpec *pspec);static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GObjectClass *object_class = G_OBJECT_CLASS (klass); /* define virtual function pointers */ object_class-&gt;set_property = gst_my_filter_set_property; object_class-&gt;get_property = gst_my_filter_get_property; /* define properties */ g_object_class_install_property (object_class, PROP_SILENT, g_param_spec_boolean ("silent", "Silent", "Whether to be very verbose or not", FALSE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));&#125;static voidgst_my_filter_set_property (GObject *object, guint prop_id, const GValue *value, GParamSpec *pspec)&#123; GstMyFilter *filter = GST_MY_FILTER (object); switch (prop_id) &#123; case PROP_SILENT: filter-&gt;silent = g_value_get_boolean (value); g_print ("Silent argument was changed to %s\n", filter-&gt;silent ? "true" : "false"); break; default: G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec); break; &#125;&#125;static voidgst_my_filter_get_property (GObject *object, guint prop_id, GValue *value, GParamSpec *pspec)&#123; GstMyFilter *filter = GST_MY_FILTER (object); switch (prop_id) &#123; case PROP_SILENT: g_value_set_boolean (value, filter-&gt;silent); break; default: G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec); break; &#125;&#125; 两种调度模式Gstreamer 有两种调度模式 push mode pull mode 我们之前讨论的_chain ()函数属于push mode，通过调用gst_pad_push ()，使得下游的element的_chain ()被调用。 后续补充]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件之Transform elements]]></title>
    <url>%2F2019%2F03%2F29%2FGStreamer%E6%8F%92%E4%BB%B6%E4%B9%8BTransform-elements%2F</url>
    <content type="text"><![CDATA[前言写了个gstreamer插件继承于基类Transform element. 其中有些概念需要理解一下，特此做下笔记。参考官网链接 Transform elements基于sink和src pad的caps将输入的buffer转换为输出buffer。而输出的caps完全由输入的caps所定义，这表明像解码器这种组件不能够由Transform elements来实现，因为其输出的视频帧的宽高在输入时是被压缩在流当中的，所以输入是没有宽高这种属性的。如下所示的avdec_h264解码组件所示：12345678910111213141516171819202122232425Pad Templates: SRC template: 'src' Availability: Always Capabilities: video/x-raw format: &#123; (string)I420, (string)YUY2, (string)RGB, (string)BGR, (string)Y42B, (string)Y444, (string)YUV9, (string)Y41B, (string)GRAY8, (string)RGB8P, (string)I420, (string)Y42B, (string)Y444, (string)UYVY, (string)NV12, (string)NV21, (string)ARGB, (string)RGBA, (string)ABGR, (string)BGRA, (string)GRAY16_BE, (string)GRAY16_LE, (string)A420, (string)RGB16, (string)RGB15, (string)I420_10BE, (string)I420_10LE, (string)I422_10BE, (string)I422_10LE, (string)Y444_10BE, (string)Y444_10LE, (string)GBR, (string)GBR_10BE, (string)GBR_10LE, (string)A420_10BE, (string)A420_10LE, (string)A422_10BE, (string)A422_10LE, (string)A444_10BE, (string)A444_10LE, (string)GBRA, (string)xRGB, (string)RGBx, (string)xBGR, (string)BGRx, (string)I420_12BE, (string)I420_12LE, (string)I422_12BE, (string)I422_12LE, (string)Y444_12BE, (string)Y444_12LE, (string)GBR_12BE, (string)GBR_12LE, (string)GBRA_12BE, (string)GBRA_12LE &#125; SINK template: 'sink' Availability: Always Capabilities: video/x-h264 alignment: au stream-format: &#123; (string)avc, (string)byte-stream &#125; 典型transform elements包含： audio convertors (audioconvert, audioresample,…) video convertors (colorspace, videoscale, …) filters (capsfilter, volume, colorbalance, …) 要实现transform elements必须关心的是： efficient negotiation both up and downstream efficient buffer alloc and other buffer management transform elements可以使用不同模式： passthrough (no changes are done on the input buffers) in-place (changes made directly to the incoming buffers without requiring a copy or new buffer allocation) metadata changes only transform元素通常也会处理以下事项： flushing, seeking state changes timestamping, this is typically done by copying the input timestamps to the output buffers but subclasses should be able to override this. QoS, avoiding calls to the subclass transform function handle scheduling issues such as push and pull based operation. transform element应在任何时候可以重新协商sink和src caps，并改变操作模式。根据不同的模式，buffer的分配可能采用不同策略。 transform element behaviourProcessingtransform主要由两种处理函数： transform(): Transform the input buffer to the output buffer. The output buffer is guaranteed to be writable and different from the input buffer. transform_ip(): Transform the input buffer in-place. The input buffer is writable and of bigger or equal size than the output buffer. 转换操作有以下模式： passthrough: The element will not make changes to the buffers, buffers are pushed straight through, caps on both sides need to be the same. The element can optionally implement a transform_ip() function to take a look at the data, the buffer does not have to be writable. in-place: Changes can be made to the input buffer directly to obtain the output buffer. The transform must implement a transform_ip() function. copy-transform: The transform is performed by copying and transforming the input buffer to a new output buffer. The transform must implement a transform() function. 当没有使用transform()函数的时候，只有in-place 和 passthrough模式可以使用，这意味着sinkpad和srcpad要一样或者src buffer大于等于sink buffer。 当没有使用transform_ip()函数的时候，只允许passthrough和copy-transforms两种模式，提供这个函数可以避免内存的拷贝。 当没有使用以上两种函数时，只使用passthrough模式。 Negotiation在push mode下transform element的协商总是从sink到src： sinkpad接收到新的caps事件 transform函数算出它可以将此caps转化成什么 尝试不做任何修改，因为我们倾向于不做任何事情 transform配置自身使得可以将sink caps转换到模板src caps transform在srcpad上设置处理输出caps1234567 sinkpad transform srcpadCAPS event | | |------------&gt;| find_transform() | | |-------------------&gt;| | | | CAPS event | | |---------------------&gt;| | &lt;configure caps&gt; &lt;-| | transform 有三个函数执行协商： transform_caps(): Transform the caps on a certain pad to all the possible supported caps on the other pad. The input caps are guaranteed to be a simple caps with just one structure. The caps do not have to be fixed. fixate_caps(): Given a caps on one pad, fixate the caps on the other pad. The target caps are writable. set_caps(): Configure the transform for a transformation between src caps and dest caps. Both caps are guaranteed to be fixed caps. 如果transform_caps()未定义，默认只执行同样的转换。如果set_caps()未定义，我们不关心caps，在这种情况下我们假设没有任何内容写到缓冲区，我们不会为该transform_ip()函数强制执行可写缓冲区（如果存在）。 我们对transform元素需要的一个常见函数是找到从一种格式（src）到另一种格式（dest）的最佳转换。该函数的一些要求是： 有一个固定的src caps 找到一个固定的transform element可以转换成的dest caps dest caps是兼容的并且可被peer elements接受 transform函数倾向于使src caps == dest caps transform函数可以选择性固定dest caps find_transform()函数执行如下: 从一个固定的src caps开始； 检测这些caps是否可以被用作src caps，这通常由元素的padtemplate强制执行； 使用transform_caps()计算所有的可以转换生成的caps 如果原始的caps是transforms的一个子集，尝试caps是否能被peer接受。如果可行，我们可以执行passthrough然后设置src == dest。这只要简单调用gst_pad_peer_query_accept_caps()即可。 如果caps不是固定的，我们需要固定它们。 transform_caps()检索每个转换的caps 使用fixate_caps()固定caps 如果caps是固定的，使用_peer_query_accept_caps()检测peer是否接受他们，如果接受，我们就找到了dest caps。 如果找遍caps还没发现可转换的caps就表明失败了。 如果找到dest caps，使用set_caps()进行配置。 在协商过程之后，transform元素通常是一个稳定的状态。我们可以确定这个状态： src和sink pads有同样的caps passthrough: buffers are inspected but no metadata or buffer data is changed. The input buffers don’t need to be writable. The input buffer is simply pushed out again without modifications. (SCP) 123456 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| pad_push() | | |---------------------&gt;| | | | in-place: buffers are modified in-place, this means that the input buffer is modified to produce a new output buffer. This requires the input buffer to be writable. If the input buffer is not writable, a new buffer has to be allocated from the bufferpool. (SCI) 123456789101112 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | [!writable] | | | alloc buffer | | .-| | | &lt;transform_ip&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | copy transform: a new output buffer is allocate from the bufferpool and data from the input buffer is transformed into the output buffer. (SCC) 1234567891011 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | alloc buffer | | .-| | | &lt;transform&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | src和sink pads有不一样的样的caps in-place: input buffers are modified in-place. This means that the input buffer has a size that is larger or equal to the output size. The input buffer will be resized to the size of the output buffer. If the input buffer is not writable or the output size is bigger than the input size, we need to pad-alloc a new buffer. (DCI) 123456789101112 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | [!writable || !size] | | | alloc buffer | | .-| | | &lt;transform_ip&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | copy transform: a new output buffer is allocated and the data from the input buffer is transformed into the output buffer. The flow is exactly the same as the case with the same-caps negotiation. (DCC) Allocation当transform element配置完成之后，缓冲池需要根据caps开辟内存，主要有两种情况： 当使用passthrough模式的时候不需要在transform element中开辟内存。 当不使用passthrough，并且需要开辟输出buffer。 对于第一种情况，我们不需要查询和配置pool。我们让upstream自动决定是否需要bufferpool，然后我们将从下游到上游进行代理。 对于第二种情况，我们在srcpad设置分配内存池。 为了分配内存，我们还需要知道输出空间的大小，这里有两个函数获取大小： transform_size(): Given a caps and a size on one pad, and a caps on the other pad, calculate the size of the other buffer. This function is able to perform all size transforms and is the preferred method of transforming a size. get_unit_size(): When the input size and output size are always a multiple of each other (audio conversion, ..) we can define a more simple get_unit_size() function. The transform will use this function to get the same amount of units in the source and destination buffers. For performance reasons, the mapping between caps and size is kept in a cache.]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
</search>
