<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PaperReading: FaceBoxes]]></title>
    <url>%2F2019%2F05%2F05%2FPaperReading%3AFaceBoxes%2F</url>
    <content type="text"><![CDATA[概述​ 人脸检测是人脸对齐、人脸识别、人脸跟踪的基础。目前人脸检测还面临着很多挑战，主要还是精度和速度的问题。很多研究都是为了解决这两个问题。早期的方法是基于人工特征，以V-J人脸检测为代表，大量的研究都是设计一个鲁棒的特征和训练一个有效的分类器。cascade structure和DMP模型都能获得不错的性能。但是这些方法都是基于不鲁棒的特征，虽然速度快，但是在不同场景下精度不高。另一种方法是基于卷积神经网络。卷积网络对于多变人脸具有很高的鲁棒性，但是在速度上却不快，尤其是在CPU设备上面。 ​ 这两种方法有各自的优点。为了在速度和精度上能够达到较好的性能，一种自然的想法是结合两种类型的方法，也就是采用级联的卷积神经网络，比如MTCNN。但是基于级联的卷积神经网络会带来三个问题：1.速度和人脸数量相关，人脸越多速度越慢；2.级联检测器都是基于局部优化，训练复杂；3.不能达到实时。 ​ 此篇文章灵感来源于Faster R-CNN中的RPN以及SSD的多尺度机制。这是一个ONE-STAGE网络，网络结构主要包含两部分：1.Rapidly Digested Convolutional Layers (RDCL)和Multiple Scale Convolutional Layers (MSCL)。RDCL是为了解决实时问题，MSCL主要为了丰富感受野，使不同层的anchor离散化，解决人脸多尺度问题。除此之外，作者还提出Anchor densification strategy让不同类型的anchor有相同的密度，这极大提高小人脸的召回率。对于VGA图片(640x480)在CPU可以达到20FPS，在GPU可以达到125FPS。作者认为他们工作的贡献包含四部分，除了以上说的三点之外，还包含：在AFW, PASCAL face, and FDDB datasets取得最好性能(what? 这也算？) 网络结构 RDCL 缩小输入的空间大小：为了快速减小输入的空间尺度大小，在卷积核池化上使用了一系列的大的stride，在Conv1、Pool1、Conv2、Pool2上stride分别是4、2、2、2，RDCL的stride一共是32，意味着输入的尺度大小被快速减小了32倍。 选择合适的kernel size：一个网络开始的一些层的kernel size应该比较小以用来加速，同时也应该足够大用以减轻空间大小减小带来的信息损失。Conv1、Conv2以及所有的Pool层分别选取7x7，5x5，3x3的kernel size。 减少输出通道数：使用C.ReLU来减少输出通道数。为啥提出这个激活函数有专门的论文参考，引：网络的前部，网络倾向于同时捕获正负相位的信息，但ReLU会抹掉负响应。 这造成了卷积核会存在冗余。 MSCL 将RPN作为一个人脸检测器，不能获取很好的性能有以下两个原因： RPN中的anchor只和最后一个卷积层相关，其中的特征和分辨率对于处理人脸变化问题上太弱。 anchor相应的层使用一系列不同的尺度来检测人脸，但只有单一的感受野，不能匹配不同尺度的人脸。 为解决这个问题，对MSCL从以下两个角度去设计： Multi-scale design along the dimension of network depth. Anchor在多尺度的feature map上面取，类似SSD。 Multi-scale design along the dimension of network width.使用inception模块，内部使用不同大小的卷积核，可以捕获到更多的尺度信息。 Anchor densification strategy​ 对于Anchor作者使用1:1的宽高比，原因是因为人脸框接近正方形。 Inception3的anchor尺度为32x32，64x64，128x128，Conv3_2、Conv4_2的尺度分别为256x256和512x512。 ​ 对于anchor相应层的间隔相当于步长大小、比如，对于Conv3 2步长是64，anchor大小256x256，意思是对于输入图片，每隔64个像素有一个256x256的anchor。作者提出了一个anchor密度概念：$$A_{density} = \frac{A_{scale}}{A_{interval}}$$其中分子表示anchor大小，分母表示anchor间隔，对于anchor间隔一般是默认的，也就是步长大小，分别为32、32、32、64、128。根据式子计算出来的密度分别为1、2、4、4、4。由此可以看到对于小人脸anchor太稀疏，密度太低，会导致小人脸的召回率下降。为了消除这个不平衡，作者提出了一种策略，在原来的anchor中心均匀叠加n^2个anchor，以保证密度相同，所以对于32x32的anchor叠加为原来的４倍，对于64x64的anchor叠加为原来的２倍。 训练训练集WIDER FACE的子集，12880个图片。 数据增强 Color distortion Random cropping Scale transformation Horizontal flipping Face-box filter 匹配策略在训练时需要判断哪个anchor是和哪个bounding box对应。首先使用jaccard overlap将每个脸和anchor对应起来，然后对anchor和任意脸jaccard overlap高于阈值（0.35）的匹配起来。 损失函数和Faster R-CNN中的RPN用同样的loss，一个2分类的softmax loss用来做分类，smooth L1用来做回归。 Hard negative mining:在anchor匹配后，大多数anchor都是负样本，导致正样本和负样本严重不均衡。为了更快更稳定的训练，将他们按照loss值排序并选取最高的几个，保证正样本和负样本的比例最高不超过3:1. Other implementation details:Xavier随机初始化。优化器SGD，momentum:0.9，weight decay:5e-4，batch size:32，迭代最大次数:120k，初始80k迭代learning rate:1e-3，80-100k迭代用1e-4，,100-120k迭代用1e-5，使用caffe实现。 参考链接《Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units》 CReLU激活函数 代码]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>人脸检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 使用方法总结]]></title>
    <url>%2F2019%2F04%2F30%2Fgit-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[git 使用方法总结比较基础的方法就不一一写了，碰到没使用过的在慢慢总结更新。 git status可以看到有三部分的内容，我们分为上中下。对于Changes to be committed 为暂存区，Changes not staged for commit为工作区，Untracked files为未添加文件（本地文件）。 先解释几个概念： １．工作区：就是你在电脑里能看到的目录 ２．版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 当我们想把文件往Git版本库里添加的时候，是分两步执行的：第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 12345678910111213141516171819202122232425ubuntu@ubuntu-B250-HD3:~/Project/faceengine/faceengine$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: src/core/CMakeLists.txt modified: src/core/algservice/FaceDetection/FaceDetector.cpp modified: src/core/algservice/FaceDetection/FaceDetector.h modified: src/core/algservice/FaceDetection/MTCNNCaffeDetector.h new file: src/core/algservice/FaceDetection/MTCNNTensorrtDetector.cpp new file: src/core/algservice/FaceDetection/MTCNNTensorrtDetector.h new file: src/core/algservice/FaceDetection/resizeconvertion.cu modified: src/core/scheduler/FaceEngine.cppChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: src/core/CMakeLists.txtUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) patch １．对于暂存区的内容，如果想要恢复和本地版本库一样，则需要输入命令： 12$ git reset HEAD &lt;file&gt;...$ git checkout -- &lt;file&gt;... ２．对于工作区的内容，如果需要恢复和本地版本库一样，则需要输入命令： 1$ git checkout -- &lt;file&gt;... ３．如果想把工作区的内容或者本地内容添加到暂存区： 1$ git add &lt;file&gt;... ４．当我们执行commit之后，想把版本回退到之前的版本： 123456# 回退到上一个版本$ git reset --hard HEAD^# 回退到上上版本$ git reset --hard HEAD^^# 回退到往上１００个版本$ git reset --hard HEAD~100 如果想恢复到最新版本： 123456# 找到commit id$ git reflog9febc2e HEAD@&#123;0&#125;: pull: Fast-forward7a028ee HEAD@&#123;1&#125;: clone: from https://xxx.git# 回退到某个版本$ git reset --hard 7a028ee git log123456789101112131415161718ubuntu@ubuntu-B250-HD3:~/Project/faceengine/faceengine$ git logcommit 9febc2e07ae0d5401dade4913578e2ae07381a73Author: yeweijing &lt;ypat_999@163.com&gt;Date: Sun Apr 28 10:28:06 2019 +0800 提交日志commit ca94b89fd7bfe19e8891a0f5c5f05d1339b42480Author: chendepin &lt;danpechen@126.com&gt;Date: Mon Apr 22 15:55:26 2019 +0800 修复适应不同目录结构的问题commit 0be1f9bb8f0d6fc41af30b88de70e539da421b67Author: chendepin &lt;danpechen@126.com&gt;Date: Fri Apr 19 15:16:13 2019 +0800 忽略 pyc 格式文件 9febc2e07ae0d5401dade4913578e2ae07381a73：为commit id（版本号），和SVN不一样，Git的commit id不是1，2，3……递增的数字，而是一个SHA1计算出来的一个非常大的数字，用十六进制表示为什么commit id需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。Author：为作者。Date：提交日期。最后是日志内容。 git rm12345678910111213141516# 创建文件并提交$ git add test.txt$ git commit -m "add test.txt"# 删除本地文件$ rm test.txt# 场景一# 更新到暂存区$ git rm/add test.txt# 删除本地库文件$ git commit -m "remove test.txt"# 场景二# 只删除本地文件，可以使用checkout复原$ git checkout -- test.txt git diff12345678910111213141516171819202122# 工作区与暂存区比较$ git diff# 暂存区与最新本地库比较$ git diff --cached [&lt;path&gt;...]# 工作区及暂存区与本地最新版本库比较$ git diff HEAD [&lt;path&gt;...]# 暂存区与指定commit-id比较$ git diff --cached [&lt;commit-id&gt;] [&lt;path&gt;...]# 比较两个commit-id之间的差异 $ git diff [&lt;commit-id&gt;] [&lt;commit-id&gt;]# 打补丁# 将暂存区与版本库的差异做成补丁$ git diff --cached &gt; patch# 将工作区以及暂存区与本地版本库的差异做成补丁$ git diff HEAD &gt; patch # 将工作区单个文件做成补丁$ git diff &lt;file&gt; git stash当我们在我们的分支上修改完成之后，需要先使用pull命令把远程库最新内容checkout下来，此时可能产生冲突导致pull不下来，因此需要现将我们修订的东西暂时储存起来。或者当我们在工作过程中，临时接到新任务，需要把当前的工作现场清理一下，等做完新任务后再恢复工作现场，这时候可以使用git stash来管理： 123456789101112131415161718192021222324252627282930313233343536373839404142# 查看当前分支状态$ git statusOn branch devChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: hello.pyChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txt# 将工作区和暂存区的文件保存到堆栈中$ git stashSaved working directory and index state WIP on dev: f52c633 add merge# 恢复$ git stash pop #相当于使用git stash apply和git stash dropOn branch devChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: hello.pyChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txtDropped refs/stash@&#123;0&#125; (5d677e2ee266f39ea296182fb2354265b91b3b2a)# 查看堆栈内容$ git stash list# 恢复指定的stash$ git stash apply stash@&#123;0&#125;# 清除stash$ git stash clean 远程仓库管理要关联一个远程库，使用命令如下，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库。 1$ git remote add origin git@github.com:clancylian/repo-name.git 关联后，由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 1$ git push -u origin master 此后，每次本地提交后，只要有必要，就可以使用以下命令提交： 1$ git push origin master 从远程库克隆下来： 1$ git clone https://github.com/clancylian/repo-name.git 1234567891011121314151617181920212223242526272829# 查看远程库信息$ git remoteorigin$ git remote -vorigin https://github.com/amdegroot/ssd.pytorch.git (fetch)origin https://github.com/amdegroot/ssd.pytorch.git (push)# 推送分支，master为本地分支$ git push origin master# checkout远程其他分支$ git checkout -b dev origin/dev# 如果push失败需要先pull下来$ git pullThere is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt;If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=origin/&lt;branch&gt; dev # 提示没有关联，需要先关联$ git branch --set-upstream-to=origin/dev devBranch 'dev' set up to track remote branch 'dev' from 'origin'. 分支管理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 创建分支并切换到分支$ git checkout -b branch1Switched to a new branch 'branch1'# 相当于以下命令$ git branch branch1$ git checkout branch1Switched to branch 'branch1'# 查看当前分支,当前分支会有*号，也就是HEAD指向的分支$ git branch* branch1 master # 修改完分支内容之后，切换回主分支$ git checkout masterSwitched to branch 'master'# 合并分支，git merge命令用于合并指定分支(branch1)到当前分支(master)$ git merge branch1Updating d46f35e..b17d20eFast-forward readme.txt | 1 + 1 file changed, 1 insertion(+) # 删除分支$ git branch -d branch1Deleted branch dev (was b17d20e).######################################################3# 当合并分支的时候出现冲突时$ git statusOn branch masterYour branch is ahead of 'origin/master' by 2 commits. (use "git push" to publish your local commits)You have unmerged paths. (fix conflicts and run "git commit") (use "git merge --abort" to abort the merge)Unmerged paths: (use "git add &lt;file&gt;..." to mark resolution) both modified: readme.txtno changes added to commit (use "git add" and/or "git commit -a")# 查看文件内容出现&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADaaaaaaaaaaaaaaaaaaaaaaaa=======bbbbbbbbbbbbbbbbbbbbbbbb&gt;&gt;&gt;&gt;&gt;&gt;&gt; branch1# 手动修改后$ git add &lt;file&gt; $ git commit -m "conflict fixed" ## 标签管理 1234567891011121314151617181920212223242526272829303132333435363738# 创建标签$ git tag v1.0$ git tagv1.0# 对历史版本打标签$ git tag v0.9 f52c633# 查看标签信息$ git show v0.9# 带有说明的标签$ git tag -a v0.1 -m "version 0.1 released" 1094adb# 删除本地标签$ git tag -d v0.1Deleted tag 'v0.1' (was f15b0dd)# 提交标签到远程库$ git push origin v1.0Total 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v1.0 -&gt; v1.0# 提交所有标签$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v0.9 -&gt; v0.9# 删除远程标签$ git tag -d v0.9Deleted tag 'v0.9' (was f52c633)$ git push origin :refs/tags/v0.9To github.com:michaelliao/learngit.git - [deleted] v0.9 参考链接git 学习网站推荐 gitignore 配置文件]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv GPU和CPUX实现直方图均衡差异]]></title>
    <url>%2F2019%2F04%2F29%2Fopencv-GPU%E5%92%8CCPUX%E5%AE%9E%E7%8E%B0%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%B7%AE%E5%BC%82%2F</url>
    <content type="text"><![CDATA[opencv gpu和cpu实现直方图均衡会出现不同，版本3.3.1，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace cv;using namespace std;void testCPU()&#123; //cpu cv::Mat src = imread("/home/ubuntu/Pictures/2.png"); //cv::resize(src, src, cv::Size(0, 0), 0.5, 0.5); vector&lt;Mat&gt; channels; split(src, channels); Mat B,G,R;//#pragma omp parallel sections &#123;//#pragma omp section &#123; equalizeHist( channels[0], B ); //GaussianBlur(B,B,Size(3, 3), 2.0); //B = (B+ channels[0]) / 2; //addWeighted(B, 0.5, channels[0], 0.5, 0, B); &#125;//#pragma omp section &#123; equalizeHist( channels[1], G ); //GaussianBlur(G,G,Size(3, 3), 2.0); //G = (G+ channels[1]) / 2; //addWeighted(G, 0.5, channels[1], 0.5, 0, G); &#125;//#pragma omp section &#123; equalizeHist( channels[2], R ); //GaussianBlur(R,R,Size(3, 3), 2.0); //R = (R+ channels[2]) / 2; //addWeighted(R, 0.5, channels[2], 0.5, 0, R); &#125; &#125; vector&lt;Mat&gt; combined; combined.push_back(B); combined.push_back(G); combined.push_back(R); Mat sample_single; merge(combined, sample_single); imwrite("cpu.jpg", sample_single); imshow("cpu", sample_single); //waitKey(0);&#125;void testGPU()&#123; //gpu cv::Mat src = imread("/home/ubuntu/Pictures/2.png"); //cv::resize(src, src, cv::Size(0, 0), 0.5, 0.5); cv::cuda::GpuMat gpu_src;// = cv::cuda::GpuMat(src.height, src.width, CV_8UC3, src.data); gpu_src.upload(src); std::vector&lt;cv::cuda::GpuMat&gt; channels; cv::cuda::split(gpu_src, channels); cv::cuda::GpuMat B, G, R; cv::cuda::equalizeHist(channels[0], B); cv::cuda::equalizeHist(channels[1], G); cv::cuda::equalizeHist(channels[2], R); //创建高斯滤波器 cv::Ptr&lt;cv::cuda::Filter&gt; gauss = cv::cuda::createGaussianFilter(CV_8UC1, CV_8UC1, Size(3, 3), 2.0); //高斯滤波 //gauss-&gt;apply(B, B); //gauss-&gt;apply(G, G); //gauss-&gt;apply(R, R);// cv::cuda::addWeighted(B, 0.5, channels[0], 0.5, 0, B);// cv::cuda::addWeighted(G, 0.5, channels[1], 0.5, 0, G);// cv::cuda::addWeighted(R, 0.5, channels[2], 0.5, 0, R); vector&lt;cv::cuda::GpuMat&gt; combined; combined.push_back(B); combined.push_back(G); combined.push_back(R); cv::cuda::GpuMat gpu_dst; cv::cuda::merge(combined, gpu_dst); Mat img; gpu_dst.download(img); imwrite("gpu.jpg", img); imshow("gpu", img); waitKey(0);&#125;int main()&#123; testCPU(); testGPU(); return 0;&#125; 原图 CPU GPU]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NVIDIA NPP LIBRARY SDK]]></title>
    <url>%2F2019%2F04%2F29%2FNVIDIA-NPP-LIBRARY-SDK%2F</url>
    <content type="text"><![CDATA[CUDA NPP库使用NPP库是英伟达提供的可用在实现GPU加速图像处理，详细SDK文档可以参考链接，主要包含的库如下： 12345678910111213141516171819202122//图像处理基础库，类似opencv corenppc NPP core library which MUST be included when linking any application, functions are listed in nppCore.h//算术逻辑操作nppial arithmetic and logical operation functions in nppi_arithmetic_and_logical_operations.h//颜色转换操作nppicc color conversion and sampling functions in nppi_color_conversion.h//图像压缩和解压nppicom JPEG compression and decompression functions in nppi_compression_functions.h//数据转换及初始化nppidei data exchange and initialization functions in nppi_data_exchange_and_initialization.h//滤波操作nppif filtering and computer vision functions in nppi_filter_functions.h//几何变换nppig geometry transformation functions found in nppi_geometry_transforms.h//形态学操作nppim morphological operation functions found in nppi_morphological_operations.h//统计及线性变换nppist statistics and linear transform in nppi_statistics_functions.h and nppi_linear_transforms.h//内存支持函数nppisu memory support functions in nppi_support_functions.h//阈值及比较操作nppitc threshold and compare operation functions in nppi_threshold_and_compare_operations.h 由于项目需求，这里主要介绍一些常用的操作，主要是opencv中基本图像处理操作，比如颜色空间转换，图像伸缩变换等等。 RESIZEresize操作支持单通道、３通道、４通道。8u、16u、16s、32f，接口一般是nppiResizeSqrPixel_ _ ，其中可以选择对感兴趣区域进行resize。这里需要注意的是resize的一些插值方式，和opencv不太一样，并且官方文档没有详细说明，导致有一些坑在里面。比如之前使用NPPI_INTER_SUPER插值方式的时候发现factor大于１的时候会出错。后面找到答案说NPPI_INTER_SUPER只支持降采样操作，参考链接。这里举个BGR进行通道转换的栗子： 12345678910111213141516171819202122232425262728293031323334353637383940bool imageResize_8u_C3R(void *src, int srcWidth, int srcHeight, void *dst, int dstWidth, int dstHeight)&#123; NppiSize oSrcSize; oSrcSize.width = srcWidth; oSrcSize.height = srcHeight; int nSrcStep = srcWidth * 3; NppiRect oSrcROI; oSrcROI.x = 0; oSrcROI.y = 0; oSrcROI.width = srcWidth; oSrcROI.height = srcHeight; int nDstStep = dstWidth * 3; NppiRect oDstROI; oDstROI.x = 0; oDstROI.y = 0; oDstROI.width = dstWidth; oDstROI.height = dstHeight; // Scale Factor double nXFactor = double(dstWidth) / (oSrcROI.width); double nYFactor = double(dstHeight) / (oSrcROI.height); // Scaled X/Y Shift double nXShift = - oSrcROI.x * nXFactor ; double nYShift = - oSrcROI.y * nYFactor; int eInterpolation = NPPI_INTER_SUPER; if (nXFactor &gt;= 1.f || nYFactor &gt;= 1.f) eInterpolation = NPPI_INTER_LANCZOS; NppStatus ret = nppiResizeSqrPixel_8u_C3R((const Npp8u *)src, oSrcSize, nSrcStep, oSrcROI, (Npp8u *)dst, nDstStep, oDstROI, nXFactor, nYFactor, nXShift, nYShift, eInterpolation ); if(ret != NPP_SUCCESS) &#123; printf("imageResize_8u_C3R failed %d.\n", ret); return false; &#125; return true;&#125; resize库包含在nppig库里面，其中还有各种操作，包括mirror、remap、rotate、warp等等，这些在平常使用过程中比较少用到，需要用的时候再参考文档。 ## 颜色转换 自己实现一些操作padding123456789101112131415161718192021222324252627__global__ void imagePaddingKernel(float3 *ptr, float3 *dst, int width, int height, int top, int bottom, int left, int right)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if(x &lt; left || x &gt;= (width - right) || y &lt; top || y &gt; (height - bottom)) &#123; return; &#125; float3 color = ptr[(y - top) * (width - top - right) + (x - left)]; dst[y * width + x] = color;&#125;void imagePadding(const void *src, void *dst, int width, int height, int top, int bottom, int left, int right)&#123; int dstW = width + left + right; int dstH = height + top + bottom; cudaMemset(dst, 0, dstW * dstH * sizeof(float3)); dim3 grids((dstW + 31) / 32, (dstH + 31) / 32); dim3 blocks(32, 32); imagePaddingKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (float3 *)dst, dstW, dstH, top, bottom, left, right);&#125; split123456789101112131415161718192021__global__ void imageSplitKernel(float3 *ptr, float *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; float3 color = ptr[y * width + x]; dst[y * width + x] = color.x; dst[y * width + x + width * height] = color.y; dst[y * width + x + width * height * 2] = color.z;&#125;void imageSplit(const void *src, float *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); imageSplitKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (float *)dst, width, height);&#125; normalization12345678910111213141516171819202122__global__ void imageNormalizationKernel(float3 *ptr, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; float3 color = ptr[y * width + x]; color.x = (color.x - 127.5) * 0.0078125; color.y = (color.y - 127.5) * 0.0078125; color.z = (color.z - 127.5) * 0.0078125; ptr[y * width + x] = make_float3(color.x, color.y, color.z);&#125;void imageNormalization(void *ptr, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); imageNormalizationKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)ptr, width, height);&#125; BGR2RGBfloat123456789101112131415161718__global__ void convertBGR2RGBfloatKernel(uchar3 *src, float3 *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar3 color = src[y * width + x]; dst[y * width + x] = make_float3(color.z, color.y, color.x);&#125;void convertBGR2RGBfloat(void *src, void *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); convertBGR2RGBfloatKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((uchar3 *)src, (float3 *)dst, width, height);&#125; RGBA2Gray12345678910111213141516171819202122__global__ void convertRGBA2GrayKernel(uchar4 *src, uchar1 *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar4 color = src[y * width + x]; //dst[y * width + x] = make_uchar1((color.x+color.y+color.z) * .333333f); dst[y * width + x] = make_uchar1(0.114f * color.x + 0.587f * color.y + 0.299f * color.z);&#125;void convertRGBA2Gray(void *src, void *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); convertRGBA2GrayKernel&lt;&lt;&lt;grids, blocks, 0, stream&gt;&gt;&gt;((uchar4 *)src, (uchar1 *)dst, width, height);// cudaDeviceSynchronize(); cudaStreamSynchronize(stream);&#125; RGBA2BGR123456789101112131415161718__global__ void convertRGBA2BGRKernel(uchar4 *src, uchar3 *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar4 color = src[y * width + x]; dst[y * width + x] = make_uchar3(color.z, color.y, color.x);&#125;void convertRGBA2BGR(void *src, void *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); convertRGBA2BGRKernel&lt;&lt;&lt;grids, blocks, 0, stream&gt;&gt;&gt;((uchar4 *)src, (uchar3 *)dst, width, height);&#125; TX2 nvx实现RGBA2YUVI42012345678910111213141516171819202122232425262728293031323334353637383940void convertRGBA2YUVI420(void *src, void *dst, int width, int height)&#123; static bool inited = false; static nvxcu_stream_exec_target_t exec_target; if (!inited) &#123; int deviceID; /*HANDLE_CUDA_ERROR*/(cudaGetDevice(&amp;deviceID)); exec_target.base.exec_target_type = NVXCU_STREAM_EXEC_TARGET; exec_target.stream = NULL; /*HANDLE_CUDA_ERROR*/(cudaGetDeviceProperties(&amp;exec_target.dev_prop, deviceID)); inited = true; &#125; nvxcu_pitch_linear_image_t input, output; input.base.format = NVXCU_DF_IMAGE_RGBX; input.base.width = width; input.base.height = height; input.base.image_type = NVXCU_PITCH_LINEAR_IMAGE; input.planes[0].dev_ptr = src; input.planes[0].pitch_in_bytes = width * 4; output.base.format = NVXCU_DF_IMAGE_IYUV; output.base.width = width; output.base.height = height; output.base.image_type = NVXCU_PITCH_LINEAR_IMAGE; output.planes[0].dev_ptr = dst; output.planes[0].pitch_in_bytes = width; output.planes[1].dev_ptr = (char *)dst + width * height; output.planes[1].pitch_in_bytes = width / 2; output.planes[2].dev_ptr = (char *)dst + width * height * 5 / 4; output.planes[2].pitch_in_bytes = width / 2; nvxcu_error_status_e stat; stat = nvxcuColorConvert(&amp;input.base, &amp;output.base, NVXCU_COLOR_SPACE_DEFAULT, NVXCU_CHANNEL_RANGE_FULL, &amp;exec_target.base); if (stat != NVXCU_SUCCESS) &#123; dbgInfo("Conver RGB to YUVI420 failed: %d.\n", stat); &#125;&#125; 叠加图片1234567891011121314151617181920212223__global__ void cudaPutLogoToImageKernel(uchar4 *devImg, int imgWidth, int imgHeight, uchar3 *devLogo, int width, int height, int offsetX, int offsetY)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar3 devLogoColor = devLogo[y * width + x]; int offset = (y + offsetY) * imgWidth + offsetX + x; devImg[offset] = make_uchar4(devLogoColor.z, devLogoColor.y, devLogoColor.x, 0);&#125;void cudaPutLogoToImage(void *devImg, int imgWidth, int imgHeight, void *devLogo, int width, int height, int offsetX, int offsetY, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); //if use stream, every time the result will be error. have to test!!! cudaPutLogoToImageKernel&lt;&lt;&lt;grids, blocks, 0, stream&gt;&gt;&gt;((uchar4 *)devImg, imgWidth, imgHeight, (uchar3 *)devLogo, width, height, offsetX, offsetY);&#125; ## 参考链接 官网地址]]></content>
      <categories>
        <category>NVIDIA</category>
      </categories>
      <tags>
        <tag>NPP</tag>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch学习之路]]></title>
    <url>%2F2019%2F04%2F13%2FPyTorch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[参考文档 1. 基础概念PyTorch类似于Numpy。它的优点在于可以充分利用GPU资源。它是一个深度学习框架，提供最大的灵活性和速度。 1.1 张量概念12345678910111213141516171819202122232425262728from __future__ import print_functionimport torch# 构造未初始化5x3的矩阵x = torch.empty(5, 3)print(x)# 构造随机初始化矩阵x = torch.rand(5, 3)print(x)# 构造0矩阵，数据类型为longx = torch.zeros(5, 3, dtype=torch.long)print(x)# 直接用数据构造一个张量x = torch.tensor([5.5, 3])print(x)# 基于存在的张量构造，可以使用存在的张量的一些属性，比如数据类型，数据纬度，除非手动修改x = x.new_ones(5, 3, dtype=torch.double) # new_* methods take in sizesprint(x)x = torch.randn_like(x, dtype=torch.float) # override dtype!print(x) # result has the same size# 获取张量大小.实际上torch.Size是一个元组类型，支持元组所有操作print(x.size()) 1.2 张量操作关于张量的操作有100多种，包括转置、索引、切片、数值计算、线性代数、随机数等等。 123456789101112131415161718192021222324252627282930# 加法1y = torch.rand(5, 3)print(x + y)# 加法2print(torch.add(x, y))# 输出张量作为参数result = torch.empty(5, 3)torch.add(x, y, out=result)print(result)# 原地（in-place）加法# adds x to yy.add_(x)print(y)# 以 _ 作为后缀将会改变操作数，比如x.copy_(y), x.t_(),都会改变x的值# 可以像Numpy一样索引print(x[:, 1])# resize和reshape操作可以使用torch.viewx = torch.randn(4, 4)y = x.view(16)z = x.view(-1, 8) # the size -1 is inferred from other dimensionsprint(x.size(), y.size(), z.size())# 如果你有一个只有一个元素的张量，可以使用.item()获取数值x = torch.randn(1)print(x)print(x.item()) 1.3 与Numpy互操作1234567891011121314# tensor转为Numpya = torch.ones(5)print(a)b = a.numpy()print(b)# Numpy转为tensorimport numpy as npa = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a)print(a)print(b) 1.4 CUDA 张量可以使用 .to 方法把张量拷贝到设备内存(GPU) 123456789# let us run this cell only if CUDA is available# We will use ``torch.device`` objects to move tensors in and out of GPUif torch.cuda.is_available():device = torch.device("cuda") # a CUDA device objecty = torch.ones_like(x, device=device) # directly create a tensor on GPUx = x.to(device) # or just use strings ``.to("cuda")``z = x + yprint(z)print(z.to("cpu", torch.double)) # ``.to`` can also change dtype together! 1.5 自动微分技术PyTorch中的反向传播中求导都是使用autograd包完成的。它提供了张量求导所有操作，它是一个define-by-run框架，意味着每一次反向传播都取决于你的代码是如何跑的，每一次迭代都可能不同。 torch.Tensor 是pytorch一个最基础的类。如果你设置其属性 .requires_grad 为 True, 它将会跟踪它所有的操作，当你调用.backward()时，会自动计算梯度，可以使用 .grad 获取梯度值。可以使用.detach()来停止跟踪历史或者阻止将来的操作。也可以使用with torch.no_grad():。 除了torch.Tensor 还有一个很重要的类来实现自动求导——Fucction。每一个张量（除了用户创建的之外）都有.grad_fn属性。 当想要计算导数的时候只要调用.backward()。当输出张量是一个标量的时候，不需要特别指明参数，然而如果是一个向量就需要指明gradient参数。 12345678910111213141516# 设置requires_grad为truex = torch.ones(2, 2, requires_grad=True)print(x)y = x + 2print(y)# 因为y是由操作得来的结果，所以有grad_fn属性print(y.grad_fn)z = y * y * 3out = z.mean()print(z, out)# 因为out输出为标量，相当于out.backward(torch.tensor(1.))out.backward()print(x.grad) 1.6 神经网络1.6.1 定义网络结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):def __init__(self):super(Net, self).__init__()# 1 input image channel, 6 output channels, 5x5 square convolution# kernelself.conv1 = nn.Conv2d(1, 6, 5)self.conv2 = nn.Conv2d(6, 16, 5)# an affine operation: y = Wx + bself.fc1 = nn.Linear(16 * 5 * 5, 120)self.fc2 = nn.Linear(120, 84)self.fc3 = nn.Linear(84, 10)def forward(self, x):# Max pooling over a (2, 2) windowx = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))# If the size is a square you can only specify a single numberx = F.max_pool2d(F.relu(self.conv2(x)), 2)x = x.view(-1, self.num_flat_features(x))x = F.relu(self.fc1(x))x = F.relu(self.fc2(x))x = self.fc3(x)return xdef num_flat_features(self, x):size = x.size()[1:] # all dimensions except the batch dimensionnum_features = 1for s in size:num_features *= sreturn num_featuresnet = Net()# 输出网络结构print(net)# 模型参数存在net.parameters()中params = list(net.parameters())print(len(params))print(params[0].size()) # conv1's .weight# 测试输入input = torch.randn(1, 1, 32, 32)out = net(input)print(out)# 模型梯度置0然后反向传播net.zero_grad()out.backward(torch.randn(1, 10)) 注：torch.nn只支持最小批量 1.6.2 损失函数1234567output = net(input)target = torch.randn(10) # a dummy target, for exampletarget = target.view(1, -1) # make it the same shape as outputcriterion = nn.MSELoss()loss = criterion(output, target)print(loss) 由此可以得出计算图： 1234input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d-&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear-&gt; MSELoss-&gt; loss 1.6.3 反向传播123456789net.zero_grad() # zeroes the gradient buffers of all parametersprint('conv1.bias.grad before backward')print(net.conv1.bias.grad)loss.backward()print('conv1.bias.grad after backward')print(net.conv1.bias.grad) 1.6.4 更新权重1234567891011import torch.optim as optim# create your optimizeroptimizer = optim.SGD(net.parameters(), lr=0.01)# in your training loop:optimizer.zero_grad() # zero the gradient buffersoutput = net(input)loss = criterion(output, target)loss.backward()optimizer.step() # Does the update 注：每次optimizer.zero_grad()需要手动置0，因为梯度是累积的。 1.7 训练一个分类器1.7.1 加载数据1234567891011121314151617181920import torchimport torchvisionimport torchvision.transforms as transformstransform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=2)classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck') 1.7.2 定义卷积神经网络12345678910111213141516171819202122232425import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):def __init__(self):super(Net, self).__init__()self.conv1 = nn.Conv2d(3, 6, 5)self.pool = nn.MaxPool2d(2, 2)self.conv2 = nn.Conv2d(6, 16, 5)self.fc1 = nn.Linear(16 * 5 * 5, 120)self.fc2 = nn.Linear(120, 84)self.fc3 = nn.Linear(84, 10)def forward(self, x):x = self.pool(F.relu(self.conv1(x)))x = self.pool(F.relu(self.conv2(x)))x = x.view(-1, 16 * 5 * 5)x = F.relu(self.fc1(x))x = F.relu(self.fc2(x))x = self.fc3(x)return xnet = Net() 1.7.3 定义损失函数和优化器1234import torch.optim as optimcriterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 1.7.4 训练网络123456789101112131415161718192021222324for epoch in range(2): # loop over the dataset multiple timesrunning_loss = 0.0for i, data in enumerate(trainloader, 0):# get the inputsinputs, labels = data# zero the parameter gradientsoptimizer.zero_grad()# forward + backward + optimizeoutputs = net(inputs)loss = criterion(outputs, labels)loss.backward()optimizer.step()# print statisticsrunning_loss += loss.item()if i % 2000 == 1999: # print every 2000 mini-batchesprint('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))running_loss = 0.0print('Finished Training') 1.7.5 测试1234567891011121314151617class_correct = list(0. for i in range(10))class_total = list(0. for i in range(10))with torch.no_grad():for data in testloader:images, labels = dataoutputs = net(images)_, predicted = torch.max(outputs, 1)c = (predicted == labels).squeeze()for i in range(4):label = labels[i]class_correct[label] += c[i].item()class_total[label] += 1for i in range(10):print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i])) 12345678910Accuracy of plane : 72 %Accuracy of car : 47 %Accuracy of bird : 41 %Accuracy of cat : 32 %Accuracy of deer : 42 %Accuracy of dog : 49 %Accuracy of frog : 70 %Accuracy of horse : 62 %Accuracy of ship : 46 %Accuracy of truck : 76 % 1.7.6 GPU训练12345678device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# Assuming that we are on a CUDA machine, this should print a CUDA device:print(device)net.to(device)inputs, labels = inputs.to(device), labels.to(device) 1.8 数据并行1234567891011# cuda设备device = torch.device("cuda:0")# 将模型移到GPUmodel.to(device)# 输入拷贝到GPUmytensor = my_tensor.to(device)# 设置数据并行model = nn.DataParallel(model) 2. 数据3. 模型4. 策略（损失函数）5. 算法]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>深度学习框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量配置]]></title>
    <url>%2F2019%2F04%2F02%2FLinux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[设置文件为:123456//全局设置文件/etc/profile//针对某个用户设置~/.bashrc` 设置PATH:1export PATH=/your/bin/path:$PATH 注意： PATH=中间不能有空格。 设置LD_LIBRARY_PATH:1export LD_LIBRARY_PATH=/your/lib/path:$LD_LIBRARY_PATH 另：也可以在/etc/ld.so.conf.d/ 下设置目录，然后调用ldconfig生效。 生效：123source ~/.bashrcorsource /etc/profile]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件之自定义数据结构]]></title>
    <url>%2F2019%2F04%2F01%2FGStreamer%E6%8F%92%E4%BB%B6%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[GstMeta当我们需要添加自定义的数据结构到GstBuffer中时，需要使用GstMeta自定义数据结构。GstMeta数据结构为：1234struct _GstMeta &#123; GstMetaFlags flags; const GstMetaInfo *info; /* tag and info for the meta item */&#125;; 其中 info 结构体为：123456789struct _GstMetaInfo &#123; GType api; //api 类型 GType type; //具体实现类型 gsize size; //自定义数据结构体大小 GstMetaInitFunction init_func; //初始化函数 GstMetaFreeFunction free_func; //释放函数 GstMetaTransformFunction transform_func; //转换函数&#125;; 其中api成员需要由gst_meta_api_type_register()函数注册生成，具体看下文实施例。 GstMeta是我们自定义数据结构体的公共头，比如gstreamer自带时间信息结构体：12345678struct _GstMetaTiming &#123; GstMeta meta; /* common meta header */ GstClockTime dts; /* decoding timestamp */ GstClockTime pts; /* presentation timestamp */ GstClockTime duration; /* duration of the data */ GstClockTime clock_rate; /* clock rate for the above values */&#125;; 自定义的数据结构体由字段或者方法组成。一个典型的buffer可能是如以下结构：1234567891011121314151617181920212223242526272829 +----------------------------------+GstMiniObject | GType (GstBuffer) | | refcount, flags, copy/disp/free | +----------------------------------+GstBuffer | pool,pts,dts,duration,offsets | | &lt;private data&gt; | +..................................+ | next ---+ +- | info ------&gt; GstMetaInfoGstMetaTiming | | | | | | dts | | | | pts | | | | duration | | +- | clock_rate | | + . . . . . . . . . . . . . . . . + | | next &lt;--+GstVideoMeta +- +- | info ------&gt; GstMetaInfo | | | | | | | | flags | | | | | n_planes | | | | | planes[] | | | | | map | | | | | unmap | | +- | | | | | | private fields | |GstVideoMetaImpl | | ... | | | | ... | | +- | | | + . . . . . . . . . . . . . . . . + . 自定义meta实现头文件123456789101112131415161718192021222324252627282930313233343536373839404142#ifndef GSTFACEPARAMMETA_H#define GSTFACEPARAMMETA_H#include "gst/gst.h"/** Defines GStreamer metadata types. *///定义枚举类型，用来指定meta_data指针所指向的数据类型typedef enum&#123; META_INIT = 0x0, FACE_PARAM,&#125; Meta_type;typedef struct _FaceParamMeta FaceParamMeta;//该结构体为要附加的元数据结构体struct _FaceParamMeta &#123; //公共头 GstMeta meta; //存储各种需要的自定义结构体，方便扩展 void *meta_data; //meta_data指针指向的结构体类型 int meta_type; //类似回调函数指针，在buffer销毁的时候会调用 GDestroyNotify destroy;&#125;;//注册api type的接口，返回api用于注册metaGType face_param_meta_api_get_type(void);#define FACE_PARAM_META_API_TYPE (face_param_meta_api_get_type())//注册meta的时候返回GstMetaInfoconst GstMetaInfo *face_param_meta_get_info(void);#define FACE_PARAM_META_INFO (face_param_meta_get_info())//往buffer中添加数据，返回FaceParamMeta*指针指向添加位置FaceParamMeta *gst_buffer_add_face_param_meta(GstBuffer *buffer, void *metadata, int metatype, GDestroyNotify destroy);//从buffer中获取自定义meta数据FaceParamMeta *gst_buffer_get_face_param_meta(GstBuffer *buffer);#endif // GSTFACEPARAMMETA_H 实现文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include "gstfaceparammeta.h"GType face_param_meta_api_get_type(void)&#123; static volatile GType type; //可以往api type加入标签，使用gst_meta_api_type_has_tag查找是否由我们自定义结构体 static const gchar *tags[] = &#123;"face", "detect", NULL&#125;; if(g_once_init_enter(&amp;type)) &#123; //注册api type GType _type = gst_meta_api_type_register("FaceParamMetaAPI", tags); g_once_init_leave(&amp;type, _type); &#125; return type;&#125;//初始化函数实现static gboolean face_param_meta_init(GstMeta *meta, gpointer params, GstBuffer *buffer)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; emeta-&gt;meta_type = META_INIT; emeta-&gt;meta_data = NULL; emeta-&gt;destroy = NULL; return TRUE;&#125;//转换函数实现，具体复杂情况下怎么用还需琢磨static gboolean face_param_meta_transform(GstBuffer *transbuf, GstMeta *meta, GstBuffer *buffer, GQuark type, gpointer data)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; gst_buffer_add_face_param_meta(transbuf, emeta-&gt;meta_data, emeta-&gt;meta_type, emeta-&gt;destroy); return TRUE;&#125;//释放函数static void face_param_meta_free(GstMeta *meta, GstBuffer *buffer)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; emeta-&gt;meta_type = META_INIT; //回调函数 emeta-&gt;destroy(emeta-&gt;meta_data);&#125;//注册我们的meta函数const GstMetaInfo *face_param_meta_get_info(void)&#123; static const GstMetaInfo *meta_info = NULL; if(g_once_init_enter(&amp;meta_info)) &#123; //注册返回GstMetaInfo //第二个参数可以在gst_meta_get_info（）函数使用 const GstMetaInfo *mi = gst_meta_register(FACE_PARAM_META_API_TYPE, "FaceParamMeta", sizeof(FaceParamMeta), face_param_meta_init, face_param_meta_free, face_param_meta_transform); g_once_init_leave(&amp;meta_info, mi); &#125; return meta_info;&#125;//增加数据FaceParamMeta *gst_buffer_add_face_param_meta(GstBuffer *buffer, void *metadata, int metatype, GDestroyNotify destroy)&#123; FaceParamMeta *meta; g_return_val_if_fail(GST_IS_BUFFER(buffer), NULL); meta = (FaceParamMeta *)gst_buffer_add_meta(buffer, FACE_PARAM_META_INFO, NULL); //指针简单赋值，需要注意外面传进来的指针必须不是局部变量，否则会自动释放 meta-&gt;meta_data = metadata; //meta_data指向类型 meta-&gt;meta_type = metatype; //回调函数，在free的时候使用 meta-&gt;destroy = destroy; return meta;&#125;//获取数据FaceParamMeta *gst_buffer_get_face_param_meta(GstBuffer *buffer)&#123; FaceParamMeta *meta; meta = (FaceParamMeta *)gst_buffer_get_meta(buffer, FACE_PARAM_META_API_TYPE); return meta;&#125; 具体使用调用添加数据函数1faceParamMeta = gst_buffer_add_face_param_meta(outbuf, metadata, FACE_PARAM, free_face_param_meta); 释放函数为：12345678910/** * Free the metadata allocated in attach_metadata_full_frame */static voidfree_face_param_meta (gpointer meta_data)&#123; g_print ("free output buffer, free output buffer.\n"); MtcnnPluginOutput *output = (MtcnnPluginOutput *)meta_data; g_free(output);&#125; 获取数据可以使用如下方法：方法1：直接调用我们自己定义的函数1metadata = gst_buffer_get_face_param_meta(); 方法2：因为我们可能在不同的element中添加很多个自定义数据结构，使用方法1只能取到最后一个添加的，需要使用以下方法进行遍历：123456static GQuark _ivameta_quark = 0;if (!_ivameta_quark) &#123; //注意参数时我们注册api type时添加的tag //类似键值对 _ivameta_quark = g_quark_from_static_string ("face");&#125; 1234567891011121314151617181920212223GstMeta *gst_meta;// Standard way of iterating through buffer metadatawhile ((gst_meta = gst_buffer_iterate_meta (outbuf, &amp;state)) != NULL) &#123; //可以获取GstMetaInfo，注意参数需要和注册时一致 const GstMetaInfo *info = gst_meta_get_info("FaceParamMeta"); //查询是否有我们想要的api type if (!gst_meta_api_type_has_tag (gst_meta-&gt;info-&gt;api, _ivameta_quark)) &#123; continue; &#125; //如果是，转成我们的结构体 ivameta = (FaceParamMeta *) gst_meta; // Check if the metadata of IvaMeta contains object bounding boxes if (ivameta-&gt;meta_type != FACE_PARAM) continue; //根据meta_type获取具体数据 meta_data = (MtcnnPluginOutput *) ivameta-&gt;meta_data;&#125; 参考官网链接:GstMetaMemory allocation]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019学习计划]]></title>
    <url>%2F2019%2F03%2F31%2F2019%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件编写学习]]></title>
    <url>%2F2019%2F03%2F29%2FGStreamer%E6%8F%92%E4%BB%B6%E7%BC%96%E5%86%99%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[下载插件模板1234567shell $ git clone https://gitlab.freedesktop.org/gstreamer/gst-template.gitInitialized empty Git repository in /some/path/gst-template/.git/remote: Counting objects: 373, done.remote: Compressing objects: 100% (114/114), done.remote: Total 373 (delta 240), reused 373 (delta 240)Receiving objects: 100% (373/373), 75.16 KiB | 78 KiB/s, done.Resolving deltas: 100% (240/240), done. 以上方案有点过时，可到github下载gst-plugins-bad模块，使用里面的工具生成模板。 使用make_element生成模板12cd gst-template/gst-plugin/src../tools/make_element MyFilter &lt;基类文件如:gsttransform&gt; 修改makefile.am文件12345678910111213141516171819202122# Note: plugindir is set in configure############################################################################### TODO: change libgstplugin.la to something else, e.g. libmysomething.la ###############################################################################plugin_LTLIBRARIES = libgstplugin.la libgstaudiofilterexample.la############################################################################### TODO: for the next set of variables, name the prefix if you named the .la, ## e.g. libmysomething.la =&gt; libmysomething_la_SOURCES ## libmysomething_la_CFLAGS ## libmysomething_la_LIBADD ## libmysomething_la_LDFLAGS ################################################################################# Plugin 1# sources used to compile this plug-inlibgstplugin_la_SOURCES = gstplugin.c gstplugin.h# compiler and linker flags used to compile this plugin, set in configure.aclibgstplugin_la_CFLAGS = $(GST_CFLAGS)libgstplugin_la_LIBADD = $(GST_LIBS)libgstplugin_la_LDFLAGS = $(GST_PLUGIN_LDFLAGS)libgstplugin_la_LIBTOOLFLAGS = --tag=disable-static# headers we need but don&apos;t want installednoinst_HEADERS = gstplugin.h 生成makefile文件123./autogen.shmakesudo make install 注意：需要修改configure.ac文件里面安装的路径，不然插件会被安装到/usr/local/lib/gstreamer-1.0中 Example Demo1234567891011121314151617181920212223242526#include &lt;gst/gst.h&gt;/* Definition of structure storing data for this element. */typedef struct _GstMyFilter &#123; GstElement element; GstPad *sinkpad, *srcpad; gboolean silent;&#125; GstMyFilter; /* Standard definition defining a class for this element. */typedef struct _GstMyFilterClass &#123; GstElementClass parent_class;&#125; GstMyFilterClass;/* Standard macros for defining types for this element. */#define GST_TYPE_MY_FILTER (gst_my_filter_get_type())#define GST_MY_FILTER(obj) \ (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_MY_FILTER,GstMyFilter))#define GST_MY_FILTER_CLASS(klass) \ (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_MY_FILTER,GstMyFilterClass))#define GST_IS_MY_FILTER(obj) \ (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_MY_FILTER))#define GST_IS_MY_FILTER_CLASS(klass) \ (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_MY_FILTER)) /* Standard function returning type information. */GType gst_my_filter_get_type (void); Element metadata元素元数据提供额外的元素信息，使用gst_element_class_set_metadata或者gst_element_class_set_static_metadata函数来设置，其参数包含： A long, English, name for the element. The type of the element, see the docs/design/draft-klass.txt documentin the GStreamer core source tree for details and examples. A brief description of the purpose of the element. The name of the author of the element, optionally followed by acontact email address in angle brackets.例如：12345gst_element_class_set_static_metadata (klass,"An example plugin","Example/FirstExample","Shows the basic structure of a plugin","your name &lt;your.name@your.isp&gt;"); 以上函数在初始化_class_init ()插件的时候调用123456789101112static voidgst_my_filter_class_init (GstMyFilterClass * klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_set_static_metadata (element_klass, "An example plugin", "Example/FirstExample", "Shows the basic structure of a plugin", "your name &lt;your.name@your.isp&gt;");&#125; GstStaticPadTemplateGstStaticPadTemplate是用来描述将要创建的pad的信息，包含: A short name for the pad. Pad direction. Existence property. This indicates whether the pad exists always (an “always” pad), only in some cases (a “sometimes” pad) or only if the application requested such a pad (a “request” pad). Supported types by this element (capabilities).例如：1234567static GstStaticPadTemplate sink_factory =GST_STATIC_PAD_TEMPLATE ( "sink", //名称 GST_PAD_SINK, //方向sink or src GST_PAD_ALWAYS, //availability GST_STATIC_CAPS ("ANY") //capability); 同样该sink_factory也是在初始化时候使用，通过gst_element_class_add_pad_template ()和gst_static_pad_template_get ()来调用1234567891011121314static GstStaticPadTemplate sink_factory = [..], src_factory = [..];static voidgst_my_filter_class_init (GstMyFilterClass * klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;src_factory)); gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;sink_factory));&#125; 该pad将在构造函数_init ()函数中使用gst_pad_new_from_static_template ()来创建。 注：对于每个element来说，有两个构造函数，其中_class_init()函数只调用一次，用来说明类所拥有的信号、参数、虚函数以及设置全局状态；_init()函数则用在初始化实例特定的实例。 插件初始化函数当我们写完插件的所有部件之后，需要编写插件的初始化函数，这个函数在插件加载的时候调用，需要返回TRUE or FALSE来觉得是否正确加载。在这个函数中，任何支持的element插件应该被注册。12345678910111213141516171819static gbooleanplugin_init (GstPlugin *plugin)&#123; return gst_element_register (plugin, "my_filter", GST_RANK_NONE, GST_TYPE_MY_FILTER);&#125;GST_PLUGIN_DEFINE ( GST_VERSION_MAJOR, GST_VERSION_MINOR, my_filter, "My filter plugin", plugin_init, VERSION, "LGPL", "GStreamer", "http://gstreamer.net/") pads具体说明PADS是数据流进出每个element的端口，在初始化_init ()函数中，你从pad template中创建了一个pad，这个pad template是在_class_init ()函数中注册的，创建了pad之后，你必须在sinkpad设置_chain ()函数指针用来接收和处理数据。可选的，你也可以设置_event ()和_query ()指针；pad亦可以使用循环模式，这意味着它们可以自己拉取数据。1234567891011121314151617181920static voidgst_my_filter_init (GstMyFilter *filter)&#123; /* pad through which data comes in to the element */ filter-&gt;sinkpad = gst_pad_new_from_static_template ( &amp;sink_template, "sink"); /* pads are configured here with gst_pad_set_*_function () */ gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;sinkpad); /* pad through which data goes out of the element */ filter-&gt;srcpad = gst_pad_new_from_static_template ( &amp;src_template, "src"); /* pads are configured here with gst_pad_set_*_function () */ gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;srcpad); /* properties initial value */ filter-&gt;silent = FALSE; &#125; Sometimes PadSometimes pad 只有在一些特定情况下才创建，这取决于流内容。比如demuxers解析流头。每个element可以创建多个sometimes pad，唯一限制就是都要有唯一的名字。当流数据被销毁时（比如从PAUSED到READY状态），pad也应该被销毁，但是在EOS状态不应该被销毁。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146typedef struct _GstMyFilter &#123;[..] gboolean firstrun; GList *srcpadlist;&#125; GstMyFilter;//静态目标类型sometimesstatic GstStaticPadTemplate src_factory =GST_STATIC_PAD_TEMPLATE ( "src_%u", GST_PAD_SRC, GST_PAD_SOMETIMES, GST_STATIC_CAPS ("ANY"));static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..]//注册pad gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;src_factory));[..]&#125;static voidgst_my_filter_init (GstMyFilter *filter)&#123;[..] filter-&gt;firstrun = TRUE; filter-&gt;srcpadlist = NULL;&#125;/* * Get one line of data - without newline. */static GstBuffer *gst_my_filter_getline (GstMyFilter *filter)&#123; guint8 *data; gint n, num; /* max. line length is 512 characters - for safety */ for (n = 0; n &lt; 512; n++) &#123; num = gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n + 1); if (num != n + 1) return NULL; /* newline? */ if (data[n] == '\n') &#123; GstBuffer *buf = gst_buffer_new_allocate (NULL, n + 1, NULL); gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n); gst_buffer_fill (buf, 0, data, n); gst_buffer_memset (buf, n, '\0', 1); gst_bytestream_flush_fast (filter-&gt;bs, n + 1); return buf; &#125; &#125;&#125;static voidgst_my_filter_loopfunc (GstElement *element)&#123; GstMyFilter *filter = GST_MY_FILTER (element); GstBuffer *buf; GstPad *pad; GstMapInfo map; gint num, n; /* parse header */ if (filter-&gt;firstrun) &#123; gchar *padname; guint8 id; if (!(buf = gst_my_filter_getline (filter))) &#123; gst_element_error (element, STREAM, READ, (NULL), ("Stream contains no header")); return; &#125; gst_buffer_extract (buf, 0, &amp;id, 1); num = atoi (id); gst_buffer_unref (buf); /* for each of the streams, create a pad */ //根据头的流个数，创建num个pad for (n = 0; n &lt; num; n++) &#123; padname = g_strdup_printf ("src_%u", n); pad = gst_pad_new_from_static_template (src_factory, padname); g_free (padname); /* here, you would set _event () and _query () functions */ /* need to activate the pad before adding */ gst_pad_set_active (pad, TRUE); gst_element_add_pad (element, pad); filter-&gt;srcpadlist = g_list_append (filter-&gt;srcpadlist, pad); &#125; &#125; /* and now, simply parse each line and push over */ if (!(buf = gst_my_filter_getline (filter))) &#123; GstEvent *event = gst_event_new (GST_EVENT_EOS); GList *padlist; for (padlist = srcpadlist; padlist != NULL; padlist = g_list_next (padlist)) &#123; pad = GST_PAD (padlist-&gt;data); gst_pad_push_event (pad, gst_event_ref (event)); &#125; gst_event_unref (event); /* pause the task here */ return; &#125; /* parse stream number and go beyond the ':' in the data */ gst_buffer_map (buf, &amp;map, GST_MAP_READ); num = atoi (map.data[0]); if (num &gt;= 0 &amp;&amp; num &lt; g_list_length (filter-&gt;srcpadlist)) &#123; //取第N个pad塞数据 pad = GST_PAD (g_list_nth_data (filter-&gt;srcpadlist, num); /* magic buffer parsing foo */ for (n = 0; map.data[n] != ':' &amp;&amp; map.data[n] != '\0'; n++) ; if (map.data[n] != '\0') &#123; GstBuffer *sub; /* create region copy that starts right past the space. The reason * that we don't just forward the data pointer is because the * pointer is no longer the start of an allocated block of memory, * but just a pointer to a position somewhere in the middle of it. * That cannot be freed upon disposal, so we'd either crash or have * a memleak. Creating a region copy is a simple way to solve that. */ sub = gst_buffer_copy_region (buf, GST_BUFFER_COPY_ALL, n + 1, map.size - n - 1); gst_pad_push (pad, sub); &#125; &#125; gst_buffer_unmap (buf, &amp;map); gst_buffer_unref (buf);&#125; Request padRequest pad 只有在外部需要的时候才创建而不是element内部。比如tee element可以根据需要拷贝多份数据到不同的分支。需要实现request_new_pad和release_pad两个虚函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static GstPad * gst_my_filter_request_new_pad (GstElement *element, GstPadTemplate *templ, const gchar *name, const GstCaps *caps);static void gst_my_filter_release_pad (GstElement *element, GstPad *pad);static GstStaticPadTemplate sink_factory =GST_STATIC_PAD_TEMPLATE ( "sink_%u", GST_PAD_SINK, GST_PAD_REQUEST, GST_STATIC_CAPS ("ANY"));static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_add_pad_template (klass, gst_static_pad_template_get (&amp;sink_factory));[..] element_class-&gt;request_new_pad = gst_my_filter_request_new_pad; element_class-&gt;release_pad = gst_my_filter_release_pad;&#125;static GstPad *gst_my_filter_request_new_pad (GstElement *element, GstPadTemplate *templ, const gchar *name, const GstCaps *caps)&#123; GstPad *pad; GstMyFilterInputContext *context; context = g_new0 (GstMyFilterInputContext, 1); pad = gst_pad_new_from_template (templ, name); gst_pad_set_element_private (pad, context); /* normally, you would set _chain () and _event () functions here */ gst_element_add_pad (element, pad); return pad;&#125;static voidgst_my_filter_release_pad (GstElement *element, GstPad *pad)&#123; GstMyFilterInputContext *context; context = gst_pad_get_element_private (pad); g_free (context); gst_element_remove_pad (element, pad);&#125; The chain functionchain函数是处理数据的地方，记住buffers并不总是可写的。123456789101112131415161718192021222324252627282930static GstFlowReturn gst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf);[..]static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] /* configure chain function on the pad before adding * the pad to the element */ gst_pad_set_chain_function (filter-&gt;sinkpad, gst_my_filter_chain);[..]&#125;static GstFlowReturngst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); if (!filter-&gt;silent) g_print ("Have data of size %" G_GSIZE_FORMAT" bytes!\n", gst_buffer_get_size (buf)); return gst_pad_push (filter-&gt;srcpad, buf);&#125; The event function在一些高级的element中，需要设置event处理函数。它通知一些发生在数据流中的特定事件，比如（caps, end-of-stream, newsegment, tags, etc.），事件可以传播到上游和下游，所以你可以在sink pads和source pads接收到。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] gst_pad_set_event_function (filter-&gt;sinkpad, gst_my_filter_sink_event);[..]&#125;static gbooleangst_my_filter_sink_event (GstPad *pad, GstObject *parent, GstEvent *event)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); switch (GST_EVENT_TYPE (event)) &#123; case GST_EVENT_CAPS: /* we should handle the format here */ break; case GST_EVENT_EOS: /* end-of-stream, we should close down all stream leftovers here */ gst_my_filter_stop_processing (filter); break; default: break; &#125; return gst_pad_event_default (pad, parent, event);&#125;static GstFlowReturngst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); GstBuffer *outbuf; outbuf = gst_my_filter_process_data (filter, buf); gst_buffer_unref (buf); if (!outbuf) &#123; /* something went wrong - signal an error */ GST_ELEMENT_ERROR (GST_ELEMENT (filter), STREAM, FAILED, (NULL), (NULL)); return GST_FLOW_ERROR; &#125; return gst_pad_push (filter-&gt;srcpad, outbuf);&#125; The query function通过query函数，element可以接收查询事件并作出回复，比如（position, duration，supported formats，scheduling modes）。查询同样可以传播到上下游，你可以在sink pads和source pads接收到。123456789101112131415161718192021222324252627282930313233343536373839404142434445static gboolean gst_my_filter_src_query (GstPad *pad, GstObject *parent, GstQuery *query);[..]static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] /* configure event function on the pad before adding * the pad to the element */ gst_pad_set_query_function (filter-&gt;srcpad, gst_my_filter_src_query);[..]&#125;static gbooleangst_my_filter_src_query (GstPad *pad, GstObject *parent, GstQuery *query)&#123; gboolean ret; GstMyFilter *filter = GST_MY_FILTER (parent); switch (GST_QUERY_TYPE (query)) &#123; case GST_QUERY_POSITION: /* we should report the current position */ [...] break; case GST_QUERY_DURATION: /* we should report the duration here */ [...] break; case GST_QUERY_CAPS: /* we should report the supported caps here */ [...] break; default: /* just call the default handler */ ret = gst_pad_query_default (pad, parent, query); break; &#125; return ret;&#125; element状态状态可以用来描述element是否初始化，是否准备传送数据，是否正在处理数据。 GST_STATE_NULL element默认状态，不分配任何资源，不加载任何库。 GST_STATE_READY 分配默认资源(runtime-libraries, runtime-memory)，不分配或者定义stream-specific相关的资源，当状态从NULL到READY时，分配任何non-stream-specific资源，加载运行时库。当状态从READY转到NULL时，卸载相关资源，比如硬件设备。注意文件也是流，所以在READY状态下不会分配。 GST_STATE_PAUSED element准备接收和处理数据，对于大部分elements来说PAUSED和PLAYING是一样的，唯一的区别是sink elements，它只接收一次数据然后阻塞住，这时候pipeline处于’prerolled’状态，准备渲染数据。 GST_STATE_PLAYING 在播放状态下sink elements渲染接收的数据，其他elements和PAUSED状态一样。 管理filter状态一般来说，elements继承一些基类，比如sources, sinks and filter/transformation elements。如果是继承这些基类，你就不需要亲自处理状态的改变。你只需继承基类的虚函数start()和stop()。如果不是继承基类，而是继承GstElement，你就必须自己处理状态的改变，比如像demuxer和muxer这种插件。通过虚函数，element可以被通知状态的改变然后初始化必要数据，也可以选择状态改变失败。 注意，向上（NULL =&gt; READY，READY =&gt; PAUSED，PAUSED =&gt; PLAYING）和向下（PLAYING =&gt; PAUSED，PAUSED =&gt; READY，READY =&gt; NULL）状态更改在两个单独的块中处理，向下状态发生变化只有在我们链接到父类的状态更改函数之后才会处理。这是为了安全地处理多个线程的并发访问所必需的。123456789101112131415161718192021222324252627282930313233343536373839404142static GstStateChangeReturngst_my_filter_change_state (GstElement *element, GstStateChange transition);static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass); element_class-&gt;change_state = gst_my_filter_change_state;&#125;static GstStateChangeReturngst_my_filter_change_state (GstElement *element, GstStateChange transition)&#123; GstStateChangeReturn ret = GST_STATE_CHANGE_SUCCESS; GstMyFilter *filter = GST_MY_FILTER (element); switch (transition) &#123; case GST_STATE_CHANGE_NULL_TO_READY: if (!gst_my_filter_allocate_memory (filter)) return GST_STATE_CHANGE_FAILURE; break; default: break; &#125; ret = GST_ELEMENT_CLASS (parent_class)-&gt;change_state (element, transition); if (ret == GST_STATE_CHANGE_FAILURE) return ret; switch (transition) &#123; case GST_STATE_CHANGE_READY_TO_NULL: gst_my_filter_free_memory (filter); break; default: break; &#125; return ret;&#125; 增加属性通过属性可以控制element的行为。属性在_class_init ()函数中定义，在_get_property ()和a _set_property ()函数中设置或者获取。可以在_init ()构造函数中初始化属性值。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/* properties */enum &#123; PROP_0, PROP_SILENT /* FILL ME */&#125;;static void gst_my_filter_set_property (GObject *object, guint prop_id, const GValue *value, GParamSpec *pspec);static void gst_my_filter_get_property (GObject *object, guint prop_id, GValue *value, GParamSpec *pspec);static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GObjectClass *object_class = G_OBJECT_CLASS (klass); /* define virtual function pointers */ object_class-&gt;set_property = gst_my_filter_set_property; object_class-&gt;get_property = gst_my_filter_get_property; /* define properties */ g_object_class_install_property (object_class, PROP_SILENT, g_param_spec_boolean ("silent", "Silent", "Whether to be very verbose or not", FALSE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));&#125;static voidgst_my_filter_set_property (GObject *object, guint prop_id, const GValue *value, GParamSpec *pspec)&#123; GstMyFilter *filter = GST_MY_FILTER (object); switch (prop_id) &#123; case PROP_SILENT: filter-&gt;silent = g_value_get_boolean (value); g_print ("Silent argument was changed to %s\n", filter-&gt;silent ? "true" : "false"); break; default: G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec); break; &#125;&#125;static voidgst_my_filter_get_property (GObject *object, guint prop_id, GValue *value, GParamSpec *pspec)&#123; GstMyFilter *filter = GST_MY_FILTER (object); switch (prop_id) &#123; case PROP_SILENT: g_value_set_boolean (value, filter-&gt;silent); break; default: G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec); break; &#125;&#125; 两种调度模式Gstreamer 有两种调度模式 push mode pull mode 我们之前讨论的_chain ()函数属于push mode，通过调用gst_pad_push ()，使得下游的element的_chain ()被调用。 后续补充]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件之Transform elements]]></title>
    <url>%2F2019%2F03%2F29%2FGStreamer%E6%8F%92%E4%BB%B6%E4%B9%8BTransform-elements%2F</url>
    <content type="text"><![CDATA[前言写了个gstreamer插件继承于基类Transform element. 其中有些概念需要理解一下，特此做下笔记。参考官网链接 Transform elements基于sink和src pad的caps将输入的buffer转换为输出buffer。而输出的caps完全由输入的caps所定义，这表明像解码器这种组件不能够由Transform elements来实现，因为其输出的视频帧的宽高在输入时是被压缩在流当中的，所以输入是没有宽高这种属性的。如下所示的avdec_h264解码组件所示：12345678910111213141516171819202122232425Pad Templates: SRC template: 'src' Availability: Always Capabilities: video/x-raw format: &#123; (string)I420, (string)YUY2, (string)RGB, (string)BGR, (string)Y42B, (string)Y444, (string)YUV9, (string)Y41B, (string)GRAY8, (string)RGB8P, (string)I420, (string)Y42B, (string)Y444, (string)UYVY, (string)NV12, (string)NV21, (string)ARGB, (string)RGBA, (string)ABGR, (string)BGRA, (string)GRAY16_BE, (string)GRAY16_LE, (string)A420, (string)RGB16, (string)RGB15, (string)I420_10BE, (string)I420_10LE, (string)I422_10BE, (string)I422_10LE, (string)Y444_10BE, (string)Y444_10LE, (string)GBR, (string)GBR_10BE, (string)GBR_10LE, (string)A420_10BE, (string)A420_10LE, (string)A422_10BE, (string)A422_10LE, (string)A444_10BE, (string)A444_10LE, (string)GBRA, (string)xRGB, (string)RGBx, (string)xBGR, (string)BGRx, (string)I420_12BE, (string)I420_12LE, (string)I422_12BE, (string)I422_12LE, (string)Y444_12BE, (string)Y444_12LE, (string)GBR_12BE, (string)GBR_12LE, (string)GBRA_12BE, (string)GBRA_12LE &#125; SINK template: 'sink' Availability: Always Capabilities: video/x-h264 alignment: au stream-format: &#123; (string)avc, (string)byte-stream &#125; 典型transform elements包含： audio convertors (audioconvert, audioresample,…) video convertors (colorspace, videoscale, …) filters (capsfilter, volume, colorbalance, …) 要实现transform elements必须关心的是： efficient negotiation both up and downstream efficient buffer alloc and other buffer management transform elements可以使用不同模式： passthrough (no changes are done on the input buffers) in-place (changes made directly to the incoming buffers without requiring a copy or new buffer allocation) metadata changes only transform元素通常也会处理以下事项： flushing, seeking state changes timestamping, this is typically done by copying the input timestamps to the output buffers but subclasses should be able to override this. QoS, avoiding calls to the subclass transform function handle scheduling issues such as push and pull based operation. transform element应在任何时候可以重新协商sink和src caps，并改变操作模式。根据不同的模式，buffer的分配可能采用不同策略。 transform element behaviourProcessingtransform主要由两种处理函数： transform(): Transform the input buffer to the output buffer. The output buffer is guaranteed to be writable and different from the input buffer. transform_ip(): Transform the input buffer in-place. The input buffer is writable and of bigger or equal size than the output buffer. 转换操作有以下模式： passthrough: The element will not make changes to the buffers, buffers are pushed straight through, caps on both sides need to be the same. The element can optionally implement a transform_ip() function to take a look at the data, the buffer does not have to be writable. in-place: Changes can be made to the input buffer directly to obtain the output buffer. The transform must implement a transform_ip() function. copy-transform: The transform is performed by copying and transforming the input buffer to a new output buffer. The transform must implement a transform() function. 当没有使用transform()函数的时候，只有in-place 和 passthrough模式可以使用，这意味着sinkpad和srcpad要一样或者src buffer大于等于sink buffer。 当没有使用transform_ip()函数的时候，只允许passthrough和copy-transforms两种模式，提供这个函数可以避免内存的拷贝。 当没有使用以上两种函数时，只使用passthrough模式。 Negotiation在push mode下transform element的协商总是从sink到src： sinkpad接收到新的caps事件 transform函数算出它可以将此caps转化成什么 尝试不做任何修改，因为我们倾向于不做任何事情 transform配置自身使得可以将sink caps转换到模板src caps transform在srcpad上设置处理输出caps1234567 sinkpad transform srcpadCAPS event | | |------------&gt;| find_transform() | | |-------------------&gt;| | | | CAPS event | | |---------------------&gt;| | &lt;configure caps&gt; &lt;-| | transform 有三个函数执行协商： transform_caps(): Transform the caps on a certain pad to all the possible supported caps on the other pad. The input caps are guaranteed to be a simple caps with just one structure. The caps do not have to be fixed. fixate_caps(): Given a caps on one pad, fixate the caps on the other pad. The target caps are writable. set_caps(): Configure the transform for a transformation between src caps and dest caps. Both caps are guaranteed to be fixed caps. 如果transform_caps()未定义，默认只执行同样的转换。如果set_caps()未定义，我们不关心caps，在这种情况下我们假设没有任何内容写到缓冲区，我们不会为该transform_ip()函数强制执行可写缓冲区（如果存在）。 我们对transform元素需要的一个常见函数是找到从一种格式（src）到另一种格式（dest）的最佳转换。该函数的一些要求是： 有一个固定的src caps 找到一个固定的transform element可以转换成的dest caps dest caps是兼容的并且可被peer elements接受 transform函数倾向于使src caps == dest caps transform函数可以选择性固定dest caps find_transform()函数执行如下: 从一个固定的src caps开始； 检测这些caps是否可以被用作src caps，这通常由元素的padtemplate强制执行； 使用transform_caps()计算所有的可以转换生成的caps 如果原始的caps是transforms的一个子集，尝试caps是否能被peer接受。如果可行，我们可以执行passthrough然后设置src == dest。这只要简单调用gst_pad_peer_query_accept_caps()即可。 如果caps不是固定的，我们需要固定它们。 transform_caps()检索每个转换的caps 使用fixate_caps()固定caps 如果caps是固定的，使用_peer_query_accept_caps()检测peer是否接受他们，如果接受，我们就找到了dest caps。 如果找遍caps还没发现可转换的caps就表明失败了。 如果找到dest caps，使用set_caps()进行配置。 在协商过程之后，transform元素通常是一个稳定的状态。我们可以确定这个状态： src和sink pads有同样的caps passthrough: buffers are inspected but no metadata or buffer data is changed. The input buffers don’t need to be writable. The input buffer is simply pushed out again without modifications. (SCP) 123456 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| pad_push() | | |---------------------&gt;| | | | in-place: buffers are modified in-place, this means that the input buffer is modified to produce a new output buffer. This requires the input buffer to be writable. If the input buffer is not writable, a new buffer has to be allocated from the bufferpool. (SCI) 123456789101112 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | [!writable] | | | alloc buffer | | .-| | | &lt;transform_ip&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | copy transform: a new output buffer is allocate from the bufferpool and data from the input buffer is transformed into the output buffer. (SCC) 1234567891011 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | alloc buffer | | .-| | | &lt;transform&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | src和sink pads有不一样的样的caps in-place: input buffers are modified in-place. This means that the input buffer has a size that is larger or equal to the output size. The input buffer will be resized to the size of the output buffer. If the input buffer is not writable or the output size is bigger than the input size, we need to pad-alloc a new buffer. (DCI) 123456789101112 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | [!writable || !size] | | | alloc buffer | | .-| | | &lt;transform_ip&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | copy transform: a new output buffer is allocated and the data from the input buffer is transformed into the output buffer. The flow is exactly the same as the case with the same-caps negotiation. (DCC) Allocation当transform element配置完成之后，缓冲池需要根据caps开辟内存，主要有两种情况： 当使用passthrough模式的时候不需要在transform element中开辟内存。 当不使用passthrough，并且需要开辟输出buffer。 对于第一种情况，我们不需要查询和配置pool。我们让upstream自动决定是否需要bufferpool，然后我们将从下游到上游进行代理。 对于第二种情况，我们在srcpad设置分配内存池。 为了分配内存，我们还需要知道输出空间的大小，这里有两个函数获取大小： transform_size(): Given a caps and a size on one pad, and a caps on the other pad, calculate the size of the other buffer. This function is able to perform all size transforms and is the preferred method of transforming a size. get_unit_size(): When the input size and output size are always a multiple of each other (audio conversion, ..) we can define a more simple get_unit_size() function. The transform will use this function to get the same amount of units in the source and destination buffers. For performance reasons, the mapping between caps and size is kept in a cache.]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
</search>
