<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CUDA Grid Block Thread]]></title>
    <url>%2F2019%2F05%2F28%2FCUDA-Grid-Block-Thread%2F</url>
    <content type="text"><![CDATA[GPU性能如下所示，是调用NVIDIA_CUDA-10.1_Samples/1_Utilities/deviceQuery查询的GPU性能。 123456789101112131415161718192021222324252627282930313233343536373839404142434445ubuntu@ubuntu-B250-HD3:~/NVIDIA_CUDA-10.1_Samples/1_Utilities/deviceQuery$ ./deviceQuery ./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking)Detected 1 CUDA Capable device(s)Device 0: "GeForce GTX 1080 Ti" CUDA Driver Version / Runtime Version 10.2 / 10.1 CUDA Capability Major/Minor version number: 6.1 Total amount of global memory: 11177 MBytes (11720130560 bytes) (28) Multiprocessors, (128) CUDA Cores/MP: 3584 CUDA Cores GPU Max Clock rate: 1645 MHz (1.64 GHz) Memory Clock rate: 5505 Mhz Memory Bus Width: 352-bit L2 Cache Size: 2883584 bytes Maximum Texture Dimension Size (x,y,z) 1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384) Maximum Layered 1D Texture Size, (num) layers 1D=(32768), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(32768, 32768), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 2 copy engine(s) Run time limit on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement for Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device supports Compute Preemption: Yes Supports Cooperative Kernel Launch: Yes Supports MultiDevice Co-op Kernel Launch: Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.1, NumDevs = 1Result = PASS 首先要明确几个概念： 硬件SP：最基本的处理单元，Streaming Processor，也称为CUDA Core。具体的指令和任务都是在SP上处理的。GPU进行并行计算，也就是很多个SP同时做处理。 从上表可以看出，1080Ti显卡一共有3584 CUDA Cores。 SM：多个SP加上其他的一些资源组成一个Streaming Multiprocessor，也叫流处理簇。其他资源如：warp scheduler，register，shared memory/L1Cache，Load/Store Units等。SM可以看做GPU的心脏（对比CPU核心），register和shared memory是SM的稀缺资源。CUDA将这些资源分配给所有驻留在SM中的threads。因此，这些有限的资源就使每个SM中active warps有非常严格的限制，也就限制了并行能力。从上表可以看出，1080Ti显卡一共有28个SM，每个SM有128个SP，所以共有3584个SP。 需要指出，每个SM包含的SP数量依据GPU架构而不同，Fermi架构GF100是32个，GF10X是48个，Kepler架构都是192个，Maxwell都是128个。相同架构的GPU包含的SM数量则根据GPU的中高低端来定。 软件grid，block，thread，warp是CUDA编程上的概念，以方便程序员软件设计，组织线程，同样的我们给出一个示意图来表示。 thread(线程)：一个CUDA的并行程序会被以许多个threads来执行。 block(线程块)：数个threads会被群组成一个block，同一个block中的threads可以同步，也可以通过shared memory通信。 grid(线程网格)：多个blocks则会再构成grid。 warp(线程束)：GPU执行程序时的调度单位，目前CUDA的warp的大小为32，同在一个warp的线程，以不同数据资源执行相同的指令，这就是所谓 SIMT。 执行状态CUDA 的 device 实际在执行的时候，会以 Block 为单位，把一个个的 block 分配给 SM 进行运算；而 block 中的thread，又会以warp为单位，把 thread 来做分组计算。目前 CUDA 的 warp 大小都是 32，也就是 32 个 thread 会被群组成一个 warp 来一起执行;同一个 warp 里的 thread，会以不同的数据，执行同样的指令。 基本上 warp 分组的动作是由 SM 自动进行的，会以连续的方式来做分组。比如说如果有一个 block 里有 128 个 thread 的话，就会被分成四组 warp，第 0-31 个 thread 会是 warp 1、32-63 是 warp 2、64-95 是 warp 3、96-127 是 warp 4。而如果 block 里面的 thread 数量不是 32 的倍数，那他会把剩下的 thread 独立成一个 warp;比如说 thread 数目是 66 的话，就会有三个 warp：0-31、32-63、64-65。由于最后一个 warp 里只剩下两个 thread，所以其实在计算时，就相当于浪费了 30 个 thread 的计算能力。这点是在设定 block 中 thread 数量一定要注意的事! 一个 SM 一次只会执行一个 block 里的一个 warp，但是 SM 不见得会一次就把这个 warp 的所有指令都执行完；当遇到正在执行的 warp 需要等待的时候(例如存取 global memory 就会要等好一段时间)，就切换到别的 warp 来继续做运算，藉此避免为了等待而浪费时间。所以理论上效率最好的状况，就是在 SM 中有够多的 warp 可以切换，让在执行的时候，不会有「所有 warp 都要等待」的情形发生;因为当所有的 warp 都要等待时，就会变成 SM 无事可做的状况了。 实际上，warp 也是 CUDA 中，每一个 SM 执行的最小单位；如果 GPU 有 16 个 SM 的话，也就代表他真正在执行的thread数目会是 32*16 个(resident thread)。不过由于 CUDA 是要透过 warp 的切换来隐藏 thread 的延迟、等待，来达到大量平行化的目的，所以会用所谓的 active thread 这个名词来代表一个 SM 里同时可以处理的 thread 数目。 active warp是指已经分配给SM的warp，并且该warp需要的资源（寄存器）也已经分配。 而在 block 的方面，一个 SM 可以同时处理多个 thread block，当其中有 block 的所有 thread 都处理完后，他就会再去找其他还没处理的 block 来处理。假设有 16 个 SM、64 个 block、每个 SM 可以同时处理三个 block 的话，那一开始执时，device 就会同时处理 48 个 block，而剩下的 16 个 block 则会等 SM 有处理完 block 后，再进到 SM 中处理，直到所有 block 都处理结束。 为一个SM指定了一个或多个要执行的线程块时，它会将其分成warp块，并由SIMT单元进行调度。将块分割为warp的方法总是相同的，每个warp都包含连续的线程，递增线程索引，第一个warp中包含全局线程过索引0-31。每发出一条指令时，SIMT单元都会选择一个已准备好执行的warp块，并将指令发送到该warp块的活动线程。Warp块每次执行一条通用指令，因此在warp块的全部32个线程执行同一条路径时，可达到最高效率。如果一个warp块的线程通过独立于数据的条件分支而分散，warp块将连续执行所使用的各分支路径，而禁用未在此路径上的线程，完成所有路径时，线程重新汇聚到同一执行路径下，其执行时间为各时间总和。分支仅在warp块内出现，不同的warp块总是独立执行的–无论它们执行的是通用的代码路径还是彼此无关的代码路径。 总结 一个SM可以同时处理多个线程块，warp是SM最小执行单元。比如一个SM可以同时处理3个线程块，每个线程块有256个线程，那么就有3*256/32=24warp，同一时刻SM只能执行一个warp。注意只有一个block全部warp执行完才会换其它block来执行，同一个block的所有线程必定在同一个SM执行。 注意区分active warp和resident thread概念，active warp不一定在SM执行，而是分配好资源，等待SM调度。一个SM不一定要全部执行完，比如访存的时候可以换入其它warp来计算。这样就可以隐藏thread延迟、等待。 线程块数量一般分配为SM个数的8倍。 一个线程块分配的线程数是32的倍数。 线程块和线程网格都是三维索引。 尽量减少线程束分歧产生。 注意上表每个SM最大支持的线程数，以及每个线程块最大线程数。 问题每个SM可以同时执行多少个block? 充分利用资源的话每个SM可以同时有多少个warp ? block合理设计？ ## 参考链接 https://blog.csdn.net/junparadox/article/details/50540602 https://blog.csdn.net/yu132563/article/details/52548913]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[perf 安装及使用]]></title>
    <url>%2F2019%2F05%2F23%2Fperf%20%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[perf 安装及使用perf 安装123$ sudo apt install linux-tools-common## 注意版本号$ sudo apt-get install linux-tools-4.4.0-24-generic linux-cloud-tools-4.4.0-24-generic linux-tools-generic linux-cloud-tools-generic perf 命令1234567891011121314151617181920212223242526272829303132333435ubuntu@ubuntu-B250-HD3:~$ perf usage: perf [--version] [--help] [OPTIONS] COMMAND [ARGS] The most commonly used perf commands are: annotate Read perf.data (created by perf record) and display annotated code archive Create archive with object files with build-ids found in perf.data file bench General framework for benchmark suites buildid-cache Manage build-id cache. buildid-list List the buildids in a perf.data file c2c Shared Data C2C/HITM Analyzer. config Get and set variables in a configuration file. data Data file related processing diff Read perf.data files and display the differential profile evlist List the event names in a perf.data file ftrace simple wrapper for kernel's ftrace functionality inject Filter to augment the events stream with additional information kallsyms Searches running kernel for symbols kmem Tool to trace/measure kernel memory properties kvm Tool to trace/measure kvm guest os list List all symbolic event types lock Analyze lock events mem Profile memory accesses record Run a command and record its profile into perf.data report Read perf.data (created by perf record) and display the profile sched Tool to trace/measure scheduler properties (latencies) script Read perf.data (created by perf record) and display trace output stat Run a command and gather performance counter statistics test Runs sanity tests. timechart Tool to visualize total system behavior during a workload top System profiling tool. probe Define new dynamic tracepoints trace strace inspired tool See 'perf help COMMAND' for more information on a specific command. 序号 命令 作用 1 annotate 解析perf record生成的perf.data文件，显示被注释的代码。 2 archive 根据数据文件记录的build-id，将所有被采样到的elf文件打包。利用此压缩包，可以再任何机器上分析数据文件中记录的采样数据。 3 bench perf中内置的benchmark，目前包括两套针对调度器和内存管理子系统的benchmark。 4 buildid-cache 管理perf的buildid缓存，每个elf文件都有一个独一无二的buildid。buildid被perf用来关联性能数据与elf文件。 5 buildid-list 列出数据文件中记录的所有buildid。 6 diff 对比两个数据文件的差异。能够给出每个符号（函数）在热点分析上的具体差异。 7 evlist 列出数据文件perf.data中所有性能事件。 8 inject 该工具读取perf record工具记录的事件流，并将其定向到标准输出。在被分析代码中的任何一点，都可以向事件流中注入其它事件。 9 kmem 针对内核内存（slab）子系统进行追踪测量的工具 10 kvm 用来追踪测试运行在KVM虚拟机上的Guest OS。 11 list 列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点。 12 lock 分析内核中的锁信息，包括锁的争用情况，等待延迟等。 13 mem 内存存取情况 14 record 收集采样信息，并将其记录在数据文件中。随后可通过其它工具对数据文件进行分析。 15 report 读取perf record创建的数据文件，并给出热点分析结果。 16 sched 针对调度器子系统的分析工具。 17 script 执行perl或python写的功能扩展脚本、生成脚本框架、读取数据文件中的数据信息等。 18 stat 执行某个命令，收集特定进程的性能概况，包括CPI、Cache丢失率等。 19 test perf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能。 20 timechart 针对测试期间系统行为进行可视化的工具 21 top 类似于linux的top命令，对系统性能进行实时分析。 22 trace 关于syscall的工具。 23 probe 用于定义动态检查点。 perf 使用系统级性能优化通常包括两个阶段：性能剖析（performance profiling）和代码优化。 性能剖析的目标是寻找性能瓶颈，查找引发性能问题的原因及热点代码。 代码优化的目标是针对具体性能问题而优化代码或编译选项，以改善软件性能。 perf listperf list 可以显示所有支持的事件类型，可以显示特定模块支持的perf事件：hw/cache/pmu都是硬件相关的；tracepoint基于内核的ftrace；sw实际上是内核计数器 1234567891011121314151617181920212223242526272829303132333435363738ubuntu@ubuntu-B250-HD3:~$ sudo perf listList of pre-defined events (to be used in -e): branch-instructions OR branches [Hardware event] branch-misses [Hardware event] bus-cycles [Hardware event] cache-misses [Hardware event] cache-references [Hardware event] cpu-cycles OR cycles [Hardware event] instructions [Hardware event] ref-cycles [Hardware event] alignment-faults [Software event] bpf-output [Software event] context-switches OR cs [Software event] ... minor-faults [Software event] page-faults OR faults [Software event] task-clock [Software event] L1-dcache-load-misses [Hardware cache event] L1-dcache-loads [Hardware cache event] L1-dcache-stores [Hardware cache event] ... iTLB-loads [Hardware cache event] node-load-misses [Hardware cache event] node-loads [Hardware cache event] node-store-misses [Hardware cache event] node-stores [Hardware cache event] branch-instructions OR cpu/branch-instructions/ [Kernel PMU event] branch-misses OR cpu/branch-misses/ [Kernel PMU event] bus-cycles OR cpu/bus-cycles/ [Kernel PMU event] ... cycles-ct OR cpu/cycles-ct/ [Kernel PMU event] cycles-t OR cpu/cycles-t/ [Kernel PMU event] el-abort OR cpu/el-abort/ [Kernel PMU event] perf stat1234567891011121314ubuntu@ubuntu-B250-HD3:~$ sudo perf stat Performance counter stats for 'system wide': 78762.210390 cpu-clock (msec) # 8.000 CPUs utilized 102,321 context-switches # 0.001 M/sec 888 cpu-migrations # 0.011 K/sec 102,842 page-faults # 0.001 M/sec 34,026,798,403 cycles # 0.432 GHz 34,823,881,180 instructions # 1.02 insn per cycle 7,258,813,402 branches # 92.161 M/sec 59,271,180 branch-misses # 0.82% of all branches 9.845475012 seconds time elapsed cpu-clock：任务真正占用的处理器时间，单位为ms。CPUs utilized = task-clock / time elapsed，CPU的占用率。 context-switches：程序在运行过程中上下文的切换次数。 CPU-migrations：程序在运行过程中发生的处理器迁移次数。Linux为了维持多个处理器的负载均衡，在特定条件下会将某个任务从一个CPU迁移到另一个CPU。 CPU迁移和上下文切换：发生上下文切换不一定会发生CPU迁移，而发生CPU迁移时肯定会发生上下文切换。发生上下文切换有可能只是把上下文从当前CPU中换出，下一次调度器还是将进程安排在这个CPU上执行。 page-faults：缺页异常的次数。当应用程序请求的页面尚未建立、请求的页面不在内存中，或者请求的页面虽然在内存中，但物理地址和虚拟地址的映射关系尚未建立时，都会触发一次缺页异常。另外TLB不命中，页面访问权限不匹配等情况也会触发缺页异常。 cycles：消耗的处理器周期数。如果把被ls使用的cpu cycles看成是一个处理器的，那么它的主频为2.486GHz。可以用cycles / task-clock算出。 stalled-cycles-frontend：指令读取或解码的质量步骤，未能按理想状态发挥并行左右，发生停滞的时钟周期。 stalled-cycles-backend：指令执行步骤，发生停滞的时钟周期。 instructions：执行了多少条指令。IPC为平均每个cpu cycle执行了多少条指令。 branches：遇到的分支指令数。 branch-misses：是预测错误的分支指令数。 perf stat 常用参数： -a, --all-cpus 显示所有CPU上的统计信息 -C, --cpu &lt;cpu&gt; 显示指定CPU的统计信息 -c, --scale scale/normalize counters -D, --delay &lt;n&gt; ms to wait before starting measurement after program start -d, --detailed detailed run - start a lot of events -e, --event &lt;event&gt; event selector. use &apos;perf list&apos; to list available events -G, --cgroup &lt;name&gt; monitor event in cgroup name only -g, --group put the counters into a counter group -I, --interval-print &lt;n&gt; print counts at regular interval in ms (&gt;= 10) -i, --no-inherit child tasks do not inherit counters -n, --null null run - dont start any counters -o, --output &lt;file&gt; 输出统计信息到文件 -p, --pid &lt;pid&gt; stat events on existing process id -r, --repeat &lt;n&gt; repeat command and print average + stddev (max: 100, forever: 0) -S, --sync call sync() before starting a run -t, --tid &lt;tid&gt; stat events on existing thread id perf top123456789101112131415161718192021$ sudo perf topSamples: 147K of event 'cycles:ppp', Event count (approx.): 59239863864Overhead Shared Object Symbol 9.86% [kernel] [k] do_syscall_64 5.12% [kernel] [k] syscall_return_via_sysret 3.12% libcuda.so.418.56 [.] 0x00000000002fb584 2.99% libgomp.so.1.0.0 [.] 0x0000000000011b27 1.82% [kernel] [k] __schedule 1.21% [kernel] [k] pick_next_task_fair 1.07% [kernel] [k] _raw_spin_lock 1.00% [unknown] [k] 0xfffffe000013a01b 0.98% libpthread-2.23.so [.] pthread_mutex_lock 0.81% [kernel] [k] prepare_exit_to_usermode 0.81% libc-2.23.so [.] __sched_yield 0.80% [kernel] [k] cpuacct_charge 0.79% libpthread-2.23.so [.] pthread_mutex_unlock 0.76% [kernel] [k] clear_page_erms 0.69% [kernel] [k] native_sched_clock 0.69% [kernel] [k] update_curr 0.63% [kernel] [k] yield_task_fair 第一列：符号引发的性能事件的比例，指占用的cpu周期比例。 第二列：符号所在的DSO(Dynamic Shared Object)，可以是应用程序、内核、动态链接库、模块。 第三列：DSO的类型。[.]表示此符号属于用户态的ELF文件，包括可执行文件与动态链接库；[k]表述此符号属于内核或模块。 第四列：符号名。有些符号不能解析为函数名，只能用地址表示。 perf top 常用的选项： -e ：指明要分析的性能事件。 -p ：Profile events on existing Process ID (comma sperated list). 仅分析目标进程及其创建的线程。 -k ：Path to vmlinux. Required for annotation functionality. 带符号表的内核映像所在的路径。 -K：不显示属于内核或模块的符号。 -U：不显示属于用户态程序的符号。 -d ：界面的刷新周期，默认为2s，因为perf top默认每2s从mmap的内存区域读取一次性能数据。 -g：得到函数的调用关系图。 perf reocrd使用 top 和 stat之后，已经大致有数了。要进一步分析，便需要一些粒度更细的信息。比如说已经断定目标程序计算量较大，也许是因为有些代码写的不够精简。那么面对长长的代码文件，究竟哪几行代码需要进一步修改呢？这便需要使用perf record 记录单个函数级别的统计信息，并使用 perf report 来显示统计结果。 123$ sudo perf record -g -e cpu-clock ./test$ sudo perf report## 查看百分比比较高的为耗时比较严重的函数 perf record 常用参数： -e record指定PMU事件 –filter event事件过滤器 -a 录取所有CPU的事件 -p 录取指定pid进程的事件 -o 指定录取保存数据的文件名 -g 使能函数调用图功能 -C 录取指定CPU的事件 perf report 常用参数： -i 导入的数据文件名称，如果没有则默认为perf.data -g 生成函数调用关系图，此时内核要打开CONFIG_KALLSYMS；用户空间库或者执行文件需要带符号信息(not stripped)，编译选项需要加上-g。 –sort 从更高层面显示分类统计信息，比如： pid, comm, dso, symbol, parent, cpu,socket, srcline, weight, local_weight. TODO还有很多功能，带后续慢慢挖掘。 参考链接https://www.cnblogs.com/arnoldlu/p/6241297.html https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/index.html]]></content>
      <categories>
        <category>perf</category>
      </categories>
      <tags>
        <tag>perf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PaperReading:RetinaNet]]></title>
    <url>%2F2019%2F05%2F10%2FPaperReading-RetinaNet%2F</url>
    <content type="text"><![CDATA[Focal Loss for Dense Object Detection代码链接 论文链接 作者提出了focal loss，通过在交叉熵损失函数中加入一个衰减系数，达到可以降低那些”分类好“的样本的损失，从而更加关注那个误分类的样本。根据这个损失函数，作者训练了一个检测器RetinaNet，性能比当前最好的two-stage检测器性能还高，在COCO数据集可以达到40.8 AP。 之前最好的目标检测器还是基于two-stage，基于候选框驱动机制。先生成候选框目标集，然后在分类回归定位。那么one-stage是否也可以达到同样的精度呢？one-stage通过密集采样，基于anchor机制采样不同目标位置，不同scale，不同ratios。比如YOLO，SSD等方法。 作者提出的RetinaNet可以匹敌two-stage检测器，比如Feature Pyramid Network (FPN)、Mask R-CNN、Faster R-CNN。作者发现了类别不均衡是导致one-stage检测器精度上不去的原因。在two-stage检测器中一般有提取候选框的步骤，所以可以很快降低候选框数目，这其实以及有降低类别不均衡的意思在里面，因为图像大部分地方都是背景，在two-stage方法中解决样本不均衡一般采用启发式采样，比如前景和背景比例保持在1:3左右，或者使用难样本挖掘（online hard example mining (OHEM)）。然而在one-stage中一般要处理100k左右的候选框，虽然也使用启发式采样，但是效率很低，比如使用bootstrapping或者hard example mining等方法。 样本不均衡所带来的问题：1训练效率不高，因为大部分的样本为easy-negatives，对学习没有帮助；2大量的easy-negatives会使训练overwhelm从而使模型退化。 很多论文都在解决损失函数鲁棒性问题，比如Huber loss，但是大部分的损失函数都是致力于离群点，降低hard examples的损失权重，相反的focal loss主要设计为处理样本不均衡问题，致力于降低非离群点也就是easy example的损失权重。 Focal Loss标准交叉熵损失函数：$$CE(p,y)= \left{\begin{aligned}-log(p) &amp;&amp; if(y = 1) \-log(1-p) &amp;&amp; otherwise\end{aligned}\right.$$设$$p_t = \left{\begin{aligned}p &amp;&amp; if(y = 1) \1-p &amp;&amp; otherwise\end{aligned}\right.$$可以得到CE(p, y) = CE(pt ) = − log(pt ) 画出曲线可以分析看到即使是容易分类的样本，数量一多，也会造成很大的损失。实验表明样本不均衡使得易分类样本的损失占大部分，主导了梯度。作者提出的损失函数：$$FL(p_t ) = −(1 − p_t )^γ log(p_t )$$ 当样本误分类的时候pt很小，系数接近于１，系数对loss没啥影响；当pt接近于１的时候，系数接近０，对于易分类的样本可以降低权重。通过降低易分类样本的损失权重反过来增加了分类错误的损失的重要性。 作者还加了一个系数可以提高精度：$$FL(p_t ) = −α_t (1 − p_t )^γ log(p_t )$$]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PaperReading:RetinaFace]]></title>
    <url>%2F2019%2F05%2F07%2FPaperReading-RetinaFace%2F</url>
    <content type="text"><![CDATA[摘要虽然对于无约束人脸检测取得了巨大进步，但是精度和速度依然是一个挑战。作者提出一种鲁棒的single-stage人脸检测器，加入extra-supervised和self-supervised模块，提高人脸检测性能的多任务学习方法。论文主要贡献有５点： 手动标注WIDER FACE数据集人脸关键点，并且在难人脸检测上由于额外监督信号的帮助取得了巨大的提高。 在现有的模块上并行加入self-supervised解码分支预测3D人脸信息分支。 在WIDER FACE hard test数据集上提高1.1%（达到91.4%）。 在IJB-C test set上测试结果表明可以提高ArcFace在人脸验证精度(TAR=89.59% for FAR=1e-6)。 使用轻量级骨干网络，RetinaFace在CPU上测试VGA图片可以达到实时。 概述此片论文包含face detection、face alignment、pixel-wise face parsing、3D dense correspondence regres-sion等任务。 首先论文灵感来源于一般目标检测rcnn系列、SSD、YOLO系列、FPN、Focal loss。和一般的目标检测不同，人脸检测的宽高比一般是1:1到1:1.5之间，但是大小可以从几个像素到几千个像素。目前比较流行的方法是one-stage方法，速度比较快，所以作者基于one-stage采用多任务方法得到state-of-the-art结果。 《Joint cascade face detection and alignment》论文提出的联合人脸检测和人脸对齐可以提取到更好的人脸特征。所以基于MTCNN和STN方法灵感，作者加入５个人脸关键点，由于训练数据的限制JDA 、MTCNN、和STN没有验证过小人脸检测是否可以从额外的５个关键点中获益。通过加入５个关键点，作者想看看能否在WIDER FACE hard test取得更好的性能。 Mask R-CNN通过加入了Mask并行预测分支之后性能得到了很大的提升。证实了密集pixel-wise标签可以提高检测。然而WIDER FACE对密集标注很难实施，能够使用非监督方法来进一步提高人脸检测呢？ 在FAN论文中，提出了一种anchor-level attention map来提高遮挡的人脸检测，但是这个方法太粗糙，并且不包含语义信息。目前，self-supervised 3D morphable models在3D人脸建模取得良好成绩，尤其是Mesh Decoder达到了实时。但是应用Mesh Decoder方法有两个难点：１相机参数难以估计精确；２特征漂移。本篇论文作者使用自监督学习方法加入额外分支来预测3D人脸形状。 相关工作Image pyramid v.s. feature pyramid Two-stage v.s. single-stage Context Modelling Multi-task Learning RetinaFace多任务损失函数$$L = L_{cls}(p_i ,p^∗_i) + λ_1p^∗_iL_{box}(t_i,t^∗_i) λ_2p^∗_iL_{pts}(l_i,l_i^∗) + λ_3p^∗_iL_{pixel}$$ 其中Lcls代表分类损失，softmax，pi表示anchor i预测为人脸的概率，p*为１表示为正样本，为０表示负样本。 其中Lbox为边框回归损失，smooth-L1，t i = {t x , t y , t w , t h }，对中心点和宽高进行归一化操作，对于正样本anchor的损失。 其中L pts为５个关键点回归，类似边框回归中的中心点回归。 其中L pixel为密集回归损失函数，具体函数见后面。 λ 1 -λ 3为权重分别设置为0.25 0.1 0.01]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>人脸检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PaperReading: FaceBoxes]]></title>
    <url>%2F2019%2F05%2F05%2FPaperReading%3AFaceBoxes%2F</url>
    <content type="text"><![CDATA[概述​ 人脸检测是人脸对齐、人脸识别、人脸跟踪的基础。目前人脸检测还面临着很多挑战，主要还是精度和速度的问题。很多研究都是为了解决这两个问题。早期的方法是基于人工特征，以V-J人脸检测为代表，大量的研究都是设计一个鲁棒的特征和训练一个有效的分类器。cascade structure和DMP模型都能获得不错的性能。但是这些方法都是基于不鲁棒的特征，虽然速度快，但是在不同场景下精度不高。另一种方法是基于卷积神经网络。卷积网络对于多变人脸具有很高的鲁棒性，但是在速度上却不快，尤其是在CPU设备上面。 ​ 这两种方法有各自的优点。为了在速度和精度上能够达到较好的性能，一种自然的想法是结合两种类型的方法，也就是采用级联的卷积神经网络，比如MTCNN。但是基于级联的卷积神经网络会带来三个问题：1.速度和人脸数量相关，人脸越多速度越慢；2.级联检测器都是基于局部优化，训练复杂；3.不能达到实时。 ​ 此篇文章灵感来源于Faster R-CNN中的RPN以及SSD的多尺度机制。这是一个ONE-STAGE网络，网络结构主要包含两部分：1.Rapidly Digested Convolutional Layers (RDCL)和Multiple Scale Convolutional Layers (MSCL)。RDCL是为了解决实时问题，MSCL主要为了丰富感受野，使不同层的anchor离散化，解决人脸多尺度问题。除此之外，作者还提出Anchor densification strategy让不同类型的anchor有相同的密度，这极大提高小人脸的召回率。对于VGA图片(640x480)在CPU可以达到20FPS，在GPU可以达到125FPS。作者认为他们工作的贡献包含四部分，除了以上说的三点之外，还包含：在AFW, PASCAL face, and FDDB datasets取得最好性能(what? 这也算？) 网络结构 RDCL 缩小输入的空间大小：为了快速减小输入的空间尺度大小，在卷积核池化上使用了一系列的大的stride，在Conv1、Pool1、Conv2、Pool2上stride分别是4、2、2、2，RDCL的stride一共是32，意味着输入的尺度大小被快速减小了32倍。 选择合适的kernel size：一个网络开始的一些层的kernel size应该比较小以用来加速，同时也应该足够大用以减轻空间大小减小带来的信息损失。Conv1、Conv2以及所有的Pool层分别选取7x7，5x5，3x3的kernel size。 减少输出通道数：使用C.ReLU来减少输出通道数。为啥提出这个激活函数有专门的论文参考，引：网络的前部，网络倾向于同时捕获正负相位的信息，但ReLU会抹掉负响应。 这造成了卷积核会存在冗余。 MSCL 将RPN作为一个人脸检测器，不能获取很好的性能有以下两个原因： RPN中的anchor只和最后一个卷积层相关，其中的特征和分辨率对于处理人脸变化问题上太弱。 anchor相应的层使用一系列不同的尺度来检测人脸，但只有单一的感受野，不能匹配不同尺度的人脸。 为解决这个问题，对MSCL从以下两个角度去设计： Multi-scale design along the dimension of network depth. Anchor在多尺度的feature map上面取，类似SSD。 Multi-scale design along the dimension of network width.使用inception模块，内部使用不同大小的卷积核，可以捕获到更多的尺度信息。 Anchor densification strategy​ 对于Anchor作者使用1:1的宽高比，原因是因为人脸框接近正方形。 Inception3的anchor尺度为32x32，64x64，128x128，Conv3_2、Conv4_2的尺度分别为256x256和512x512。 ​ 对于anchor相应层的间隔相当于步长大小、比如，对于Conv3 2步长是64，anchor大小256x256，意思是对于输入图片，每隔64个像素有一个256x256的anchor。作者提出了一个anchor密度概念：$$A_{density} = \frac{A_{scale}}{A_{interval}}$$其中分子表示anchor大小，分母表示anchor间隔，对于anchor间隔一般是默认的，也就是步长大小，分别为32、32、32、64、128。根据式子计算出来的密度分别为1、2、4、4、4。由此可以看到对于小人脸anchor太稀疏，密度太低，会导致小人脸的召回率下降。为了消除这个不平衡，作者提出了一种策略，在原来的anchor中心均匀叠加n^2个anchor，以保证密度相同，所以对于32x32的anchor叠加为原来的４倍，对于64x64的anchor叠加为原来的２倍。 训练训练集WIDER FACE的子集，12880个图片。 数据增强 Color distortion Random cropping Scale transformation Horizontal flipping Face-box filter 匹配策略在训练时需要判断哪个anchor是和哪个bounding box对应。首先使用jaccard overlap将每个脸和anchor对应起来，然后对anchor和任意脸jaccard overlap高于阈值（0.35）的匹配起来。 损失函数和Faster R-CNN中的RPN用同样的loss，一个2分类的softmax loss用来做分类，smooth L1用来做回归。 Hard negative mining:在anchor匹配后，大多数anchor都是负样本，导致正样本和负样本严重不均衡。为了更快更稳定的训练，将他们按照loss值排序并选取最高的几个，保证正样本和负样本的比例最高不超过3:1. Other implementation details:Xavier随机初始化。优化器SGD，momentum:0.9，weight decay:5e-4，batch size:32，迭代最大次数:120k，初始80k迭代learning rate:1e-3，80-100k迭代用1e-4，,100-120k迭代用1e-5，使用caffe实现。 参考链接《Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units》 CReLU激活函数 代码]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>人脸检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 使用方法总结]]></title>
    <url>%2F2019%2F04%2F30%2Fgit-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[git 使用方法总结比较基础的方法就不一一写了，碰到没使用过的在慢慢总结更新。 git status可以看到有三部分的内容，我们分为上中下。对于Changes to be committed 为暂存区，Changes not staged for commit为工作区，Untracked files为未添加文件（本地文件）。 先解释几个概念： １．工作区：就是你在电脑里能看到的目录 ２．版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 当我们想把文件往Git版本库里添加的时候，是分两步执行的：第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 12345678910111213141516171819202122232425ubuntu@ubuntu-B250-HD3:~/Project/faceengine/faceengine$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: src/core/CMakeLists.txt modified: src/core/algservice/FaceDetection/FaceDetector.cpp modified: src/core/algservice/FaceDetection/FaceDetector.h modified: src/core/algservice/FaceDetection/MTCNNCaffeDetector.h new file: src/core/algservice/FaceDetection/MTCNNTensorrtDetector.cpp new file: src/core/algservice/FaceDetection/MTCNNTensorrtDetector.h new file: src/core/algservice/FaceDetection/resizeconvertion.cu modified: src/core/scheduler/FaceEngine.cppChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: src/core/CMakeLists.txtUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) patch １．对于暂存区的内容，如果想要恢复和本地版本库一样，则需要输入命令： 12$ git reset HEAD &lt;file&gt;...$ git checkout -- &lt;file&gt;... ２．对于工作区的内容，如果需要恢复和本地版本库一样，则需要输入命令： 1$ git checkout -- &lt;file&gt;... ３．如果想把工作区的内容或者本地内容添加到暂存区： 1$ git add &lt;file&gt;... ４．当我们执行commit之后，想把版本回退到之前的版本： 123456# 回退到上一个版本$ git reset --hard HEAD^# 回退到上上版本$ git reset --hard HEAD^^# 回退到往上１００个版本$ git reset --hard HEAD~100 如果想恢复到最新版本： 123456# 找到commit id$ git reflog9febc2e HEAD@&#123;0&#125;: pull: Fast-forward7a028ee HEAD@&#123;1&#125;: clone: from https://xxx.git# 回退到某个版本$ git reset --hard 7a028ee git log123456789101112131415161718ubuntu@ubuntu-B250-HD3:~/Project/faceengine/faceengine$ git logcommit 9febc2e07ae0d5401dade4913578e2ae07381a73Author: yeweijing &lt;ypat_999@163.com&gt;Date: Sun Apr 28 10:28:06 2019 +0800 提交日志commit ca94b89fd7bfe19e8891a0f5c5f05d1339b42480Author: chendepin &lt;danpechen@126.com&gt;Date: Mon Apr 22 15:55:26 2019 +0800 修复适应不同目录结构的问题commit 0be1f9bb8f0d6fc41af30b88de70e539da421b67Author: chendepin &lt;danpechen@126.com&gt;Date: Fri Apr 19 15:16:13 2019 +0800 忽略 pyc 格式文件 9febc2e07ae0d5401dade4913578e2ae07381a73：为commit id（版本号），和SVN不一样，Git的commit id不是1，2，3……递增的数字，而是一个SHA1计算出来的一个非常大的数字，用十六进制表示为什么commit id需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。Author：为作者。Date：提交日期。最后是日志内容。 git rm12345678910111213141516# 创建文件并提交$ git add test.txt$ git commit -m "add test.txt"# 删除本地文件$ rm test.txt# 场景一# 更新到暂存区$ git rm/add test.txt# 删除本地库文件$ git commit -m "remove test.txt"# 场景二# 只删除本地文件，可以使用checkout复原$ git checkout -- test.txt git diff12345678910111213141516171819202122# 工作区与暂存区比较$ git diff# 暂存区与最新本地库比较$ git diff --cached [&lt;path&gt;...]# 工作区及暂存区与本地最新版本库比较$ git diff HEAD [&lt;path&gt;...]# 暂存区与指定commit-id比较$ git diff --cached [&lt;commit-id&gt;] [&lt;path&gt;...]# 比较两个commit-id之间的差异 $ git diff [&lt;commit-id&gt;] [&lt;commit-id&gt;]# 打补丁# 将暂存区与版本库的差异做成补丁$ git diff --cached &gt; patch# 将工作区以及暂存区与本地版本库的差异做成补丁$ git diff HEAD &gt; patch # 将工作区单个文件做成补丁$ git diff &lt;file&gt; git stash当我们在我们的分支上修改完成之后，需要先使用pull命令把远程库最新内容checkout下来，此时可能产生冲突导致pull不下来，因此需要现将我们修订的东西暂时储存起来。或者当我们在工作过程中，临时接到新任务，需要把当前的工作现场清理一下，等做完新任务后再恢复工作现场，这时候可以使用git stash来管理： 123456789101112131415161718192021222324252627282930313233343536373839404142# 查看当前分支状态$ git statusOn branch devChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: hello.pyChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txt# 将工作区和暂存区的文件保存到堆栈中$ git stashSaved working directory and index state WIP on dev: f52c633 add merge# 恢复$ git stash pop #相当于使用git stash apply和git stash dropOn branch devChanges to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: hello.pyChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: readme.txtDropped refs/stash@&#123;0&#125; (5d677e2ee266f39ea296182fb2354265b91b3b2a)# 查看堆栈内容$ git stash list# 恢复指定的stash$ git stash apply stash@&#123;0&#125;# 清除stash$ git stash clean 远程仓库管理要关联一个远程库，使用命令如下，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的，但是origin这个名字一看就知道是远程库。 1$ git remote add origin git@github.com:clancylian/repo-name.git 关联后，由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 1$ git push -u origin master 此后，每次本地提交后，只要有必要，就可以使用以下命令提交： 1$ git push origin master 从远程库克隆下来： 1$ git clone https://github.com/clancylian/repo-name.git 1234567891011121314151617181920212223242526272829# 查看远程库信息$ git remoteorigin$ git remote -vorigin https://github.com/amdegroot/ssd.pytorch.git (fetch)origin https://github.com/amdegroot/ssd.pytorch.git (push)# 推送分支，master为本地分支$ git push origin master# checkout远程其他分支$ git checkout -b dev origin/dev# 如果push失败需要先pull下来$ git pullThere is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details. git pull &lt;remote&gt; &lt;branch&gt;If you wish to set tracking information for this branch you can do so with: git branch --set-upstream-to=origin/&lt;branch&gt; dev # 提示没有关联，需要先关联$ git branch --set-upstream-to=origin/dev devBranch 'dev' set up to track remote branch 'dev' from 'origin'. 分支管理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 创建分支并切换到分支$ git checkout -b branch1Switched to a new branch 'branch1'# 相当于以下命令$ git branch branch1$ git checkout branch1Switched to branch 'branch1'# 查看当前分支,当前分支会有*号，也就是HEAD指向的分支$ git branch* branch1 master # 修改完分支内容之后，切换回主分支$ git checkout masterSwitched to branch 'master'# 合并分支，git merge命令用于合并指定分支(branch1)到当前分支(master)$ git merge branch1Updating d46f35e..b17d20eFast-forward readme.txt | 1 + 1 file changed, 1 insertion(+) # 删除分支$ git branch -d branch1Deleted branch dev (was b17d20e).######################################################3# 当合并分支的时候出现冲突时$ git statusOn branch masterYour branch is ahead of 'origin/master' by 2 commits. (use "git push" to publish your local commits)You have unmerged paths. (fix conflicts and run "git commit") (use "git merge --abort" to abort the merge)Unmerged paths: (use "git add &lt;file&gt;..." to mark resolution) both modified: readme.txtno changes added to commit (use "git add" and/or "git commit -a")# 查看文件内容出现&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADaaaaaaaaaaaaaaaaaaaaaaaa=======bbbbbbbbbbbbbbbbbbbbbbbb&gt;&gt;&gt;&gt;&gt;&gt;&gt; branch1# 手动修改后$ git add &lt;file&gt; $ git commit -m "conflict fixed" ## 标签管理 1234567891011121314151617181920212223242526272829303132333435363738# 创建标签$ git tag v1.0$ git tagv1.0# 对历史版本打标签$ git tag v0.9 f52c633# 查看标签信息$ git show v0.9# 带有说明的标签$ git tag -a v0.1 -m "version 0.1 released" 1094adb# 删除本地标签$ git tag -d v0.1Deleted tag 'v0.1' (was f15b0dd)# 提交标签到远程库$ git push origin v1.0Total 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v1.0 -&gt; v1.0# 提交所有标签$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v0.9 -&gt; v0.9# 删除远程标签$ git tag -d v0.9Deleted tag 'v0.9' (was f52c633)$ git push origin :refs/tags/v0.9To github.com:michaelliao/learngit.git - [deleted] v0.9 参考链接git 学习网站推荐 gitignore 配置文件]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv GPU和CPUX实现直方图均衡差异]]></title>
    <url>%2F2019%2F04%2F29%2Fopencv-GPU%E5%92%8CCPUX%E5%AE%9E%E7%8E%B0%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%B7%AE%E5%BC%82%2F</url>
    <content type="text"><![CDATA[opencv gpu和cpu实现直方图均衡会出现不同，版本3.3.1，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include &lt;iostream&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace cv;using namespace std;void testCPU()&#123; //cpu cv::Mat src = imread("/home/ubuntu/Pictures/2.png"); //cv::resize(src, src, cv::Size(0, 0), 0.5, 0.5); vector&lt;Mat&gt; channels; split(src, channels); Mat B,G,R;//#pragma omp parallel sections &#123;//#pragma omp section &#123; equalizeHist( channels[0], B ); //GaussianBlur(B,B,Size(3, 3), 2.0); //B = (B+ channels[0]) / 2; //addWeighted(B, 0.5, channels[0], 0.5, 0, B); &#125;//#pragma omp section &#123; equalizeHist( channels[1], G ); //GaussianBlur(G,G,Size(3, 3), 2.0); //G = (G+ channels[1]) / 2; //addWeighted(G, 0.5, channels[1], 0.5, 0, G); &#125;//#pragma omp section &#123; equalizeHist( channels[2], R ); //GaussianBlur(R,R,Size(3, 3), 2.0); //R = (R+ channels[2]) / 2; //addWeighted(R, 0.5, channels[2], 0.5, 0, R); &#125; &#125; vector&lt;Mat&gt; combined; combined.push_back(B); combined.push_back(G); combined.push_back(R); Mat sample_single; merge(combined, sample_single); imwrite("cpu.jpg", sample_single); imshow("cpu", sample_single); //waitKey(0);&#125;void testGPU()&#123; //gpu cv::Mat src = imread("/home/ubuntu/Pictures/2.png"); //cv::resize(src, src, cv::Size(0, 0), 0.5, 0.5); cv::cuda::GpuMat gpu_src;// = cv::cuda::GpuMat(src.height, src.width, CV_8UC3, src.data); gpu_src.upload(src); std::vector&lt;cv::cuda::GpuMat&gt; channels; cv::cuda::split(gpu_src, channels); cv::cuda::GpuMat B, G, R; cv::cuda::equalizeHist(channels[0], B); cv::cuda::equalizeHist(channels[1], G); cv::cuda::equalizeHist(channels[2], R); //创建高斯滤波器 cv::Ptr&lt;cv::cuda::Filter&gt; gauss = cv::cuda::createGaussianFilter(CV_8UC1, CV_8UC1, Size(3, 3), 2.0); //高斯滤波 //gauss-&gt;apply(B, B); //gauss-&gt;apply(G, G); //gauss-&gt;apply(R, R);// cv::cuda::addWeighted(B, 0.5, channels[0], 0.5, 0, B);// cv::cuda::addWeighted(G, 0.5, channels[1], 0.5, 0, G);// cv::cuda::addWeighted(R, 0.5, channels[2], 0.5, 0, R); vector&lt;cv::cuda::GpuMat&gt; combined; combined.push_back(B); combined.push_back(G); combined.push_back(R); cv::cuda::GpuMat gpu_dst; cv::cuda::merge(combined, gpu_dst); Mat img; gpu_dst.download(img); imwrite("gpu.jpg", img); imshow("gpu", img); waitKey(0);&#125;int main()&#123; testCPU(); testGPU(); return 0;&#125; 原图 CPU GPU]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NVIDIA NPP LIBRARY SDK]]></title>
    <url>%2F2019%2F04%2F29%2FNVIDIA-NPP-LIBRARY-SDK%2F</url>
    <content type="text"><![CDATA[CUDA NPP库使用NPP库是英伟达提供的可用在实现GPU加速图像处理，详细SDK文档可以参考链接，主要包含的库如下： 12345678910111213141516171819202122//图像处理基础库，类似opencv corenppc NPP core library which MUST be included when linking any application, functions are listed in nppCore.h//算术逻辑操作nppial arithmetic and logical operation functions in nppi_arithmetic_and_logical_operations.h//颜色转换操作nppicc color conversion and sampling functions in nppi_color_conversion.h//图像压缩和解压nppicom JPEG compression and decompression functions in nppi_compression_functions.h//数据转换及初始化nppidei data exchange and initialization functions in nppi_data_exchange_and_initialization.h//滤波操作nppif filtering and computer vision functions in nppi_filter_functions.h//几何变换nppig geometry transformation functions found in nppi_geometry_transforms.h//形态学操作nppim morphological operation functions found in nppi_morphological_operations.h//统计及线性变换nppist statistics and linear transform in nppi_statistics_functions.h and nppi_linear_transforms.h//内存支持函数nppisu memory support functions in nppi_support_functions.h//阈值及比较操作nppitc threshold and compare operation functions in nppi_threshold_and_compare_operations.h 由于项目需求，这里主要介绍一些常用的操作，主要是opencv中基本图像处理操作，比如颜色空间转换，图像伸缩变换等等。 RESIZEresize操作支持单通道、３通道、４通道。8u、16u、16s、32f，接口一般是nppiResizeSqrPixel_ _ ，其中可以选择对感兴趣区域进行resize。这里需要注意的是resize的一些插值方式，和opencv不太一样，并且官方文档没有详细说明，导致有一些坑在里面。比如之前使用NPPI_INTER_SUPER插值方式的时候发现factor大于１的时候会出错。后面找到答案说NPPI_INTER_SUPER只支持降采样操作，参考链接。这里举个BGR进行通道转换的栗子： 12345678910111213141516171819202122232425262728293031323334353637383940bool imageResize_8u_C3R(void *src, int srcWidth, int srcHeight, void *dst, int dstWidth, int dstHeight)&#123; NppiSize oSrcSize; oSrcSize.width = srcWidth; oSrcSize.height = srcHeight; int nSrcStep = srcWidth * 3; NppiRect oSrcROI; oSrcROI.x = 0; oSrcROI.y = 0; oSrcROI.width = srcWidth; oSrcROI.height = srcHeight; int nDstStep = dstWidth * 3; NppiRect oDstROI; oDstROI.x = 0; oDstROI.y = 0; oDstROI.width = dstWidth; oDstROI.height = dstHeight; // Scale Factor double nXFactor = double(dstWidth) / (oSrcROI.width); double nYFactor = double(dstHeight) / (oSrcROI.height); // Scaled X/Y Shift double nXShift = - oSrcROI.x * nXFactor ; double nYShift = - oSrcROI.y * nYFactor; int eInterpolation = NPPI_INTER_SUPER; if (nXFactor &gt;= 1.f || nYFactor &gt;= 1.f) eInterpolation = NPPI_INTER_LANCZOS; NppStatus ret = nppiResizeSqrPixel_8u_C3R((const Npp8u *)src, oSrcSize, nSrcStep, oSrcROI, (Npp8u *)dst, nDstStep, oDstROI, nXFactor, nYFactor, nXShift, nYShift, eInterpolation ); if(ret != NPP_SUCCESS) &#123; printf("imageResize_8u_C3R failed %d.\n", ret); return false; &#125; return true;&#125; resize库包含在nppig库里面，其中还有各种操作，包括mirror、remap、rotate、warp等等，这些在平常使用过程中比较少用到，需要用的时候再参考文档。 ## 颜色转换 自己实现一些操作padding123456789101112131415161718192021222324252627__global__ void imagePaddingKernel(float3 *ptr, float3 *dst, int width, int height, int top, int bottom, int left, int right)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if(x &lt; left || x &gt;= (width - right) || y &lt; top || y &gt; (height - bottom)) &#123; return; &#125; float3 color = ptr[(y - top) * (width - top - right) + (x - left)]; dst[y * width + x] = color;&#125;void imagePadding(const void *src, void *dst, int width, int height, int top, int bottom, int left, int right)&#123; int dstW = width + left + right; int dstH = height + top + bottom; cudaMemset(dst, 0, dstW * dstH * sizeof(float3)); dim3 grids((dstW + 31) / 32, (dstH + 31) / 32); dim3 blocks(32, 32); imagePaddingKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (float3 *)dst, dstW, dstH, top, bottom, left, right);&#125; split123456789101112131415161718192021__global__ void imageSplitKernel(float3 *ptr, float *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; float3 color = ptr[y * width + x]; dst[y * width + x] = color.x; dst[y * width + x + width * height] = color.y; dst[y * width + x + width * height * 2] = color.z;&#125;void imageSplit(const void *src, float *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); imageSplitKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (float *)dst, width, height);&#125; normalization12345678910111213141516171819202122__global__ void imageNormalizationKernel(float3 *ptr, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; float3 color = ptr[y * width + x]; color.x = (color.x - 127.5) * 0.0078125; color.y = (color.y - 127.5) * 0.0078125; color.z = (color.z - 127.5) * 0.0078125; ptr[y * width + x] = make_float3(color.x, color.y, color.z);&#125;void imageNormalization(void *ptr, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); imageNormalizationKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)ptr, width, height);&#125; BGR2RGBfloat123456789101112131415161718__global__ void convertBGR2RGBfloatKernel(uchar3 *src, float3 *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar3 color = src[y * width + x]; dst[y * width + x] = make_float3(color.z, color.y, color.x);&#125;void convertBGR2RGBfloat(void *src, void *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); convertBGR2RGBfloatKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((uchar3 *)src, (float3 *)dst, width, height);&#125; RGBA2Gray12345678910111213141516171819202122__global__ void convertRGBA2GrayKernel(uchar4 *src, uchar1 *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar4 color = src[y * width + x]; //dst[y * width + x] = make_uchar1((color.x+color.y+color.z) * .333333f); dst[y * width + x] = make_uchar1(0.114f * color.x + 0.587f * color.y + 0.299f * color.z);&#125;void convertRGBA2Gray(void *src, void *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); convertRGBA2GrayKernel&lt;&lt;&lt;grids, blocks, 0, stream&gt;&gt;&gt;((uchar4 *)src, (uchar1 *)dst, width, height);// cudaDeviceSynchronize(); cudaStreamSynchronize(stream);&#125; RGBA2BGR123456789101112131415161718__global__ void convertRGBA2BGRKernel(uchar4 *src, uchar3 *dst, int width, int height)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar4 color = src[y * width + x]; dst[y * width + x] = make_uchar3(color.z, color.y, color.x);&#125;void convertRGBA2BGR(void *src, void *dst, int width, int height, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); convertRGBA2BGRKernel&lt;&lt;&lt;grids, blocks, 0, stream&gt;&gt;&gt;((uchar4 *)src, (uchar3 *)dst, width, height);&#125; TX2 nvx实现RGBA2YUVI42012345678910111213141516171819202122232425262728293031323334353637383940void convertRGBA2YUVI420(void *src, void *dst, int width, int height)&#123; static bool inited = false; static nvxcu_stream_exec_target_t exec_target; if (!inited) &#123; int deviceID; /*HANDLE_CUDA_ERROR*/(cudaGetDevice(&amp;deviceID)); exec_target.base.exec_target_type = NVXCU_STREAM_EXEC_TARGET; exec_target.stream = NULL; /*HANDLE_CUDA_ERROR*/(cudaGetDeviceProperties(&amp;exec_target.dev_prop, deviceID)); inited = true; &#125; nvxcu_pitch_linear_image_t input, output; input.base.format = NVXCU_DF_IMAGE_RGBX; input.base.width = width; input.base.height = height; input.base.image_type = NVXCU_PITCH_LINEAR_IMAGE; input.planes[0].dev_ptr = src; input.planes[0].pitch_in_bytes = width * 4; output.base.format = NVXCU_DF_IMAGE_IYUV; output.base.width = width; output.base.height = height; output.base.image_type = NVXCU_PITCH_LINEAR_IMAGE; output.planes[0].dev_ptr = dst; output.planes[0].pitch_in_bytes = width; output.planes[1].dev_ptr = (char *)dst + width * height; output.planes[1].pitch_in_bytes = width / 2; output.planes[2].dev_ptr = (char *)dst + width * height * 5 / 4; output.planes[2].pitch_in_bytes = width / 2; nvxcu_error_status_e stat; stat = nvxcuColorConvert(&amp;input.base, &amp;output.base, NVXCU_COLOR_SPACE_DEFAULT, NVXCU_CHANNEL_RANGE_FULL, &amp;exec_target.base); if (stat != NVXCU_SUCCESS) &#123; dbgInfo("Conver RGB to YUVI420 failed: %d.\n", stat); &#125;&#125; 叠加图片1234567891011121314151617181920212223__global__ void cudaPutLogoToImageKernel(uchar4 *devImg, int imgWidth, int imgHeight, uchar3 *devLogo, int width, int height, int offsetX, int offsetY)&#123; int x = threadIdx.x + blockIdx.x * blockDim.x; int y = threadIdx.y + blockIdx.y * blockDim.y; if (x &gt;= width || y &gt;= height) &#123; return; &#125; uchar3 devLogoColor = devLogo[y * width + x]; int offset = (y + offsetY) * imgWidth + offsetX + x; devImg[offset] = make_uchar4(devLogoColor.z, devLogoColor.y, devLogoColor.x, 0);&#125;void cudaPutLogoToImage(void *devImg, int imgWidth, int imgHeight, void *devLogo, int width, int height, int offsetX, int offsetY, cudaStream_t stream)&#123; dim3 grids((width + 31) / 32, (height + 31) / 32); dim3 blocks(32, 32); //if use stream, every time the result will be error. have to test!!! cudaPutLogoToImageKernel&lt;&lt;&lt;grids, blocks, 0, stream&gt;&gt;&gt;((uchar4 *)devImg, imgWidth, imgHeight, (uchar3 *)devLogo, width, height, offsetX, offsetY);&#125; ## 参考链接 官网地址]]></content>
      <categories>
        <category>NVIDIA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>NPP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch学习之路]]></title>
    <url>%2F2019%2F04%2F13%2FPyTorch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[参考文档 1. 基础概念PyTorch类似于Numpy。它的优点在于可以充分利用GPU资源。它是一个深度学习框架，提供最大的灵活性和速度。 1.1 张量概念12345678910111213141516171819202122232425262728from __future__ import print_functionimport torch# 构造未初始化5x3的矩阵x = torch.empty(5, 3)print(x)# 构造随机初始化矩阵x = torch.rand(5, 3)print(x)# 构造0矩阵，数据类型为longx = torch.zeros(5, 3, dtype=torch.long)print(x)# 直接用数据构造一个张量x = torch.tensor([5.5, 3])print(x)# 基于存在的张量构造，可以使用存在的张量的一些属性，比如数据类型，数据纬度，除非手动修改x = x.new_ones(5, 3, dtype=torch.double) # new_* methods take in sizesprint(x)x = torch.randn_like(x, dtype=torch.float) # override dtype!print(x) # result has the same size# 获取张量大小.实际上torch.Size是一个元组类型，支持元组所有操作print(x.size()) 1.2 张量操作关于张量的操作有100多种，包括转置、索引、切片、数值计算、线性代数、随机数等等。 123456789101112131415161718192021222324252627282930# 加法1y = torch.rand(5, 3)print(x + y)# 加法2print(torch.add(x, y))# 输出张量作为参数result = torch.empty(5, 3)torch.add(x, y, out=result)print(result)# 原地（in-place）加法# adds x to yy.add_(x)print(y)# 以 _ 作为后缀将会改变操作数，比如x.copy_(y), x.t_(),都会改变x的值# 可以像Numpy一样索引print(x[:, 1])# resize和reshape操作可以使用torch.viewx = torch.randn(4, 4)y = x.view(16)z = x.view(-1, 8) # the size -1 is inferred from other dimensionsprint(x.size(), y.size(), z.size())# 如果你有一个只有一个元素的张量，可以使用.item()获取数值x = torch.randn(1)print(x)print(x.item()) 1.3 与Numpy互操作1234567891011121314# tensor转为Numpya = torch.ones(5)print(a)b = a.numpy()print(b)# Numpy转为tensorimport numpy as npa = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a)print(a)print(b) 1.4 CUDA 张量可以使用 .to 方法把张量拷贝到设备内存(GPU) 123456789# let us run this cell only if CUDA is available# We will use ``torch.device`` objects to move tensors in and out of GPUif torch.cuda.is_available():device = torch.device("cuda") # a CUDA device objecty = torch.ones_like(x, device=device) # directly create a tensor on GPUx = x.to(device) # or just use strings ``.to("cuda")``z = x + yprint(z)print(z.to("cpu", torch.double)) # ``.to`` can also change dtype together! 1.5 自动微分技术PyTorch中的反向传播中求导都是使用autograd包完成的。它提供了张量求导所有操作，它是一个define-by-run框架，意味着每一次反向传播都取决于你的代码是如何跑的，每一次迭代都可能不同。 torch.Tensor 是pytorch一个最基础的类。如果你设置其属性 .requires_grad 为 True, 它将会跟踪它所有的操作，当你调用.backward()时，会自动计算梯度，可以使用 .grad 获取梯度值。可以使用.detach()来停止跟踪历史或者阻止将来的操作。也可以使用with torch.no_grad():。 除了torch.Tensor 还有一个很重要的类来实现自动求导——Fucction。每一个张量（除了用户创建的之外）都有.grad_fn属性。 当想要计算导数的时候只要调用.backward()。当输出张量是一个标量的时候，不需要特别指明参数，然而如果是一个向量就需要指明gradient参数。 12345678910111213141516# 设置requires_grad为truex = torch.ones(2, 2, requires_grad=True)print(x)y = x + 2print(y)# 因为y是由操作得来的结果，所以有grad_fn属性print(y.grad_fn)z = y * y * 3out = z.mean()print(z, out)# 因为out输出为标量，相当于out.backward(torch.tensor(1.))out.backward()print(x.grad) 1.6 神经网络1.6.1 定义网络结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):def __init__(self):super(Net, self).__init__()# 1 input image channel, 6 output channels, 5x5 square convolution# kernelself.conv1 = nn.Conv2d(1, 6, 5)self.conv2 = nn.Conv2d(6, 16, 5)# an affine operation: y = Wx + bself.fc1 = nn.Linear(16 * 5 * 5, 120)self.fc2 = nn.Linear(120, 84)self.fc3 = nn.Linear(84, 10)def forward(self, x):# Max pooling over a (2, 2) windowx = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))# If the size is a square you can only specify a single numberx = F.max_pool2d(F.relu(self.conv2(x)), 2)x = x.view(-1, self.num_flat_features(x))x = F.relu(self.fc1(x))x = F.relu(self.fc2(x))x = self.fc3(x)return xdef num_flat_features(self, x):size = x.size()[1:] # all dimensions except the batch dimensionnum_features = 1for s in size:num_features *= sreturn num_featuresnet = Net()# 输出网络结构print(net)# 模型参数存在net.parameters()中params = list(net.parameters())print(len(params))print(params[0].size()) # conv1's .weight# 测试输入input = torch.randn(1, 1, 32, 32)out = net(input)print(out)# 模型梯度置0然后反向传播net.zero_grad()out.backward(torch.randn(1, 10)) 注：torch.nn只支持最小批量 1.6.2 损失函数1234567output = net(input)target = torch.randn(10) # a dummy target, for exampletarget = target.view(1, -1) # make it the same shape as outputcriterion = nn.MSELoss()loss = criterion(output, target)print(loss) 由此可以得出计算图： 1234input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d-&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear-&gt; MSELoss-&gt; loss 1.6.3 反向传播123456789net.zero_grad() # zeroes the gradient buffers of all parametersprint('conv1.bias.grad before backward')print(net.conv1.bias.grad)loss.backward()print('conv1.bias.grad after backward')print(net.conv1.bias.grad) 1.6.4 更新权重1234567891011import torch.optim as optim# create your optimizeroptimizer = optim.SGD(net.parameters(), lr=0.01)# in your training loop:optimizer.zero_grad() # zero the gradient buffersoutput = net(input)loss = criterion(output, target)loss.backward()optimizer.step() # Does the update 注：每次optimizer.zero_grad()需要手动置0，因为梯度是累积的。 1.7 训练一个分类器1.7.1 加载数据1234567891011121314151617181920import torchimport torchvisionimport torchvision.transforms as transformstransform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=2)testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=2)classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck') 1.7.2 定义卷积神经网络12345678910111213141516171819202122232425import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):def __init__(self):super(Net, self).__init__()self.conv1 = nn.Conv2d(3, 6, 5)self.pool = nn.MaxPool2d(2, 2)self.conv2 = nn.Conv2d(6, 16, 5)self.fc1 = nn.Linear(16 * 5 * 5, 120)self.fc2 = nn.Linear(120, 84)self.fc3 = nn.Linear(84, 10)def forward(self, x):x = self.pool(F.relu(self.conv1(x)))x = self.pool(F.relu(self.conv2(x)))x = x.view(-1, 16 * 5 * 5)x = F.relu(self.fc1(x))x = F.relu(self.fc2(x))x = self.fc3(x)return xnet = Net() 1.7.3 定义损失函数和优化器1234import torch.optim as optimcriterion = nn.CrossEntropyLoss()optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 1.7.4 训练网络123456789101112131415161718192021222324for epoch in range(2): # loop over the dataset multiple timesrunning_loss = 0.0for i, data in enumerate(trainloader, 0):# get the inputsinputs, labels = data# zero the parameter gradientsoptimizer.zero_grad()# forward + backward + optimizeoutputs = net(inputs)loss = criterion(outputs, labels)loss.backward()optimizer.step()# print statisticsrunning_loss += loss.item()if i % 2000 == 1999: # print every 2000 mini-batchesprint('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))running_loss = 0.0print('Finished Training') 1.7.5 测试1234567891011121314151617class_correct = list(0. for i in range(10))class_total = list(0. for i in range(10))with torch.no_grad():for data in testloader:images, labels = dataoutputs = net(images)_, predicted = torch.max(outputs, 1)c = (predicted == labels).squeeze()for i in range(4):label = labels[i]class_correct[label] += c[i].item()class_total[label] += 1for i in range(10):print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i])) 12345678910Accuracy of plane : 72 %Accuracy of car : 47 %Accuracy of bird : 41 %Accuracy of cat : 32 %Accuracy of deer : 42 %Accuracy of dog : 49 %Accuracy of frog : 70 %Accuracy of horse : 62 %Accuracy of ship : 46 %Accuracy of truck : 76 % 1.7.6 GPU训练12345678device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# Assuming that we are on a CUDA machine, this should print a CUDA device:print(device)net.to(device)inputs, labels = inputs.to(device), labels.to(device) 1.8 数据并行1234567891011# cuda设备device = torch.device("cuda:0")# 将模型移到GPUmodel.to(device)# 输入拷贝到GPUmytensor = my_tensor.to(device)# 设置数据并行model = nn.DataParallel(model) 2. 数据3. 模型4. 策略（损失函数）5. 算法]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>深度学习框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量配置]]></title>
    <url>%2F2019%2F04%2F02%2FLinux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[设置文件为:123456//全局设置文件/etc/profile//针对某个用户设置~/.bashrc` 设置PATH:1export PATH=/your/bin/path:$PATH 注意： PATH=中间不能有空格。 设置LD_LIBRARY_PATH:1export LD_LIBRARY_PATH=/your/lib/path:$LD_LIBRARY_PATH 另：也可以在/etc/ld.so.conf.d/ 下设置目录，然后调用ldconfig生效。 生效：123source ~/.bashrcorsource /etc/profile]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件之自定义数据结构]]></title>
    <url>%2F2019%2F04%2F01%2FGStreamer%E6%8F%92%E4%BB%B6%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[GstMeta当我们需要添加自定义的数据结构到GstBuffer中时，需要使用GstMeta自定义数据结构。GstMeta数据结构为：1234struct _GstMeta &#123; GstMetaFlags flags; const GstMetaInfo *info; /* tag and info for the meta item */&#125;; 其中 info 结构体为：123456789struct _GstMetaInfo &#123; GType api; //api 类型 GType type; //具体实现类型 gsize size; //自定义数据结构体大小 GstMetaInitFunction init_func; //初始化函数 GstMetaFreeFunction free_func; //释放函数 GstMetaTransformFunction transform_func; //转换函数&#125;; 其中api成员需要由gst_meta_api_type_register()函数注册生成，具体看下文实施例。 GstMeta是我们自定义数据结构体的公共头，比如gstreamer自带时间信息结构体：12345678struct _GstMetaTiming &#123; GstMeta meta; /* common meta header */ GstClockTime dts; /* decoding timestamp */ GstClockTime pts; /* presentation timestamp */ GstClockTime duration; /* duration of the data */ GstClockTime clock_rate; /* clock rate for the above values */&#125;; 自定义的数据结构体由字段或者方法组成。一个典型的buffer可能是如以下结构：1234567891011121314151617181920212223242526272829 +----------------------------------+GstMiniObject | GType (GstBuffer) | | refcount, flags, copy/disp/free | +----------------------------------+GstBuffer | pool,pts,dts,duration,offsets | | &lt;private data&gt; | +..................................+ | next ---+ +- | info ------&gt; GstMetaInfoGstMetaTiming | | | | | | dts | | | | pts | | | | duration | | +- | clock_rate | | + . . . . . . . . . . . . . . . . + | | next &lt;--+GstVideoMeta +- +- | info ------&gt; GstMetaInfo | | | | | | | | flags | | | | | n_planes | | | | | planes[] | | | | | map | | | | | unmap | | +- | | | | | | private fields | |GstVideoMetaImpl | | ... | | | | ... | | +- | | | + . . . . . . . . . . . . . . . . + . 自定义meta实现头文件123456789101112131415161718192021222324252627282930313233343536373839404142#ifndef GSTFACEPARAMMETA_H#define GSTFACEPARAMMETA_H#include "gst/gst.h"/** Defines GStreamer metadata types. *///定义枚举类型，用来指定meta_data指针所指向的数据类型typedef enum&#123; META_INIT = 0x0, FACE_PARAM,&#125; Meta_type;typedef struct _FaceParamMeta FaceParamMeta;//该结构体为要附加的元数据结构体struct _FaceParamMeta &#123; //公共头 GstMeta meta; //存储各种需要的自定义结构体，方便扩展 void *meta_data; //meta_data指针指向的结构体类型 int meta_type; //类似回调函数指针，在buffer销毁的时候会调用 GDestroyNotify destroy;&#125;;//注册api type的接口，返回api用于注册metaGType face_param_meta_api_get_type(void);#define FACE_PARAM_META_API_TYPE (face_param_meta_api_get_type())//注册meta的时候返回GstMetaInfoconst GstMetaInfo *face_param_meta_get_info(void);#define FACE_PARAM_META_INFO (face_param_meta_get_info())//往buffer中添加数据，返回FaceParamMeta*指针指向添加位置FaceParamMeta *gst_buffer_add_face_param_meta(GstBuffer *buffer, void *metadata, int metatype, GDestroyNotify destroy);//从buffer中获取自定义meta数据FaceParamMeta *gst_buffer_get_face_param_meta(GstBuffer *buffer);#endif // GSTFACEPARAMMETA_H 实现文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include "gstfaceparammeta.h"GType face_param_meta_api_get_type(void)&#123; static volatile GType type; //可以往api type加入标签，使用gst_meta_api_type_has_tag查找是否由我们自定义结构体 static const gchar *tags[] = &#123;"face", "detect", NULL&#125;; if(g_once_init_enter(&amp;type)) &#123; //注册api type GType _type = gst_meta_api_type_register("FaceParamMetaAPI", tags); g_once_init_leave(&amp;type, _type); &#125; return type;&#125;//初始化函数实现static gboolean face_param_meta_init(GstMeta *meta, gpointer params, GstBuffer *buffer)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; emeta-&gt;meta_type = META_INIT; emeta-&gt;meta_data = NULL; emeta-&gt;destroy = NULL; return TRUE;&#125;//转换函数实现，具体复杂情况下怎么用还需琢磨static gboolean face_param_meta_transform(GstBuffer *transbuf, GstMeta *meta, GstBuffer *buffer, GQuark type, gpointer data)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; gst_buffer_add_face_param_meta(transbuf, emeta-&gt;meta_data, emeta-&gt;meta_type, emeta-&gt;destroy); return TRUE;&#125;//释放函数static void face_param_meta_free(GstMeta *meta, GstBuffer *buffer)&#123; FaceParamMeta *emeta = (FaceParamMeta*) meta; emeta-&gt;meta_type = META_INIT; //回调函数 emeta-&gt;destroy(emeta-&gt;meta_data);&#125;//注册我们的meta函数const GstMetaInfo *face_param_meta_get_info(void)&#123; static const GstMetaInfo *meta_info = NULL; if(g_once_init_enter(&amp;meta_info)) &#123; //注册返回GstMetaInfo //第二个参数可以在gst_meta_get_info（）函数使用 const GstMetaInfo *mi = gst_meta_register(FACE_PARAM_META_API_TYPE, "FaceParamMeta", sizeof(FaceParamMeta), face_param_meta_init, face_param_meta_free, face_param_meta_transform); g_once_init_leave(&amp;meta_info, mi); &#125; return meta_info;&#125;//增加数据FaceParamMeta *gst_buffer_add_face_param_meta(GstBuffer *buffer, void *metadata, int metatype, GDestroyNotify destroy)&#123; FaceParamMeta *meta; g_return_val_if_fail(GST_IS_BUFFER(buffer), NULL); meta = (FaceParamMeta *)gst_buffer_add_meta(buffer, FACE_PARAM_META_INFO, NULL); //指针简单赋值，需要注意外面传进来的指针必须不是局部变量，否则会自动释放 meta-&gt;meta_data = metadata; //meta_data指向类型 meta-&gt;meta_type = metatype; //回调函数，在free的时候使用 meta-&gt;destroy = destroy; return meta;&#125;//获取数据FaceParamMeta *gst_buffer_get_face_param_meta(GstBuffer *buffer)&#123; FaceParamMeta *meta; meta = (FaceParamMeta *)gst_buffer_get_meta(buffer, FACE_PARAM_META_API_TYPE); return meta;&#125; 具体使用调用添加数据函数1faceParamMeta = gst_buffer_add_face_param_meta(outbuf, metadata, FACE_PARAM, free_face_param_meta); 释放函数为：12345678910/** * Free the metadata allocated in attach_metadata_full_frame */static voidfree_face_param_meta (gpointer meta_data)&#123; g_print ("free output buffer, free output buffer.\n"); MtcnnPluginOutput *output = (MtcnnPluginOutput *)meta_data; g_free(output);&#125; 获取数据可以使用如下方法：方法1：直接调用我们自己定义的函数1metadata = gst_buffer_get_face_param_meta(); 方法2：因为我们可能在不同的element中添加很多个自定义数据结构，使用方法1只能取到最后一个添加的，需要使用以下方法进行遍历：123456static GQuark _ivameta_quark = 0;if (!_ivameta_quark) &#123; //注意参数时我们注册api type时添加的tag //类似键值对 _ivameta_quark = g_quark_from_static_string ("face");&#125; 1234567891011121314151617181920212223GstMeta *gst_meta;// Standard way of iterating through buffer metadatawhile ((gst_meta = gst_buffer_iterate_meta (outbuf, &amp;state)) != NULL) &#123; //可以获取GstMetaInfo，注意参数需要和注册时一致 const GstMetaInfo *info = gst_meta_get_info("FaceParamMeta"); //查询是否有我们想要的api type if (!gst_meta_api_type_has_tag (gst_meta-&gt;info-&gt;api, _ivameta_quark)) &#123; continue; &#125; //如果是，转成我们的结构体 ivameta = (FaceParamMeta *) gst_meta; // Check if the metadata of IvaMeta contains object bounding boxes if (ivameta-&gt;meta_type != FACE_PARAM) continue; //根据meta_type获取具体数据 meta_data = (MtcnnPluginOutput *) ivameta-&gt;meta_data;&#125; 参考官网链接:GstMetaMemory allocation]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019学习计划]]></title>
    <url>%2F2019%2F03%2F31%2F2019%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件编写学习]]></title>
    <url>%2F2019%2F03%2F29%2FGStreamer%E6%8F%92%E4%BB%B6%E7%BC%96%E5%86%99%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[下载插件模板1234567shell $ git clone https://gitlab.freedesktop.org/gstreamer/gst-template.gitInitialized empty Git repository in /some/path/gst-template/.git/remote: Counting objects: 373, done.remote: Compressing objects: 100% (114/114), done.remote: Total 373 (delta 240), reused 373 (delta 240)Receiving objects: 100% (373/373), 75.16 KiB | 78 KiB/s, done.Resolving deltas: 100% (240/240), done. 以上方案有点过时，可到github下载gst-plugins-bad模块，使用里面的工具生成模板。 使用make_element生成模板12cd gst-template/gst-plugin/src../tools/make_element MyFilter &lt;基类文件如:gsttransform&gt; 修改makefile.am文件12345678910111213141516171819202122# Note: plugindir is set in configure############################################################################### TODO: change libgstplugin.la to something else, e.g. libmysomething.la ###############################################################################plugin_LTLIBRARIES = libgstplugin.la libgstaudiofilterexample.la############################################################################### TODO: for the next set of variables, name the prefix if you named the .la, ## e.g. libmysomething.la =&gt; libmysomething_la_SOURCES ## libmysomething_la_CFLAGS ## libmysomething_la_LIBADD ## libmysomething_la_LDFLAGS ################################################################################# Plugin 1# sources used to compile this plug-inlibgstplugin_la_SOURCES = gstplugin.c gstplugin.h# compiler and linker flags used to compile this plugin, set in configure.aclibgstplugin_la_CFLAGS = $(GST_CFLAGS)libgstplugin_la_LIBADD = $(GST_LIBS)libgstplugin_la_LDFLAGS = $(GST_PLUGIN_LDFLAGS)libgstplugin_la_LIBTOOLFLAGS = --tag=disable-static# headers we need but don&apos;t want installednoinst_HEADERS = gstplugin.h 生成makefile文件123./autogen.shmakesudo make install 注意：需要修改configure.ac文件里面安装的路径，不然插件会被安装到/usr/local/lib/gstreamer-1.0中 Example Demo1234567891011121314151617181920212223242526#include &lt;gst/gst.h&gt;/* Definition of structure storing data for this element. */typedef struct _GstMyFilter &#123; GstElement element; GstPad *sinkpad, *srcpad; gboolean silent;&#125; GstMyFilter; /* Standard definition defining a class for this element. */typedef struct _GstMyFilterClass &#123; GstElementClass parent_class;&#125; GstMyFilterClass;/* Standard macros for defining types for this element. */#define GST_TYPE_MY_FILTER (gst_my_filter_get_type())#define GST_MY_FILTER(obj) \ (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_MY_FILTER,GstMyFilter))#define GST_MY_FILTER_CLASS(klass) \ (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_MY_FILTER,GstMyFilterClass))#define GST_IS_MY_FILTER(obj) \ (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_MY_FILTER))#define GST_IS_MY_FILTER_CLASS(klass) \ (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_MY_FILTER)) /* Standard function returning type information. */GType gst_my_filter_get_type (void); Element metadata元素元数据提供额外的元素信息，使用gst_element_class_set_metadata或者gst_element_class_set_static_metadata函数来设置，其参数包含： A long, English, name for the element. The type of the element, see the docs/design/draft-klass.txt documentin the GStreamer core source tree for details and examples. A brief description of the purpose of the element. The name of the author of the element, optionally followed by acontact email address in angle brackets.例如：12345gst_element_class_set_static_metadata (klass,"An example plugin","Example/FirstExample","Shows the basic structure of a plugin","your name &lt;your.name@your.isp&gt;"); 以上函数在初始化_class_init ()插件的时候调用123456789101112static voidgst_my_filter_class_init (GstMyFilterClass * klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_set_static_metadata (element_klass, "An example plugin", "Example/FirstExample", "Shows the basic structure of a plugin", "your name &lt;your.name@your.isp&gt;");&#125; GstStaticPadTemplateGstStaticPadTemplate是用来描述将要创建的pad的信息，包含: A short name for the pad. Pad direction. Existence property. This indicates whether the pad exists always (an “always” pad), only in some cases (a “sometimes” pad) or only if the application requested such a pad (a “request” pad). Supported types by this element (capabilities).例如：1234567static GstStaticPadTemplate sink_factory =GST_STATIC_PAD_TEMPLATE ( "sink", //名称 GST_PAD_SINK, //方向sink or src GST_PAD_ALWAYS, //availability GST_STATIC_CAPS ("ANY") //capability); 同样该sink_factory也是在初始化时候使用，通过gst_element_class_add_pad_template ()和gst_static_pad_template_get ()来调用1234567891011121314static GstStaticPadTemplate sink_factory = [..], src_factory = [..];static voidgst_my_filter_class_init (GstMyFilterClass * klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;src_factory)); gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;sink_factory));&#125; 该pad将在构造函数_init ()函数中使用gst_pad_new_from_static_template ()来创建。 注：对于每个element来说，有两个构造函数，其中_class_init()函数只调用一次，用来说明类所拥有的信号、参数、虚函数以及设置全局状态；_init()函数则用在初始化实例特定的实例。 插件初始化函数当我们写完插件的所有部件之后，需要编写插件的初始化函数，这个函数在插件加载的时候调用，需要返回TRUE or FALSE来觉得是否正确加载。在这个函数中，任何支持的element插件应该被注册。12345678910111213141516171819static gbooleanplugin_init (GstPlugin *plugin)&#123; return gst_element_register (plugin, "my_filter", GST_RANK_NONE, GST_TYPE_MY_FILTER);&#125;GST_PLUGIN_DEFINE ( GST_VERSION_MAJOR, GST_VERSION_MINOR, my_filter, "My filter plugin", plugin_init, VERSION, "LGPL", "GStreamer", "http://gstreamer.net/") pads具体说明PADS是数据流进出每个element的端口，在初始化_init ()函数中，你从pad template中创建了一个pad，这个pad template是在_class_init ()函数中注册的，创建了pad之后，你必须在sinkpad设置_chain ()函数指针用来接收和处理数据。可选的，你也可以设置_event ()和_query ()指针；pad亦可以使用循环模式，这意味着它们可以自己拉取数据。1234567891011121314151617181920static voidgst_my_filter_init (GstMyFilter *filter)&#123; /* pad through which data comes in to the element */ filter-&gt;sinkpad = gst_pad_new_from_static_template ( &amp;sink_template, "sink"); /* pads are configured here with gst_pad_set_*_function () */ gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;sinkpad); /* pad through which data goes out of the element */ filter-&gt;srcpad = gst_pad_new_from_static_template ( &amp;src_template, "src"); /* pads are configured here with gst_pad_set_*_function () */ gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;srcpad); /* properties initial value */ filter-&gt;silent = FALSE; &#125; Sometimes PadSometimes pad 只有在一些特定情况下才创建，这取决于流内容。比如demuxers解析流头。每个element可以创建多个sometimes pad，唯一限制就是都要有唯一的名字。当流数据被销毁时（比如从PAUSED到READY状态），pad也应该被销毁，但是在EOS状态不应该被销毁。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146typedef struct _GstMyFilter &#123;[..] gboolean firstrun; GList *srcpadlist;&#125; GstMyFilter;//静态目标类型sometimesstatic GstStaticPadTemplate src_factory =GST_STATIC_PAD_TEMPLATE ( "src_%u", GST_PAD_SRC, GST_PAD_SOMETIMES, GST_STATIC_CAPS ("ANY"));static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..]//注册pad gst_element_class_add_pad_template (element_class, gst_static_pad_template_get (&amp;src_factory));[..]&#125;static voidgst_my_filter_init (GstMyFilter *filter)&#123;[..] filter-&gt;firstrun = TRUE; filter-&gt;srcpadlist = NULL;&#125;/* * Get one line of data - without newline. */static GstBuffer *gst_my_filter_getline (GstMyFilter *filter)&#123; guint8 *data; gint n, num; /* max. line length is 512 characters - for safety */ for (n = 0; n &lt; 512; n++) &#123; num = gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n + 1); if (num != n + 1) return NULL; /* newline? */ if (data[n] == '\n') &#123; GstBuffer *buf = gst_buffer_new_allocate (NULL, n + 1, NULL); gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n); gst_buffer_fill (buf, 0, data, n); gst_buffer_memset (buf, n, '\0', 1); gst_bytestream_flush_fast (filter-&gt;bs, n + 1); return buf; &#125; &#125;&#125;static voidgst_my_filter_loopfunc (GstElement *element)&#123; GstMyFilter *filter = GST_MY_FILTER (element); GstBuffer *buf; GstPad *pad; GstMapInfo map; gint num, n; /* parse header */ if (filter-&gt;firstrun) &#123; gchar *padname; guint8 id; if (!(buf = gst_my_filter_getline (filter))) &#123; gst_element_error (element, STREAM, READ, (NULL), ("Stream contains no header")); return; &#125; gst_buffer_extract (buf, 0, &amp;id, 1); num = atoi (id); gst_buffer_unref (buf); /* for each of the streams, create a pad */ //根据头的流个数，创建num个pad for (n = 0; n &lt; num; n++) &#123; padname = g_strdup_printf ("src_%u", n); pad = gst_pad_new_from_static_template (src_factory, padname); g_free (padname); /* here, you would set _event () and _query () functions */ /* need to activate the pad before adding */ gst_pad_set_active (pad, TRUE); gst_element_add_pad (element, pad); filter-&gt;srcpadlist = g_list_append (filter-&gt;srcpadlist, pad); &#125; &#125; /* and now, simply parse each line and push over */ if (!(buf = gst_my_filter_getline (filter))) &#123; GstEvent *event = gst_event_new (GST_EVENT_EOS); GList *padlist; for (padlist = srcpadlist; padlist != NULL; padlist = g_list_next (padlist)) &#123; pad = GST_PAD (padlist-&gt;data); gst_pad_push_event (pad, gst_event_ref (event)); &#125; gst_event_unref (event); /* pause the task here */ return; &#125; /* parse stream number and go beyond the ':' in the data */ gst_buffer_map (buf, &amp;map, GST_MAP_READ); num = atoi (map.data[0]); if (num &gt;= 0 &amp;&amp; num &lt; g_list_length (filter-&gt;srcpadlist)) &#123; //取第N个pad塞数据 pad = GST_PAD (g_list_nth_data (filter-&gt;srcpadlist, num); /* magic buffer parsing foo */ for (n = 0; map.data[n] != ':' &amp;&amp; map.data[n] != '\0'; n++) ; if (map.data[n] != '\0') &#123; GstBuffer *sub; /* create region copy that starts right past the space. The reason * that we don't just forward the data pointer is because the * pointer is no longer the start of an allocated block of memory, * but just a pointer to a position somewhere in the middle of it. * That cannot be freed upon disposal, so we'd either crash or have * a memleak. Creating a region copy is a simple way to solve that. */ sub = gst_buffer_copy_region (buf, GST_BUFFER_COPY_ALL, n + 1, map.size - n - 1); gst_pad_push (pad, sub); &#125; &#125; gst_buffer_unmap (buf, &amp;map); gst_buffer_unref (buf);&#125; Request padRequest pad 只有在外部需要的时候才创建而不是element内部。比如tee element可以根据需要拷贝多份数据到不同的分支。需要实现request_new_pad和release_pad两个虚函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static GstPad * gst_my_filter_request_new_pad (GstElement *element, GstPadTemplate *templ, const gchar *name, const GstCaps *caps);static void gst_my_filter_release_pad (GstElement *element, GstPad *pad);static GstStaticPadTemplate sink_factory =GST_STATIC_PAD_TEMPLATE ( "sink_%u", GST_PAD_SINK, GST_PAD_REQUEST, GST_STATIC_CAPS ("ANY"));static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass);[..] gst_element_class_add_pad_template (klass, gst_static_pad_template_get (&amp;sink_factory));[..] element_class-&gt;request_new_pad = gst_my_filter_request_new_pad; element_class-&gt;release_pad = gst_my_filter_release_pad;&#125;static GstPad *gst_my_filter_request_new_pad (GstElement *element, GstPadTemplate *templ, const gchar *name, const GstCaps *caps)&#123; GstPad *pad; GstMyFilterInputContext *context; context = g_new0 (GstMyFilterInputContext, 1); pad = gst_pad_new_from_template (templ, name); gst_pad_set_element_private (pad, context); /* normally, you would set _chain () and _event () functions here */ gst_element_add_pad (element, pad); return pad;&#125;static voidgst_my_filter_release_pad (GstElement *element, GstPad *pad)&#123; GstMyFilterInputContext *context; context = gst_pad_get_element_private (pad); g_free (context); gst_element_remove_pad (element, pad);&#125; The chain functionchain函数是处理数据的地方，记住buffers并不总是可写的。123456789101112131415161718192021222324252627282930static GstFlowReturn gst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf);[..]static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] /* configure chain function on the pad before adding * the pad to the element */ gst_pad_set_chain_function (filter-&gt;sinkpad, gst_my_filter_chain);[..]&#125;static GstFlowReturngst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); if (!filter-&gt;silent) g_print ("Have data of size %" G_GSIZE_FORMAT" bytes!\n", gst_buffer_get_size (buf)); return gst_pad_push (filter-&gt;srcpad, buf);&#125; The event function在一些高级的element中，需要设置event处理函数。它通知一些发生在数据流中的特定事件，比如（caps, end-of-stream, newsegment, tags, etc.），事件可以传播到上游和下游，所以你可以在sink pads和source pads接收到。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] gst_pad_set_event_function (filter-&gt;sinkpad, gst_my_filter_sink_event);[..]&#125;static gbooleangst_my_filter_sink_event (GstPad *pad, GstObject *parent, GstEvent *event)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); switch (GST_EVENT_TYPE (event)) &#123; case GST_EVENT_CAPS: /* we should handle the format here */ break; case GST_EVENT_EOS: /* end-of-stream, we should close down all stream leftovers here */ gst_my_filter_stop_processing (filter); break; default: break; &#125; return gst_pad_event_default (pad, parent, event);&#125;static GstFlowReturngst_my_filter_chain (GstPad *pad, GstObject *parent, GstBuffer *buf)&#123; GstMyFilter *filter = GST_MY_FILTER (parent); GstBuffer *outbuf; outbuf = gst_my_filter_process_data (filter, buf); gst_buffer_unref (buf); if (!outbuf) &#123; /* something went wrong - signal an error */ GST_ELEMENT_ERROR (GST_ELEMENT (filter), STREAM, FAILED, (NULL), (NULL)); return GST_FLOW_ERROR; &#125; return gst_pad_push (filter-&gt;srcpad, outbuf);&#125; The query function通过query函数，element可以接收查询事件并作出回复，比如（position, duration，supported formats，scheduling modes）。查询同样可以传播到上下游，你可以在sink pads和source pads接收到。123456789101112131415161718192021222324252627282930313233343536373839404142434445static gboolean gst_my_filter_src_query (GstPad *pad, GstObject *parent, GstQuery *query);[..]static voidgst_my_filter_init (GstMyFilter * filter)&#123;[..] /* configure event function on the pad before adding * the pad to the element */ gst_pad_set_query_function (filter-&gt;srcpad, gst_my_filter_src_query);[..]&#125;static gbooleangst_my_filter_src_query (GstPad *pad, GstObject *parent, GstQuery *query)&#123; gboolean ret; GstMyFilter *filter = GST_MY_FILTER (parent); switch (GST_QUERY_TYPE (query)) &#123; case GST_QUERY_POSITION: /* we should report the current position */ [...] break; case GST_QUERY_DURATION: /* we should report the duration here */ [...] break; case GST_QUERY_CAPS: /* we should report the supported caps here */ [...] break; default: /* just call the default handler */ ret = gst_pad_query_default (pad, parent, query); break; &#125; return ret;&#125; element状态状态可以用来描述element是否初始化，是否准备传送数据，是否正在处理数据。 GST_STATE_NULL element默认状态，不分配任何资源，不加载任何库。 GST_STATE_READY 分配默认资源(runtime-libraries, runtime-memory)，不分配或者定义stream-specific相关的资源，当状态从NULL到READY时，分配任何non-stream-specific资源，加载运行时库。当状态从READY转到NULL时，卸载相关资源，比如硬件设备。注意文件也是流，所以在READY状态下不会分配。 GST_STATE_PAUSED element准备接收和处理数据，对于大部分elements来说PAUSED和PLAYING是一样的，唯一的区别是sink elements，它只接收一次数据然后阻塞住，这时候pipeline处于’prerolled’状态，准备渲染数据。 GST_STATE_PLAYING 在播放状态下sink elements渲染接收的数据，其他elements和PAUSED状态一样。 管理filter状态一般来说，elements继承一些基类，比如sources, sinks and filter/transformation elements。如果是继承这些基类，你就不需要亲自处理状态的改变。你只需继承基类的虚函数start()和stop()。如果不是继承基类，而是继承GstElement，你就必须自己处理状态的改变，比如像demuxer和muxer这种插件。通过虚函数，element可以被通知状态的改变然后初始化必要数据，也可以选择状态改变失败。 注意，向上（NULL =&gt; READY，READY =&gt; PAUSED，PAUSED =&gt; PLAYING）和向下（PLAYING =&gt; PAUSED，PAUSED =&gt; READY，READY =&gt; NULL）状态更改在两个单独的块中处理，向下状态发生变化只有在我们链接到父类的状态更改函数之后才会处理。这是为了安全地处理多个线程的并发访问所必需的。123456789101112131415161718192021222324252627282930313233343536373839404142static GstStateChangeReturngst_my_filter_change_state (GstElement *element, GstStateChange transition);static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GstElementClass *element_class = GST_ELEMENT_CLASS (klass); element_class-&gt;change_state = gst_my_filter_change_state;&#125;static GstStateChangeReturngst_my_filter_change_state (GstElement *element, GstStateChange transition)&#123; GstStateChangeReturn ret = GST_STATE_CHANGE_SUCCESS; GstMyFilter *filter = GST_MY_FILTER (element); switch (transition) &#123; case GST_STATE_CHANGE_NULL_TO_READY: if (!gst_my_filter_allocate_memory (filter)) return GST_STATE_CHANGE_FAILURE; break; default: break; &#125; ret = GST_ELEMENT_CLASS (parent_class)-&gt;change_state (element, transition); if (ret == GST_STATE_CHANGE_FAILURE) return ret; switch (transition) &#123; case GST_STATE_CHANGE_READY_TO_NULL: gst_my_filter_free_memory (filter); break; default: break; &#125; return ret;&#125; 增加属性通过属性可以控制element的行为。属性在_class_init ()函数中定义，在_get_property ()和a _set_property ()函数中设置或者获取。可以在_init ()构造函数中初始化属性值。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/* properties */enum &#123; PROP_0, PROP_SILENT /* FILL ME */&#125;;static void gst_my_filter_set_property (GObject *object, guint prop_id, const GValue *value, GParamSpec *pspec);static void gst_my_filter_get_property (GObject *object, guint prop_id, GValue *value, GParamSpec *pspec);static voidgst_my_filter_class_init (GstMyFilterClass *klass)&#123; GObjectClass *object_class = G_OBJECT_CLASS (klass); /* define virtual function pointers */ object_class-&gt;set_property = gst_my_filter_set_property; object_class-&gt;get_property = gst_my_filter_get_property; /* define properties */ g_object_class_install_property (object_class, PROP_SILENT, g_param_spec_boolean ("silent", "Silent", "Whether to be very verbose or not", FALSE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));&#125;static voidgst_my_filter_set_property (GObject *object, guint prop_id, const GValue *value, GParamSpec *pspec)&#123; GstMyFilter *filter = GST_MY_FILTER (object); switch (prop_id) &#123; case PROP_SILENT: filter-&gt;silent = g_value_get_boolean (value); g_print ("Silent argument was changed to %s\n", filter-&gt;silent ? "true" : "false"); break; default: G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec); break; &#125;&#125;static voidgst_my_filter_get_property (GObject *object, guint prop_id, GValue *value, GParamSpec *pspec)&#123; GstMyFilter *filter = GST_MY_FILTER (object); switch (prop_id) &#123; case PROP_SILENT: g_value_set_boolean (value, filter-&gt;silent); break; default: G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec); break; &#125;&#125; 两种调度模式Gstreamer 有两种调度模式 push mode pull mode 我们之前讨论的_chain ()函数属于push mode，通过调用gst_pad_push ()，使得下游的element的_chain ()被调用。 后续补充]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GStreamer插件之Transform elements]]></title>
    <url>%2F2019%2F03%2F29%2FGStreamer%E6%8F%92%E4%BB%B6%E4%B9%8BTransform-elements%2F</url>
    <content type="text"><![CDATA[前言写了个gstreamer插件继承于基类Transform element. 其中有些概念需要理解一下，特此做下笔记。参考官网链接 Transform elements基于sink和src pad的caps将输入的buffer转换为输出buffer。而输出的caps完全由输入的caps所定义，这表明像解码器这种组件不能够由Transform elements来实现，因为其输出的视频帧的宽高在输入时是被压缩在流当中的，所以输入是没有宽高这种属性的。如下所示的avdec_h264解码组件所示：12345678910111213141516171819202122232425Pad Templates: SRC template: 'src' Availability: Always Capabilities: video/x-raw format: &#123; (string)I420, (string)YUY2, (string)RGB, (string)BGR, (string)Y42B, (string)Y444, (string)YUV9, (string)Y41B, (string)GRAY8, (string)RGB8P, (string)I420, (string)Y42B, (string)Y444, (string)UYVY, (string)NV12, (string)NV21, (string)ARGB, (string)RGBA, (string)ABGR, (string)BGRA, (string)GRAY16_BE, (string)GRAY16_LE, (string)A420, (string)RGB16, (string)RGB15, (string)I420_10BE, (string)I420_10LE, (string)I422_10BE, (string)I422_10LE, (string)Y444_10BE, (string)Y444_10LE, (string)GBR, (string)GBR_10BE, (string)GBR_10LE, (string)A420_10BE, (string)A420_10LE, (string)A422_10BE, (string)A422_10LE, (string)A444_10BE, (string)A444_10LE, (string)GBRA, (string)xRGB, (string)RGBx, (string)xBGR, (string)BGRx, (string)I420_12BE, (string)I420_12LE, (string)I422_12BE, (string)I422_12LE, (string)Y444_12BE, (string)Y444_12LE, (string)GBR_12BE, (string)GBR_12LE, (string)GBRA_12BE, (string)GBRA_12LE &#125; SINK template: 'sink' Availability: Always Capabilities: video/x-h264 alignment: au stream-format: &#123; (string)avc, (string)byte-stream &#125; 典型transform elements包含： audio convertors (audioconvert, audioresample,…) video convertors (colorspace, videoscale, …) filters (capsfilter, volume, colorbalance, …) 要实现transform elements必须关心的是： efficient negotiation both up and downstream efficient buffer alloc and other buffer management transform elements可以使用不同模式： passthrough (no changes are done on the input buffers) in-place (changes made directly to the incoming buffers without requiring a copy or new buffer allocation) metadata changes only transform元素通常也会处理以下事项： flushing, seeking state changes timestamping, this is typically done by copying the input timestamps to the output buffers but subclasses should be able to override this. QoS, avoiding calls to the subclass transform function handle scheduling issues such as push and pull based operation. transform element应在任何时候可以重新协商sink和src caps，并改变操作模式。根据不同的模式，buffer的分配可能采用不同策略。 transform element behaviourProcessingtransform主要由两种处理函数： transform(): Transform the input buffer to the output buffer. The output buffer is guaranteed to be writable and different from the input buffer. transform_ip(): Transform the input buffer in-place. The input buffer is writable and of bigger or equal size than the output buffer. 转换操作有以下模式： passthrough: The element will not make changes to the buffers, buffers are pushed straight through, caps on both sides need to be the same. The element can optionally implement a transform_ip() function to take a look at the data, the buffer does not have to be writable. in-place: Changes can be made to the input buffer directly to obtain the output buffer. The transform must implement a transform_ip() function. copy-transform: The transform is performed by copying and transforming the input buffer to a new output buffer. The transform must implement a transform() function. 当没有使用transform()函数的时候，只有in-place 和 passthrough模式可以使用，这意味着sinkpad和srcpad要一样或者src buffer大于等于sink buffer。 当没有使用transform_ip()函数的时候，只允许passthrough和copy-transforms两种模式，提供这个函数可以避免内存的拷贝。 当没有使用以上两种函数时，只使用passthrough模式。 Negotiation在push mode下transform element的协商总是从sink到src： sinkpad接收到新的caps事件 transform函数算出它可以将此caps转化成什么 尝试不做任何修改，因为我们倾向于不做任何事情 transform配置自身使得可以将sink caps转换到模板src caps transform在srcpad上设置处理输出caps1234567 sinkpad transform srcpadCAPS event | | |------------&gt;| find_transform() | | |-------------------&gt;| | | | CAPS event | | |---------------------&gt;| | &lt;configure caps&gt; &lt;-| | transform 有三个函数执行协商： transform_caps(): Transform the caps on a certain pad to all the possible supported caps on the other pad. The input caps are guaranteed to be a simple caps with just one structure. The caps do not have to be fixed. fixate_caps(): Given a caps on one pad, fixate the caps on the other pad. The target caps are writable. set_caps(): Configure the transform for a transformation between src caps and dest caps. Both caps are guaranteed to be fixed caps. 如果transform_caps()未定义，默认只执行同样的转换。如果set_caps()未定义，我们不关心caps，在这种情况下我们假设没有任何内容写到缓冲区，我们不会为该transform_ip()函数强制执行可写缓冲区（如果存在）。 我们对transform元素需要的一个常见函数是找到从一种格式（src）到另一种格式（dest）的最佳转换。该函数的一些要求是： 有一个固定的src caps 找到一个固定的transform element可以转换成的dest caps dest caps是兼容的并且可被peer elements接受 transform函数倾向于使src caps == dest caps transform函数可以选择性固定dest caps find_transform()函数执行如下: 从一个固定的src caps开始； 检测这些caps是否可以被用作src caps，这通常由元素的padtemplate强制执行； 使用transform_caps()计算所有的可以转换生成的caps 如果原始的caps是transforms的一个子集，尝试caps是否能被peer接受。如果可行，我们可以执行passthrough然后设置src == dest。这只要简单调用gst_pad_peer_query_accept_caps()即可。 如果caps不是固定的，我们需要固定它们。 transform_caps()检索每个转换的caps 使用fixate_caps()固定caps 如果caps是固定的，使用_peer_query_accept_caps()检测peer是否接受他们，如果接受，我们就找到了dest caps。 如果找遍caps还没发现可转换的caps就表明失败了。 如果找到dest caps，使用set_caps()进行配置。 在协商过程之后，transform元素通常是一个稳定的状态。我们可以确定这个状态： src和sink pads有同样的caps passthrough: buffers are inspected but no metadata or buffer data is changed. The input buffers don’t need to be writable. The input buffer is simply pushed out again without modifications. (SCP) 123456 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| pad_push() | | |---------------------&gt;| | | | in-place: buffers are modified in-place, this means that the input buffer is modified to produce a new output buffer. This requires the input buffer to be writable. If the input buffer is not writable, a new buffer has to be allocated from the bufferpool. (SCI) 123456789101112 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | [!writable] | | | alloc buffer | | .-| | | &lt;transform_ip&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | copy transform: a new output buffer is allocate from the bufferpool and data from the input buffer is transformed into the output buffer. (SCC) 1234567891011 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | alloc buffer | | .-| | | &lt;transform&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | src和sink pads有不一样的样的caps in-place: input buffers are modified in-place. This means that the input buffer has a size that is larger or equal to the output size. The input buffer will be resized to the size of the output buffer. If the input buffer is not writable or the output size is bigger than the input size, we need to pad-alloc a new buffer. (DCI) 123456789101112 sinkpad transform srcpad chain() | | |------------&gt;| handle_buffer() | | |-------------------&gt;| | | | [!writable || !size] | | | alloc buffer | | .-| | | &lt;transform_ip&gt; | | | | '&gt;| | | | pad_push() | | |---------------------&gt;| | | | copy transform: a new output buffer is allocated and the data from the input buffer is transformed into the output buffer. The flow is exactly the same as the case with the same-caps negotiation. (DCC) Allocation当transform element配置完成之后，缓冲池需要根据caps开辟内存，主要有两种情况： 当使用passthrough模式的时候不需要在transform element中开辟内存。 当不使用passthrough，并且需要开辟输出buffer。 对于第一种情况，我们不需要查询和配置pool。我们让upstream自动决定是否需要bufferpool，然后我们将从下游到上游进行代理。 对于第二种情况，我们在srcpad设置分配内存池。 为了分配内存，我们还需要知道输出空间的大小，这里有两个函数获取大小： transform_size(): Given a caps and a size on one pad, and a caps on the other pad, calculate the size of the other buffer. This function is able to perform all size transforms and is the preferred method of transforming a size. get_unit_size(): When the input size and output size are always a multiple of each other (audio conversion, ..) we can define a more simple get_unit_size() function. The transform will use this function to get the same amount of units in the source and destination buffers. For performance reasons, the mapping between caps and size is kept in a cache.]]></content>
      <categories>
        <category>GStreamer</category>
      </categories>
      <tags>
        <tag>GStreamer</tag>
        <tag>插件</tag>
        <tag>视频流</tag>
      </tags>
  </entry>
</search>
