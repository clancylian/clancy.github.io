<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CUDA Grid Block Thread</title>
      <link href="/2019/05/28/CUDA-Grid-Block-Thread/"/>
      <url>/2019/05/28/CUDA-Grid-Block-Thread/</url>
      
        <content type="html"><![CDATA[<h2 id="GPU性能"><a href="#GPU性能" class="headerlink" title="GPU性能"></a>GPU性能</h2><p>如下所示，是调用NVIDIA_CUDA-10.1_Samples/1_Utilities/deviceQuery查询的GPU性能。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@ubuntu-B250-HD3:~/NVIDIA_CUDA-10.1_Samples/1_Utilities/deviceQuery$ ./deviceQuery </span><br><span class="line">./deviceQuery Starting...</span><br><span class="line"></span><br><span class="line"> CUDA Device Query (Runtime API) version (CUDART static linking)</span><br><span class="line"></span><br><span class="line">Detected 1 CUDA Capable device(s)</span><br><span class="line"></span><br><span class="line">Device 0: <span class="string">"GeForce GTX 1080 Ti"</span></span><br><span class="line">  CUDA Driver Version / Runtime Version          10.2 / 10.1</span><br><span class="line">  CUDA Capability Major/Minor version number:    6.1</span><br><span class="line">  Total amount of global memory:                 11177 MBytes (11720130560 bytes)</span><br><span class="line">  (28) Multiprocessors, (128) CUDA Cores/MP:     3584 CUDA Cores</span><br><span class="line">  GPU Max Clock rate:                            1645 MHz (1.64 GHz)</span><br><span class="line">  Memory Clock rate:                             5505 Mhz</span><br><span class="line">  Memory Bus Width:                              352-bit</span><br><span class="line">  L2 Cache Size:                                 2883584 bytes</span><br><span class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)</span><br><span class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers</span><br><span class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers</span><br><span class="line">  Total amount of constant memory:               65536 bytes</span><br><span class="line">  Total amount of shared memory per block:       49152 bytes</span><br><span class="line">  Total number of registers available per block: 65536</span><br><span class="line">  Warp size:                                     32</span><br><span class="line">  Maximum number of threads per multiprocessor:  2048</span><br><span class="line">  Maximum number of threads per block:           1024</span><br><span class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</span><br><span class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</span><br><span class="line">  Maximum memory pitch:                          2147483647 bytes</span><br><span class="line">  Texture alignment:                             512 bytes</span><br><span class="line">  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)</span><br><span class="line">  Run time <span class="built_in">limit</span> on kernels:                     Yes</span><br><span class="line">  Integrated GPU sharing Host Memory:            No</span><br><span class="line">  Support host page-locked memory mapping:       Yes</span><br><span class="line">  Alignment requirement <span class="keyword">for</span> Surfaces:            Yes</span><br><span class="line">  Device has ECC support:                        Disabled</span><br><span class="line">  Device supports Unified Addressing (UVA):      Yes</span><br><span class="line">  Device supports Compute Preemption:            Yes</span><br><span class="line">  Supports Cooperative Kernel Launch:            Yes</span><br><span class="line">  Supports MultiDevice Co-op Kernel Launch:      Yes</span><br><span class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0</span><br><span class="line">  Compute Mode:</span><br><span class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</span><br><span class="line"></span><br><span class="line">deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.1, NumDevs = 1</span><br><span class="line">Result = PASS</span><br></pre></td></tr></table></figure><p>首先要明确几个概念：</p><h2 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h2><p><strong>SP</strong>：最基本的处理单元，Streaming Processor，也称为CUDA Core。具体的指令和任务都是在SP上处理的。GPU进行并行计算，也就是很多个SP同时做处理。 从上表可以看出，1080Ti显卡一共有3584 CUDA Cores。</p><p><strong>SM</strong>：多个SP加上其他的一些资源组成一个Streaming Multiprocessor，也叫流处理簇。其他资源如：warp scheduler，register，shared memory/L1Cache，Load/Store Units等。SM可以看做GPU的心脏（对比CPU核心），register和shared memory是SM的稀缺资源。CUDA将这些资源分配给所有驻留在SM中的threads。因此，这些有限的资源就使每个SM中active warps有非常严格的限制，也就限制了并行能力。从上表可以看出，1080Ti显卡一共有28个SM，每个SM有128个SP，所以共有3584个SP。</p><p>需要指出，每个SM包含的SP数量依据GPU架构而不同，Fermi架构GF100是32个，GF10X是48个，Kepler架构都是192个，Maxwell都是128个。相同架构的GPU包含的SM数量则根据GPU的中高低端来定。</p><h2 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h2><p>grid，block，thread，warp是CUDA编程上的概念，以方便程序员软件设计，组织线程，同样的我们给出一个示意图来表示。</p><ul><li>thread(线程)：一个CUDA的并行程序会被以许多个threads来执行。</li><li>block(线程块)：数个threads会被群组成一个block，同一个block中的threads可以同步，也可以通过shared memory通信。</li><li>grid(线程网格)：多个blocks则会再构成grid。</li><li>warp(线程束)：GPU执行程序时的调度单位，目前CUDA的warp的大小为32，同在一个warp的线程，以不同数据资源执行相同的指令，这就是所谓 SIMT。</li></ul><h2 id="执行状态"><a href="#执行状态" class="headerlink" title="执行状态"></a>执行状态</h2><p>CUDA 的 device 实际在执行的时候，会以 Block 为单位，把一个个的 block 分配给 SM 进行运算；而 block 中的thread，又会以warp为单位，把 thread 来做分组计算。目前 CUDA 的 warp 大小都是 32，也就是 32 个 thread 会被群组成一个 warp 来一起执行;同一个 warp 里的 thread，会以不同的数据，执行同样的指令。</p><p>基本上 warp 分组的动作是由 SM 自动进行的，会以连续的方式来做分组。比如说如果有一个 block 里有 128 个 thread 的话，就会被分成四组 warp，第 0-31 个 thread 会是 warp 1、32-63 是 warp 2、64-95 是 warp 3、96-127 是 warp 4。而如果 block 里面的 thread 数量不是 32 的倍数，那他会把剩下的 thread 独立成一个 warp;比如说 thread 数目是 66 的话，就会有三个 warp：0-31、32-63、64-65。由于最后一个 warp 里只剩下两个 thread，所以其实在计算时，就相当于浪费了 30 个 thread 的计算能力。这点是在设定 block 中 thread 数量一定要注意的事!</p><p>一个 SM 一次只会执行一个 block 里的一个 warp，但是 SM 不见得会一次就把这个 warp 的所有指令都执行完；当遇到正在执行的 warp 需要等待的时候(例如存取 global memory 就会要等好一段时间)，就切换到别的 warp 来继续做运算，藉此避免为了等待而浪费时间。所以理论上效率最好的状况，就是在 SM 中有够多的 warp 可以切换，让在执行的时候，不会有「所有 warp 都要等待」的情形发生;因为当所有的 warp 都要等待时，就会变成 SM 无事可做的状况了。</p><p>实际上，warp 也是 CUDA 中，每一个 SM 执行的最小单位；如果 GPU 有 16 个 SM 的话，也就代表他真正在执行的thread数目会是 32*16 个(resident thread)。不过由于 CUDA 是要透过 warp 的切换来隐藏 thread 的延迟、等待，来达到大量平行化的目的，所以会用所谓的 active thread 这个名词来代表一个 SM 里同时可以处理的 thread 数目。 active warp是指已经分配给SM的warp，并且该warp需要的资源（寄存器）也已经分配。</p><p>而在 block 的方面，一个 SM 可以同时处理多个 thread block，当其中有 block 的所有 thread 都处理完后，他就会再去找其他还没处理的 block 来处理。假设有 16 个 SM、64 个 block、每个 SM 可以同时处理三个 block 的话，那一开始执时，device 就会同时处理 48 个 block，而剩下的 16 个 block 则会等 SM 有处理完 block 后，再进到 SM 中处理，直到所有 block 都处理结束。</p><p>为一个SM指定了一个或多个要执行的线程块时，它会将其分成warp块，并由SIMT单元进行调度。将块分割为warp的方法总是相同的，每个warp都包含连续的线程，递增线程索引，第一个warp中包含全局线程过索引0-31。每发出一条指令时，SIMT单元都会选择一个已准备好执行的warp块，并将指令发送到该warp块的活动线程。Warp块每次执行一条通用指令，因此在warp块的全部32个线程执行同一条路径时，可达到最高效率。如果一个warp块的线程通过独立于数据的条件分支而分散，warp块将连续执行所使用的各分支路径，而禁用未在此路径上的线程，完成所有路径时，线程重新汇聚到同一执行路径下，其执行时间为各时间总和。分支仅在warp块内出现，不同的warp块总是独立执行的–无论它们执行的是通用的代码路径还是彼此无关的代码路径。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>一个SM可以同时处理多个线程块，warp是SM最小执行单元。比如一个SM可以同时处理3个线程块，每个线程块有256个线程，那么就有3*256/32=24warp，同一时刻SM只能执行一个warp。注意只有一个block全部warp执行完才会换其它block来执行，同一个block的所有线程必定在同一个SM执行。</li><li>注意区分active warp和resident thread概念，active warp不一定在SM执行，而是分配好资源，等待SM调度。一个SM不一定要全部执行完，比如访存的时候可以换入其它warp来计算。这样就可以隐藏thread延迟、等待。</li><li>线程块数量一般分配为SM个数的8倍。</li><li>一个线程块分配的线程数是32的倍数。</li><li>线程块和线程网格都是三维索引。</li><li>尽量减少线程束分歧产生。</li><li>注意上表每个SM最大支持的线程数，以及每个线程块最大线程数。</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>每个SM可以同时执行多少个block?</p><p>充分利用资源的话每个SM可以同时有多少个warp ?</p><p>block合理设计？</p><p>##　参考链接</p><p><a href="https://blog.csdn.net/junparadox/article/details/50540602" target="_blank" rel="noopener">https://blog.csdn.net/junparadox/article/details/50540602</a></p><p><a href="https://blog.csdn.net/yu132563/article/details/52548913" target="_blank" rel="noopener">https://blog.csdn.net/yu132563/article/details/52548913</a></p>]]></content>
      
      
      <categories>
          
          <category> CUDA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
            <tag> GPU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>perf 安装及使用</title>
      <link href="/2019/05/23/perf%20%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
      <url>/2019/05/23/perf%20%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="perf-安装及使用"><a href="#perf-安装及使用" class="headerlink" title="perf 安装及使用"></a>perf 安装及使用</h1><h2 id="perf-安装"><a href="#perf-安装" class="headerlink" title="perf 安装"></a>perf 安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install linux-tools-common</span><br><span class="line"><span class="comment">## 注意版本号</span></span><br><span class="line">$ sudo apt-get install linux-tools-4.4.0-24-generic linux-cloud-tools-4.4.0-24-generic linux-tools-generic linux-cloud-tools-generic</span><br></pre></td></tr></table></figure><h2 id="perf-命令"><a href="#perf-命令" class="headerlink" title="perf 命令"></a>perf 命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@ubuntu-B250-HD3:~$ perf</span><br><span class="line"></span><br><span class="line"> usage: perf [--version] [--<span class="built_in">help</span>] [OPTIONS] COMMAND [ARGS]</span><br><span class="line"></span><br><span class="line"> The most commonly used perf commands are:</span><br><span class="line">   annotate        Read perf.data (created by perf record) and display annotated code</span><br><span class="line">   archive         Create archive with object files with build-ids found <span class="keyword">in</span> perf.data file</span><br><span class="line">   bench           General framework <span class="keyword">for</span> benchmark suites</span><br><span class="line">   buildid-cache   Manage build-id cache.</span><br><span class="line">   buildid-list    List the buildids <span class="keyword">in</span> a perf.data file</span><br><span class="line">   c2c             Shared Data C2C/HITM Analyzer.</span><br><span class="line">   config          Get and <span class="built_in">set</span> variables <span class="keyword">in</span> a configuration file.</span><br><span class="line">   data            Data file related processing</span><br><span class="line">   diff            Read perf.data files and display the differential profile</span><br><span class="line">   evlist          List the event names <span class="keyword">in</span> a perf.data file</span><br><span class="line">   ftrace          simple wrapper <span class="keyword">for</span> kernel<span class="string">'s ftrace functionality</span></span><br><span class="line"><span class="string">   inject          Filter to augment the events stream with additional information</span></span><br><span class="line"><span class="string">   kallsyms        Searches running kernel for symbols</span></span><br><span class="line"><span class="string">   kmem            Tool to trace/measure kernel memory properties</span></span><br><span class="line"><span class="string">   kvm             Tool to trace/measure kvm guest os</span></span><br><span class="line"><span class="string">   list            List all symbolic event types</span></span><br><span class="line"><span class="string">   lock            Analyze lock events</span></span><br><span class="line"><span class="string">   mem             Profile memory accesses</span></span><br><span class="line"><span class="string">   record          Run a command and record its profile into perf.data</span></span><br><span class="line"><span class="string">   report          Read perf.data (created by perf record) and display the profile</span></span><br><span class="line"><span class="string">   sched           Tool to trace/measure scheduler properties (latencies)</span></span><br><span class="line"><span class="string">   script          Read perf.data (created by perf record) and display trace output</span></span><br><span class="line"><span class="string">   stat            Run a command and gather performance counter statistics</span></span><br><span class="line"><span class="string">   test            Runs sanity tests.</span></span><br><span class="line"><span class="string">   timechart       Tool to visualize total system behavior during a workload</span></span><br><span class="line"><span class="string">   top             System profiling tool.</span></span><br><span class="line"><span class="string">   probe           Define new dynamic tracepoints</span></span><br><span class="line"><span class="string">   trace           strace inspired tool</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> See '</span>perf <span class="built_in">help</span> COMMAND<span class="string">' for more information on a specific command.</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>命令</th><th>作用</th></tr></thead><tbody><tr><td>1</td><td>annotate</td><td>解析perf record生成的perf.data文件，显示被注释的代码。</td></tr><tr><td>2</td><td>archive</td><td>根据数据文件记录的build-id，将所有被采样到的elf文件打包。利用此压缩包，可以再任何机器上分析数据文件中记录的采样数据。</td></tr><tr><td>3</td><td>bench</td><td>perf中内置的benchmark，目前包括两套针对调度器和内存管理子系统的benchmark。</td></tr><tr><td>4</td><td>buildid-cache</td><td>管理perf的buildid缓存，每个elf文件都有一个独一无二的buildid。buildid被perf用来关联性能数据与elf文件。</td></tr><tr><td>5</td><td>buildid-list</td><td>列出数据文件中记录的所有buildid。</td></tr><tr><td>6</td><td>diff</td><td>对比两个数据文件的差异。能够给出每个符号（函数）在热点分析上的具体差异。</td></tr><tr><td>7</td><td>evlist</td><td>列出数据文件perf.data中所有性能事件。</td></tr><tr><td>8</td><td>inject</td><td>该工具读取perf record工具记录的事件流，并将其定向到标准输出。在被分析代码中的任何一点，都可以向事件流中注入其它事件。</td></tr><tr><td>9</td><td>kmem</td><td>针对内核内存（slab）子系统进行追踪测量的工具</td></tr><tr><td>10</td><td>kvm</td><td>用来追踪测试运行在KVM虚拟机上的Guest OS。</td></tr><tr><td>11</td><td>list</td><td>列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点。</td></tr><tr><td>12</td><td>lock</td><td>分析内核中的锁信息，包括锁的争用情况，等待延迟等。</td></tr><tr><td>13</td><td>mem</td><td>内存存取情况</td></tr><tr><td>14</td><td>record</td><td>收集采样信息，并将其记录在数据文件中。随后可通过其它工具对数据文件进行分析。</td></tr><tr><td>15</td><td>report</td><td>读取perf record创建的数据文件，并给出热点分析结果。</td></tr><tr><td>16</td><td>sched</td><td>针对调度器子系统的分析工具。</td></tr><tr><td>17</td><td>script</td><td>执行perl或python写的功能扩展脚本、生成脚本框架、读取数据文件中的数据信息等。</td></tr><tr><td>18</td><td>stat</td><td>执行某个命令，收集特定进程的性能概况，包括CPI、Cache丢失率等。</td></tr><tr><td>19</td><td>test</td><td>perf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能。</td></tr><tr><td>20</td><td>timechart</td><td>针对测试期间系统行为进行可视化的工具</td></tr><tr><td>21</td><td>top</td><td>类似于linux的top命令，对系统性能进行实时分析。</td></tr><tr><td>22</td><td>trace</td><td>关于syscall的工具。</td></tr><tr><td>23</td><td>probe</td><td>用于定义动态检查点。</td></tr></tbody></table><h2 id="perf-使用"><a href="#perf-使用" class="headerlink" title="perf 使用"></a>perf 使用</h2><p>系统级性能优化通常包括两个阶段：性能剖析（performance profiling）和代码优化。</p><p>性能剖析的目标是寻找性能瓶颈，查找引发性能问题的原因及热点代码。</p><p>代码优化的目标是针对具体性能问题而优化代码或编译选项，以改善软件性能。</p><h3 id="perf-list"><a href="#perf-list" class="headerlink" title="perf list"></a>perf list</h3><p>perf list 可以显示所有支持的事件类型，可以显示特定模块支持的perf事件：hw/cache/pmu都是硬件相关的；tracepoint基于内核的ftrace；sw实际上是内核计数器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@ubuntu-B250-HD3:~$ sudo perf list</span><br><span class="line"></span><br><span class="line">List of pre-defined events (to be used <span class="keyword">in</span> -e):</span><br><span class="line"></span><br><span class="line">  branch-instructions OR branches                    [Hardware event]</span><br><span class="line">  branch-misses                                      [Hardware event]</span><br><span class="line">  bus-cycles                                         [Hardware event]</span><br><span class="line">  cache-misses                                       [Hardware event]</span><br><span class="line">  cache-references                                   [Hardware event]</span><br><span class="line">  cpu-cycles OR cycles                               [Hardware event]</span><br><span class="line">  instructions                                       [Hardware event]</span><br><span class="line">  ref-cycles                                         [Hardware event]</span><br><span class="line"></span><br><span class="line">  alignment-faults                                   [Software event]</span><br><span class="line">  bpf-output                                         [Software event]</span><br><span class="line">  context-switches OR cs                             [Software event]</span><br><span class="line">  ...</span><br><span class="line">  minor-faults                                       [Software event]</span><br><span class="line">  page-faults OR faults                              [Software event]</span><br><span class="line">  task-clock                                         [Software event]</span><br><span class="line"></span><br><span class="line">  L1-dcache-load-misses                              [Hardware cache event]</span><br><span class="line">  L1-dcache-loads                                    [Hardware cache event]</span><br><span class="line">  L1-dcache-stores                                   [Hardware cache event]</span><br><span class="line">　...</span><br><span class="line">  iTLB-loads                                         [Hardware cache event]</span><br><span class="line">  node-load-misses                                   [Hardware cache event]</span><br><span class="line">  node-loads                                         [Hardware cache event]</span><br><span class="line">  node-store-misses                                  [Hardware cache event]</span><br><span class="line">  node-stores                                        [Hardware cache event]</span><br><span class="line"></span><br><span class="line">  branch-instructions OR cpu/branch-instructions/    [Kernel PMU event]</span><br><span class="line">  branch-misses OR cpu/branch-misses/                [Kernel PMU event]</span><br><span class="line">  bus-cycles OR cpu/bus-cycles/                      [Kernel PMU event]</span><br><span class="line">  ...</span><br><span class="line">  cycles-ct OR cpu/cycles-ct/                        [Kernel PMU event]</span><br><span class="line">  cycles-t OR cpu/cycles-t/                          [Kernel PMU event]</span><br><span class="line">  el-abort OR cpu/el-abort/                          [Kernel PMU event]</span><br></pre></td></tr></table></figure><h3 id="perf-stat"><a href="#perf-stat" class="headerlink" title="perf stat"></a>perf stat</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@ubuntu-<span class="keyword">B250-HD3:~$ </span>sudo perf stat</span><br><span class="line"></span><br><span class="line"> Performance counter stats for <span class="string">'system wide'</span>:</span><br><span class="line"></span><br><span class="line">      <span class="number">78762</span>.<span class="number">210390</span>      cpu-<span class="keyword">clock </span>(msec)          <span class="comment">#    8.000 CPUs utilized          </span></span><br><span class="line">           <span class="number">102</span>,<span class="number">321</span>      <span class="built_in">context</span>-<span class="keyword">switches </span>         <span class="comment">#    0.001 M/sec                  </span></span><br><span class="line">               <span class="number">888</span>      cpu-migrations            <span class="comment">#    0.011 K/sec                  </span></span><br><span class="line">           <span class="number">102</span>,<span class="number">842</span>      page-faults               <span class="comment">#    0.001 M/sec                  </span></span><br><span class="line">    <span class="number">34</span>,<span class="number">026</span>,<span class="number">798</span>,<span class="number">403</span>      cycles                    <span class="comment">#    0.432 GHz                    </span></span><br><span class="line">    <span class="number">34</span>,<span class="number">823</span>,<span class="number">881</span>,<span class="number">180</span>      <span class="keyword">instructions </span>             <span class="comment">#    1.02  insn per cycle         </span></span><br><span class="line">     <span class="number">7</span>,<span class="number">258</span>,<span class="number">813</span>,<span class="number">402</span>      <span class="keyword">branches </span>                 <span class="comment">#   92.161 M/sec                  </span></span><br><span class="line">        <span class="number">59</span>,<span class="number">271</span>,<span class="number">180</span>      <span class="keyword">branch-misses </span>            <span class="comment">#    0.82% of all branches        </span></span><br><span class="line"></span><br><span class="line">       <span class="number">9</span>.<span class="number">845475012</span> seconds time elapsed</span><br></pre></td></tr></table></figure><ul><li>cpu-clock：任务真正占用的处理器时间，单位为ms。CPUs utilized = task-clock / time elapsed，CPU的占用率。</li><li>context-switches：程序在运行过程中上下文的切换次数。</li><li>CPU-migrations：程序在运行过程中发生的处理器迁移次数。Linux为了维持多个处理器的负载均衡，在特定条件下会将某个任务从一个CPU迁移到另一个CPU。</li><li>CPU迁移和上下文切换：发生上下文切换不一定会发生CPU迁移，而发生CPU迁移时肯定会发生上下文切换。发生上下文切换有可能只是把上下文从当前CPU中换出，下一次调度器还是将进程安排在这个CPU上执行。</li><li>page-faults：缺页异常的次数。当应用程序请求的页面尚未建立、请求的页面不在内存中，或者请求的页面虽然在内存中，但物理地址和虚拟地址的映射关系尚未建立时，都会触发一次缺页异常。另外TLB不命中，页面访问权限不匹配等情况也会触发缺页异常。</li><li>cycles：消耗的处理器周期数。如果把被ls使用的cpu cycles看成是一个处理器的，那么它的主频为2.486GHz。可以用cycles / task-clock算出。</li><li>stalled-cycles-frontend：指令读取或解码的质量步骤，未能按理想状态发挥并行左右，发生停滞的时钟周期。</li><li>stalled-cycles-backend：指令执行步骤，发生停滞的时钟周期。</li><li>instructions：执行了多少条指令。IPC为平均每个cpu cycle执行了多少条指令。</li><li>branches：遇到的分支指令数。</li><li>branch-misses：是预测错误的分支指令数。</li></ul><p>perf stat 常用参数：</p><pre><code>-a, --all-cpus        显示所有CPU上的统计信息-C, --cpu &lt;cpu&gt;       显示指定CPU的统计信息-c, --scale           scale/normalize counters-D, --delay &lt;n&gt;       ms to wait before starting measurement after program start-d, --detailed        detailed run - start a lot of events-e, --event &lt;event&gt;   event selector. use &apos;perf list&apos; to list available events-G, --cgroup &lt;name&gt;   monitor event in cgroup name only-g, --group           put the counters into a counter group-I, --interval-print &lt;n&gt;                      print counts at regular interval in ms (&gt;= 10)-i, --no-inherit      child tasks do not inherit counters-n, --null            null run - dont start any counters-o, --output &lt;file&gt;   输出统计信息到文件-p, --pid &lt;pid&gt;       stat events on existing process id-r, --repeat &lt;n&gt;      repeat command and print average + stddev (max: 100, forever: 0)-S, --sync            call sync() before starting a run-t, --tid &lt;tid&gt;       stat events on existing thread id</code></pre><h3 id="perf-top"><a href="#perf-top" class="headerlink" title="perf top"></a>perf top</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ sudo perf top</span><br><span class="line"></span><br><span class="line">Samples: 147K of event <span class="string">'cycles:ppp'</span>, Event count (approx.): 59239863864</span><br><span class="line">Overhead  Shared Object                                 Symbol</span><br><span class="line">   9.86%  [kernel]                                      [k] do_syscall_64</span><br><span class="line">   5.12%  [kernel]                                      [k] syscall_return_via_sysret</span><br><span class="line">   3.12%  libcuda.so.418.56                             [.] 0x00000000002fb584</span><br><span class="line">   2.99%  libgomp.so.1.0.0                              [.] 0x0000000000011b27</span><br><span class="line">   1.82%  [kernel]                                      [k] __schedule</span><br><span class="line">   1.21%  [kernel]                                      [k] pick_next_task_fair</span><br><span class="line">   1.07%  [kernel]                                      [k] _raw_spin_lock</span><br><span class="line">   1.00%  [unknown]                                     [k] 0xfffffe000013a01b</span><br><span class="line">   0.98%  libpthread-2.23.so                            [.] pthread_mutex_lock</span><br><span class="line">   0.81%  [kernel]                                      [k] prepare_exit_to_usermode</span><br><span class="line">   0.81%  libc-2.23.so                                  [.] __sched_yield</span><br><span class="line">   0.80%  [kernel]                                      [k] cpuacct_charge</span><br><span class="line">   0.79%  libpthread-2.23.so                            [.] pthread_mutex_unlock</span><br><span class="line">   0.76%  [kernel]                                      [k] clear_page_erms</span><br><span class="line">   0.69%  [kernel]                                      [k] native_sched_clock</span><br><span class="line">   0.69%  [kernel]                                      [k] update_curr</span><br><span class="line">   0.63%  [kernel]                                      [k] yield_task_fair</span><br></pre></td></tr></table></figure><ul><li>第一列：符号引发的性能事件的比例，指占用的cpu周期比例。</li><li>第二列：符号所在的DSO(Dynamic Shared Object)，可以是应用程序、内核、动态链接库、模块。</li><li>第三列：DSO的类型。[.]表示此符号属于用户态的ELF文件，包括可执行文件与动态链接库；[k]表述此符号属于内核或模块。</li><li>第四列：符号名。有些符号不能解析为函数名，只能用地址表示。</li></ul><p>perf top 常用的选项：</p><ul><li>-e <event>：指明要分析的性能事件。</event></li><li>-p <pid>：Profile events on existing Process ID (comma sperated list). 仅分析目标进程及其创建的线程。</pid></li><li>-k <path>：Path to vmlinux. Required for annotation functionality. 带符号表的内核映像所在的路径。</path></li><li>-K：不显示属于内核或模块的符号。</li><li>-U：不显示属于用户态程序的符号。</li><li>-d <n>：界面的刷新周期，默认为2s，因为perf top默认每2s从mmap的内存区域读取一次性能数据。</n></li><li>-g：得到函数的调用关系图。</li></ul><h3 id="perf-reocrd"><a href="#perf-reocrd" class="headerlink" title="perf reocrd"></a>perf reocrd</h3><p>使用 top 和 stat之后，已经大致有数了。要进一步分析，便需要一些粒度更细的信息。比如说已经断定目标程序计算量较大，也许是因为有些代码写的不够精简。那么面对长长的代码文件，究竟哪几行代码需要进一步修改呢？这便需要使用perf record 记录单个函数级别的统计信息，并使用 perf report 来显示统计结果。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo perf record -g -e cpu-clock ./<span class="built_in">test</span></span><br><span class="line">$ sudo perf report</span><br><span class="line"><span class="comment">## 查看百分比比较高的为耗时比较严重的函数</span></span><br></pre></td></tr></table></figure><p>perf record 常用参数：</p><ul><li>-e record指定PMU事件</li><li>–filter  event事件过滤器</li><li>-a  录取所有CPU的事件</li><li>-p  录取指定pid进程的事件</li><li>-o  指定录取保存数据的文件名</li><li>-g  使能函数调用图功能</li><li>-C 录取指定CPU的事件</li></ul><p>perf report 常用参数：</p><ul><li>-i  导入的数据文件名称，如果没有则默认为perf.data</li><li>-g  生成函数调用关系图，<strong>此时内核要打开CONFIG_KALLSYMS；用户空间库或者执行文件需要带符号信息(not stripped)，编译选项需要加上-g。</strong></li><li>–sort  从更高层面显示分类统计信息，比如： pid, comm, dso, symbol, parent, cpu,socket, srcline, weight, local_weight.</li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>还有很多功能，带后续慢慢挖掘。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.cnblogs.com/arnoldlu/p/6241297.html" target="_blank" rel="noopener">https://www.cnblogs.com/arnoldlu/p/6241297.html</a></p><p><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/index.html</a></p>]]></content>
      
      
      <categories>
          
          <category> perf </category>
          
      </categories>
      
      
        <tags>
            
            <tag> perf </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PaperReading:RetinaNet</title>
      <link href="/2019/05/10/PaperReading-RetinaNet/"/>
      <url>/2019/05/10/PaperReading-RetinaNet/</url>
      
        <content type="html"><![CDATA[<h1 id="Focal-Loss-for-Dense-Object-Detection"><a href="#Focal-Loss-for-Dense-Object-Detection" class="headerlink" title="Focal Loss for Dense Object Detection"></a>Focal Loss for Dense Object Detection</h1><p><a href="https://github.com/facebookresearch/Detectron" target="_blank" rel="noopener">代码链接</a>　<a href="https://arxiv.org/abs/1708.02002" target="_blank" rel="noopener">论文链接</a></p><p>作者提出了focal loss，通过在交叉熵损失函数中加入一个衰减系数，达到可以降低那些”分类好“的样本的损失，从而更加关注那个误分类的样本。根据这个损失函数，作者训练了一个检测器RetinaNet，性能比当前最好的two-stage检测器性能还高，在COCO数据集可以达到40.8 AP。</p><p>之前最好的目标检测器还是基于two-stage，基于候选框驱动机制。先生成候选框目标集，然后在分类回归定位。那么one-stage是否也可以达到同样的精度呢？one-stage通过密集采样，基于anchor机制采样不同目标位置，不同scale，不同ratios。比如YOLO，SSD等方法。</p><p>作者提出的RetinaNet可以匹敌two-stage检测器，比如Feature Pyramid Network (FPN)、Mask R-CNN、Faster R-CNN。作者发现了类别不均衡是导致one-stage检测器精度上不去的原因。在two-stage检测器中一般有提取候选框的步骤，所以可以很快降低候选框数目，这其实以及有降低类别不均衡的意思在里面，因为图像大部分地方都是背景，在two-stage方法中解决样本不均衡一般采用启发式采样，比如前景和背景比例保持在1:3左右，或者使用难样本挖掘（online hard example mining (OHEM)）。然而在one-stage中一般要处理100k左右的候选框，虽然也使用启发式采样，但是效率很低，比如使用bootstrapping或者hard example mining等方法。</p><p>样本不均衡所带来的问题：1训练效率不高，因为大部分的样本为easy-negatives，对学习没有帮助；2大量的easy-negatives会使训练overwhelm从而使模型退化。</p><p>很多论文都在解决损失函数鲁棒性问题，比如Huber loss，但是大部分的损失函数都是致力于离群点，降低hard examples的损失权重，相反的focal loss主要设计为处理样本不均衡问题，致力于降低非离群点也就是easy example的损失权重。</p><h2 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h2><p>标准交叉熵损失函数：<br>$$<br>CE(p,y)= \left{<br>\begin{aligned}<br>-log(p) &amp;&amp; if(y = 1) \<br>-log(1-p) &amp;&amp; otherwise<br>\end{aligned}<br>\right.<br>$$<br>设<br>$$<br>p_t = \left{<br>\begin{aligned}<br>p &amp;&amp; if(y = 1) \<br>1-p &amp;&amp; otherwise<br>\end{aligned}<br>\right.<br>$$<br>可以得到CE(p, y) = CE(pt ) = − log(pt )</p><p>画出曲线可以分析看到即使是容易分类的样本，数量一多，也会造成很大的损失。实验表明样本不均衡使得易分类样本的损失占大部分，主导了梯度。作者提出的损失函数：<br>$$<br>FL(p_t ) = −(1 − p_t )^γ log(p_t )<br>$$</p><p>当样本误分类的时候pt很小，系数接近于１，系数对loss没啥影响；当pt接近于１的时候，系数接近０，对于易分类的样本可以降低权重。通过降低易分类样本的损失权重反过来增加了分类错误的损失的重要性。</p><p>作者还加了一个系数可以提高精度：<br>$$<br>FL(p_t ) = −α_t (1 − p_t )^γ log(p_t )<br>$$<br><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/retinanet.png" alt="图片"></p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PaperReading:RetinaFace</title>
      <link href="/2019/05/07/PaperReading-RetinaFace/"/>
      <url>/2019/05/07/PaperReading-RetinaFace/</url>
      
        <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>虽然对于无约束人脸检测取得了巨大进步，但是精度和速度依然是一个挑战。作者提出一种鲁棒的single-stage人脸检测器，加入extra-supervised和self-supervised模块，提高人脸检测性能的多任务学习方法。论文主要贡献有５点：</p><ul><li>手动标注WIDER FACE数据集人脸关键点，并且在难人脸检测上由于额外监督信号的帮助取得了巨大的提高。</li><li>在现有的模块上并行加入self-supervised解码分支预测3D人脸信息分支。</li><li>在WIDER FACE hard test数据集上提高1.1%（达到91.4%）。</li><li>在IJB-C test set上测试结果表明可以提高ArcFace在人脸验证精度(TAR=89.59% for FAR=1e-6)。</li><li>使用轻量级骨干网络，RetinaFace在CPU上测试VGA图片可以达到实时。</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>此片论文包含face detection、face alignment、pixel-wise face parsing、3D dense correspondence regres-sion等任务。</p><p>首先论文灵感来源于一般目标检测rcnn系列、SSD、YOLO系列、FPN、Focal loss。和一般的目标检测不同，人脸检测的宽高比一般是1:1到1:1.5之间，但是大小可以从几个像素到几千个像素。目前比较流行的方法是one-stage方法，速度比较快，所以作者基于one-stage采用多任务方法得到state-of-the-art结果。</p><p>《Joint cascade face detection and alignment》论文提出的联合人脸检测和人脸对齐可以提取到更好的人脸特征。所以基于MTCNN和STN方法灵感，作者加入５个人脸关键点，由于训练数据的限制JDA 、MTCNN、和STN没有验证过小人脸检测是否可以从额外的５个关键点中获益。通过加入５个关键点，作者想看看能否在WIDER FACE hard test取得更好的性能。</p><p>Mask R-CNN通过加入了Mask并行预测分支之后性能得到了很大的提升。证实了密集pixel-wise标签可以提高检测。然而WIDER FACE对密集标注很难实施，能够使用非监督方法来进一步提高人脸检测呢？</p><p>在FAN论文中，提出了一种anchor-level attention map来提高遮挡的人脸检测，但是这个方法太粗糙，并且不包含语义信息。目前，self-supervised 3D morphable models在3D人脸建模取得良好成绩，尤其是Mesh Decoder达到了实时。但是应用Mesh Decoder方法有两个难点：１相机参数难以估计精确；２特征漂移。本篇论文作者使用自监督学习方法加入额外分支来预测3D人脸形状。</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><strong>Image pyramid v.s. feature pyramid</strong></p><p><strong>Two-stage v.s. single-stage</strong></p><p><strong>Context Modelling</strong></p><p><strong>Multi-task Learning</strong></p><h2 id="RetinaFace"><a href="#RetinaFace" class="headerlink" title="RetinaFace"></a>RetinaFace</h2><h3 id="多任务损失函数"><a href="#多任务损失函数" class="headerlink" title="多任务损失函数"></a>多任务损失函数</h3><p>$$<br>L = L_{cls}(p_i ,p^∗_i) + λ_1p^∗_iL_{box}(t_i,t^∗_i)</p><ul><li>λ_2p^∗_iL_{pts}(l_i,l_i^∗) + λ_3p^∗_iL_{pixel}<br>$$</li></ul><p>其中Lcls代表分类损失，softmax，pi表示anchor i预测为人脸的概率，p*为１表示为正样本，为０表示负样本。</p><p>其中Lbox为边框回归损失，smooth-L1，t i = {t x , t y , t w , t h }，对中心点和宽高进行归一化操作，对于正样本anchor的损失。</p><p>其中L pts为５个关键点回归，类似边框回归中的中心点回归。</p><p>其中L pixel为密集回归损失函数，具体函数见后面。</p><p>λ 1 -λ 3为权重分别设置为0.25 0.1 0.01</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人脸检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PaperReading: FaceBoxes</title>
      <link href="/2019/05/05/PaperReading:FaceBoxes/"/>
      <url>/2019/05/05/PaperReading:FaceBoxes/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>​    人脸检测是人脸对齐、人脸识别、人脸跟踪的基础。目前人脸检测还面临着很多挑战，主要还是精度和速度的问题。很多研究都是为了解决这两个问题。早期的方法是基于人工特征，以V-J人脸检测为代表，大量的研究都是设计一个鲁棒的特征和训练一个有效的分类器。cascade structure和DMP模型都能获得不错的性能。但是这些方法都是基于不鲁棒的特征，虽然速度快，但是在不同场景下精度不高。另一种方法是基于卷积神经网络。卷积网络对于多变人脸具有很高的鲁棒性，但是在速度上却不快，尤其是在CPU设备上面。</p><p>​    这两种方法有各自的优点。为了在速度和精度上能够达到较好的性能，一种自然的想法是结合两种类型的方法，也就是采用级联的卷积神经网络，比如MTCNN。但是基于级联的卷积神经网络会带来三个问题：1.速度和人脸数量相关，人脸越多速度越慢；2.级联检测器都是基于局部优化，训练复杂；3.不能达到实时。</p><p>​    此篇文章灵感来源于Faster R-CNN中的RPN以及SSD的多尺度机制。这是一个ONE-STAGE网络，网络结构主要包含两部分：1.Rapidly Digested Convolutional Layers (RDCL)和Multiple Scale Convolutional Layers (MSCL)。RDCL是为了解决实时问题，MSCL主要为了丰富感受野，使不同层的anchor离散化，解决人脸多尺度问题。除此之外，作者还提出Anchor densification strategy让不同类型的anchor有相同的密度，这极大提高小人脸的召回率。对于VGA图片(640x480)在CPU可以达到20FPS，在GPU可以达到125FPS。作者认为他们工作的贡献包含四部分，除了以上说的三点之外，还包含：在AFW, PASCAL face, and FDDB datasets取得最好性能(what? 这也算？)</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/faceboxes_framework.jpg" alt="网络结构"></p><h3 id="RDCL"><a href="#RDCL" class="headerlink" title="RDCL"></a>RDCL</h3><ul><li><strong>缩小输入的空间大小：</strong>为了快速减小输入的空间尺度大小，在卷积核池化上使用了一系列的大的stride，在Conv1、Pool1、Conv2、Pool2上stride分别是4、2、2、2，RDCL的stride一共是32，意味着输入的尺度大小被快速减小了32倍。</li><li><strong>选择合适的kernel size：</strong>一个网络开始的一些层的kernel size应该比较小以用来加速，同时也应该足够大用以减轻空间大小减小带来的信息损失。Conv1、Conv2以及所有的Pool层分别选取7x7，5x5，3x3的kernel size。</li><li><strong>减少输出通道数：</strong>使用C.ReLU来减少输出通道数。为啥提出这个激活函数有专门的论文参考，引：网络的前部，网络倾向于同时捕获正负相位的信息，但ReLU会抹掉负响应。 这造成了卷积核会存在冗余。</li></ul><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/crelu.jpg" alt="crelu"></p><h3 id="MSCL"><a href="#MSCL" class="headerlink" title="MSCL"></a>MSCL</h3><p>　　将RPN作为一个人脸检测器，不能获取很好的性能有以下两个原因：</p><ul><li><p>RPN中的anchor只和最后一个卷积层相关，其中的特征和分辨率对于处理人脸变化问题上太弱。</p></li><li><p>anchor相应的层使用一系列不同的尺度来检测人脸，但只有单一的感受野，不能匹配不同尺度的人脸。</p></li></ul><p>  为解决这个问题，对MSCL从以下两个角度去设计：</p><ul><li><p><strong>Multi-scale design along the dimension of network depth.</strong> Anchor在多尺度的feature map上面取，类似SSD。 </p></li><li><p><strong>Multi-scale design along the dimension of network width.</strong>使用inception模块，内部使用不同大小的卷积核，可以捕获到更多的尺度信息。</p></li></ul><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/inception.jpg" alt="inception"></p><h3 id="Anchor-densification-strategy"><a href="#Anchor-densification-strategy" class="headerlink" title="Anchor densification strategy"></a>Anchor densification strategy</h3><p>​    对于Anchor作者使用1:1的宽高比，原因是因为人脸框接近正方形。 Inception3的anchor尺度为32x32，64x64，128x128，Conv3_2、Conv4_2的尺度分别为256x256和512x512。</p><p>​    对于anchor相应层的间隔相当于步长大小、比如，对于Conv3 2步长是64，anchor大小256x256，意思是对于输入图片，每隔64个像素有一个256x256的anchor。作者提出了一个anchor密度概念：<br>$$<br>A_{density} = \frac{A_{scale}}{A_{interval}}<br>$$<br>其中分子表示anchor大小，分母表示anchor间隔，对于anchor间隔一般是默认的，也就是步长大小，分别为32、32、32、64、128。根据式子计算出来的密度分别为1、2、4、4、4。由此可以看到对于小人脸anchor太稀疏，密度太低，会导致小人脸的召回率下降。为了消除这个不平衡，作者提出了一种策略，在原来的anchor中心均匀叠加n^2个anchor，以保证密度相同，所以对于32x32的anchor叠加为原来的４倍，对于64x64的anchor叠加为原来的２倍。</p><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/anchor-expand.jpg" alt="anchor"></p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h3><p>WIDER FACE的子集，12880个图片。</p><h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><ul><li>Color distortion</li><li>Random cropping</li><li>Scale transformation</li><li>Horizontal flipping</li><li>Face-box filter</li></ul><h3 id="匹配策略"><a href="#匹配策略" class="headerlink" title="匹配策略"></a>匹配策略</h3><p>在训练时需要判断哪个anchor是和哪个bounding box对应。首先使用jaccard overlap将每个脸和anchor对应起来，然后对anchor和任意脸jaccard overlap高于阈值（0.35）的匹配起来。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>和Faster R-CNN中的RPN用同样的loss，一个2分类的softmax loss用来做分类，smooth L1用来做回归。</p><h3 id="Hard-negative-mining"><a href="#Hard-negative-mining" class="headerlink" title="Hard negative mining:"></a><strong>Hard negative mining:</strong></h3><p>在anchor匹配后，大多数anchor都是负样本，导致正样本和负样本严重不均衡。为了更快更稳定的训练，将他们按照loss值排序并选取最高的几个，保证正样本和负样本的比例最高不超过3:1.</p><h3 id="Other-implementation-details"><a href="#Other-implementation-details" class="headerlink" title="Other implementation details:"></a><strong>Other implementation details:</strong></h3><p>Xavier随机初始化。优化器SGD，momentum:0.9，weight decay:5e-4，batch  size:32，迭代最大次数:120k，初始80k迭代learning  rate:1e-3，80-100k迭代用1e-4，,100-120k迭代用1e-5，使用caffe实现。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="http://cn.arxiv.org/abs/1603.05201" target="_blank" rel="noopener">《Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units》</a></p><p><a href="https://blog.csdn.net/shuzfan/article/details/77807550" target="_blank" rel="noopener">CReLU激活函数</a></p><p><a href="https://github.com/sfzhang15/FaceBoxes" target="_blank" rel="noopener">代码</a></p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人脸检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git 使用方法总结</title>
      <link href="/2019/04/30/git-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"/>
      <url>/2019/04/30/git-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1 id="git-使用方法总结"><a href="#git-使用方法总结" class="headerlink" title="git 使用方法总结"></a>git 使用方法总结</h1><p>比较基础的方法就不一一写了，碰到没使用过的在慢慢总结更新。</p><h2 id="git-status"><a href="#git-status" class="headerlink" title="git status"></a>git status</h2><p>可以看到有三部分的内容，我们分为上中下。对于<em>Changes to be committed</em> 为暂存区，<em>Changes not staged for commit</em>为工作区，<em>Untracked files</em>为未添加文件（本地文件）。</p><p>先解释几个概念：</p><p>１．<strong>工作区</strong>：就是你在电脑里能看到的目录</p><p>２．<strong>版本库</strong>：工作区有一个隐藏目录<code>.git</code>，这个不算工作区，而是Git的版本库。Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的<strong>暂存区</strong>，还有Git为我们自动创建的第一个分支<code>master</code>，以及指向<code>master</code>的一个指针叫<code>HEAD</code>。</p><p>当我们想把文件往Git版本库里添加的时候，是分两步执行的：第一步是用<code>git add</code>把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用<code>git commit</code>提交更改，实际上就是把暂存区的所有内容提交到当前分支。因为我们创建Git版本库时，Git自动为我们创建了唯一一个<code>master</code>分支，所以，现在，<code>git commit</code>就是往<code>master</code>分支上提交更改。你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。</p><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/git.jpeg" alt="图示"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@ubuntu-B250-HD3:~/Project/faceengine/faceengine$ git status</span><br><span class="line">On branch master</span><br><span class="line">Your branch is up-to-date with <span class="string">'origin/master'</span>.</span><br><span class="line">Changes to be committed:</span><br><span class="line">  (use <span class="string">"git reset HEAD &lt;file&gt;..."</span> to unstage)</span><br><span class="line"></span><br><span class="line">        modified:   src/core/CMakeLists.txt</span><br><span class="line">        modified:   src/core/algservice/FaceDetection/FaceDetector.cpp</span><br><span class="line">        modified:   src/core/algservice/FaceDetection/FaceDetector.h</span><br><span class="line">        modified:   src/core/algservice/FaceDetection/MTCNNCaffeDetector.h</span><br><span class="line">        new file:   src/core/algservice/FaceDetection/MTCNNTensorrtDetector.cpp</span><br><span class="line">        new file:   src/core/algservice/FaceDetection/MTCNNTensorrtDetector.h</span><br><span class="line">        new file:   src/core/algservice/FaceDetection/resizeconvertion.cu</span><br><span class="line">        modified:   src/core/scheduler/FaceEngine.cpp</span><br><span class="line"></span><br><span class="line">Changes not staged <span class="keyword">for</span> commit:</span><br><span class="line">  (use <span class="string">"git add &lt;file&gt;..."</span> to update what will be committed)</span><br><span class="line">  (use <span class="string">"git checkout -- &lt;file&gt;..."</span> to discard changes <span class="keyword">in</span> working directory)</span><br><span class="line"></span><br><span class="line">        modified:   src/core/CMakeLists.txt</span><br><span class="line"></span><br><span class="line">Untracked files:</span><br><span class="line">  (use <span class="string">"git add &lt;file&gt;..."</span> to include <span class="keyword">in</span> what will be committed)</span><br><span class="line"></span><br><span class="line">        patch</span><br></pre></td></tr></table></figure><p>１．对于暂存区的内容，如果想要恢复和本地版本库一样，则需要输入命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git reset HEAD &lt;file&gt;...</span><br><span class="line">$ git checkout -- &lt;file&gt;...</span><br></pre></td></tr></table></figure><p>２．对于工作区的内容，如果需要恢复和本地版本库一样，则需要输入命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -- &lt;file&gt;...</span><br></pre></td></tr></table></figure><p>３．如果想把工作区的内容或者本地内容添加到暂存区：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git add &lt;file&gt;...</span><br></pre></td></tr></table></figure><p>４．当我们执行commit之后，想把版本回退到之前的版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回退到上一个版本</span></span><br><span class="line">$ git reset --hard HEAD^</span><br><span class="line"><span class="comment"># 回退到上上版本</span></span><br><span class="line">$ git reset --hard HEAD^^</span><br><span class="line"><span class="comment"># 回退到往上１００个版本</span></span><br><span class="line">$ git reset --hard HEAD~100</span><br></pre></td></tr></table></figure><p>如果想恢复到最新版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找到commit id</span></span><br><span class="line">$ git reflog</span><br><span class="line">9febc2e HEAD@&#123;0&#125;: pull: Fast-forward</span><br><span class="line">7a028ee HEAD@&#123;1&#125;: <span class="built_in">clone</span>: from https://xxx.git</span><br><span class="line"><span class="comment"># 回退到某个版本</span></span><br><span class="line">$ git reset --hard 7a028ee</span><br></pre></td></tr></table></figure><h2 id="git-log"><a href="#git-log" class="headerlink" title="git log"></a>git log</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@ubuntu-B250-HD3:~/Project/faceengine/faceengine$ git <span class="built_in">log</span></span><br><span class="line">commit 9febc2e07ae0d5401dade4913578e2ae07381a73</span><br><span class="line">Author: yeweijing &lt;ypat_999@163.com&gt;</span><br><span class="line">Date:   Sun Apr 28 10:28:06 2019 +0800</span><br><span class="line"></span><br><span class="line">    提交日志</span><br><span class="line"></span><br><span class="line">commit ca94b89fd7bfe19e8891a0f5c5f05d1339b42480</span><br><span class="line">Author: chendepin &lt;danpechen@126.com&gt;</span><br><span class="line">Date:   Mon Apr 22 15:55:26 2019 +0800</span><br><span class="line"></span><br><span class="line">    修复适应不同目录结构的问题</span><br><span class="line"></span><br><span class="line">commit 0be1f9bb8f0d6fc41af30b88de70e539da421b67</span><br><span class="line">Author: chendepin &lt;danpechen@126.com&gt;</span><br><span class="line">Date:   Fri Apr 19 15:16:13 2019 +0800</span><br><span class="line"></span><br><span class="line">    忽略 pyc 格式文件</span><br></pre></td></tr></table></figure><p><strong>9febc2e07ae0d5401dade4913578e2ae07381a73</strong>：为<code>commit id</code>（版本号），和SVN不一样，Git的<code>commit id</code>不是1，2，3……递增的数字，而是一个SHA1计算出来的一个非常大的数字，用十六进制表示为什么<code>commit id</code>需要用这么一大串数字表示呢？因为Git是分布式的版本控制系统，后面我们还要研究多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。<strong>Author</strong>：为作者。<strong>Date</strong>：提交日期。最后是日志内容。</p><h2 id="git-rm"><a href="#git-rm" class="headerlink" title="git rm"></a>git rm</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#　创建文件并提交</span></span><br><span class="line">$ git add test.txt</span><br><span class="line">$ git commit -m <span class="string">"add test.txt"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除本地文件</span></span><br><span class="line">$ rm test.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 场景一</span></span><br><span class="line"><span class="comment"># 更新到暂存区</span></span><br><span class="line">$ git rm/add test.txt</span><br><span class="line"><span class="comment"># 删除本地库文件</span></span><br><span class="line">$ git commit -m <span class="string">"remove test.txt"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 场景二</span></span><br><span class="line"><span class="comment"># 只删除本地文件，可以使用checkout复原</span></span><br><span class="line">$ git checkout -- test.txt</span><br></pre></td></tr></table></figure><h2 id="git-diff"><a href="#git-diff" class="headerlink" title="git diff"></a>git diff</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 工作区与暂存区比较</span></span><br><span class="line">$ git diff</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暂存区与最新本地库比较</span></span><br><span class="line">$ git diff --cached [&lt;path&gt;...]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 工作区及暂存区与本地最新版本库比较</span></span><br><span class="line">$ git diff HEAD [&lt;path&gt;...]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 暂存区与指定commit-id比较</span></span><br><span class="line">$ git diff --cached [&lt;commit-id&gt;] [&lt;path&gt;...]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比较两个commit-id之间的差异 </span></span><br><span class="line">$ git diff [&lt;commit-id&gt;] [&lt;commit-id&gt;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打补丁</span></span><br><span class="line"><span class="comment"># 将暂存区与版本库的差异做成补丁</span></span><br><span class="line">$ git diff --cached &gt; patch</span><br><span class="line"><span class="comment"># 将工作区以及暂存区与本地版本库的差异做成补丁</span></span><br><span class="line">$ git diff HEAD &gt; patch </span><br><span class="line"><span class="comment"># 将工作区单个文件做成补丁</span></span><br><span class="line">$ git diff &lt;file&gt;</span><br></pre></td></tr></table></figure><h2 id="git-stash"><a href="#git-stash" class="headerlink" title="git stash"></a>git stash</h2><p>当我们在我们的分支上修改完成之后，需要先使用pull命令把远程库最新内容checkout下来，此时可能产生冲突导致pull不下来，因此需要现将我们修订的东西暂时储存起来。或者当我们在工作过程中，临时接到新任务，需要把当前的工作现场清理一下，等做完新任务后再恢复工作现场，这时候可以使用git stash来管理：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前分支状态</span></span><br><span class="line">$ git status</span><br><span class="line">On branch dev</span><br><span class="line">Changes to be committed:</span><br><span class="line">  (use <span class="string">"git reset HEAD &lt;file&gt;..."</span> to unstage)</span><br><span class="line"></span><br><span class="line">    new file:   hello.py</span><br><span class="line"></span><br><span class="line">Changes not staged <span class="keyword">for</span> commit:</span><br><span class="line">  (use <span class="string">"git add &lt;file&gt;..."</span> to update what will be committed)</span><br><span class="line">  (use <span class="string">"git checkout -- &lt;file&gt;..."</span> to discard changes <span class="keyword">in</span> working directory)</span><br><span class="line"></span><br><span class="line">    modified:   readme.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将工作区和暂存区的文件保存到堆栈中</span></span><br><span class="line">$ git stash</span><br><span class="line">Saved working directory and index state WIP on dev: f52c633 add merge</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复</span></span><br><span class="line">$ git stash pop　<span class="comment">#相当于使用git stash apply和git stash drop</span></span><br><span class="line">On branch dev</span><br><span class="line">Changes to be committed:</span><br><span class="line">  (use <span class="string">"git reset HEAD &lt;file&gt;..."</span> to unstage)</span><br><span class="line"></span><br><span class="line">    new file:   hello.py</span><br><span class="line"></span><br><span class="line">Changes not staged <span class="keyword">for</span> commit:</span><br><span class="line">  (use <span class="string">"git add &lt;file&gt;..."</span> to update what will be committed)</span><br><span class="line">  (use <span class="string">"git checkout -- &lt;file&gt;..."</span> to discard changes <span class="keyword">in</span> working directory)</span><br><span class="line"></span><br><span class="line">    modified:   readme.txt</span><br><span class="line"></span><br><span class="line">Dropped refs/stash@&#123;0&#125; (5d677e2ee266f39ea296182fb2354265b91b3b2a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看堆栈内容</span></span><br><span class="line">$ git stash list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复指定的stash</span></span><br><span class="line">$ git stash apply stash@&#123;0&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清除stash</span></span><br><span class="line">$ git stash clean</span><br></pre></td></tr></table></figure><h2 id="远程仓库管理"><a href="#远程仓库管理" class="headerlink" title="远程仓库管理"></a>远程仓库管理</h2><p>要关联一个远程库，使用命令如下，远程库的名字就是<code>origin</code>，这是Git默认的叫法，也可以改成别的，但是<code>origin</code>这个名字一看就知道是远程库。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote add origin git@github.com:clancylian/repo-name.git</span><br></pre></td></tr></table></figure><p>关联后，由于远程库是空的，我们第一次推送<code>master</code>分支时，加上了<code>-u</code>参数，Git不但会把本地的<code>master</code>分支内容推送的远程新的<code>master</code>分支，还会把本地的<code>master</code>分支和远程的<code>master</code>分支关联起来，在以后的推送或者拉取时就可以简化命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push -u origin master</span><br></pre></td></tr></table></figure><p>此后，每次本地提交后，只要有必要，就可以使用以下命令提交：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin master</span><br></pre></td></tr></table></figure><p>从远程库克隆下来：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/clancylian/repo-name.git</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看远程库信息</span></span><br><span class="line">$ git remote</span><br><span class="line">origin</span><br><span class="line"></span><br><span class="line">$ git remote -v</span><br><span class="line">originhttps://github.com/amdegroot/ssd.pytorch.git (fetch)</span><br><span class="line">originhttps://github.com/amdegroot/ssd.pytorch.git (push)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送分支，master为本地分支</span></span><br><span class="line">$ git push origin master</span><br><span class="line"></span><br><span class="line"><span class="comment"># checkout远程其他分支</span></span><br><span class="line">$ git checkout -b dev origin/dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#　如果push失败需要先pull下来</span></span><br><span class="line">$ git pull</span><br><span class="line">There is no tracking information <span class="keyword">for</span> the current branch.</span><br><span class="line">Please specify <span class="built_in">which</span> branch you want to merge with.</span><br><span class="line">See git-pull(1) <span class="keyword">for</span> details.</span><br><span class="line"></span><br><span class="line">    git pull &lt;remote&gt; &lt;branch&gt;</span><br><span class="line"></span><br><span class="line">If you wish to <span class="built_in">set</span> tracking information <span class="keyword">for</span> this branch you can <span class="keyword">do</span> so with:</span><br><span class="line"></span><br><span class="line">    git branch --<span class="built_in">set</span>-upstream-to=origin/&lt;branch&gt; dev</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 提示没有关联，需要先关联</span></span><br><span class="line">$ git branch --<span class="built_in">set</span>-upstream-to=origin/dev dev</span><br><span class="line">Branch <span class="string">'dev'</span> <span class="built_in">set</span> up to track remote branch <span class="string">'dev'</span> from <span class="string">'origin'</span>.</span><br></pre></td></tr></table></figure><h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建分支并切换到分支</span></span><br><span class="line">$ git checkout -b branch1</span><br><span class="line">Switched to a new branch <span class="string">'branch1'</span></span><br><span class="line"><span class="comment"># 相当于以下命令</span></span><br><span class="line">$ git branch branch1</span><br><span class="line">$ git checkout branch1</span><br><span class="line">Switched to branch <span class="string">'branch1'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前分支,当前分支会有*号，也就是HEAD指向的分支</span></span><br><span class="line">$ git branch</span><br><span class="line">* branch1</span><br><span class="line">  master</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 修改完分支内容之后，切换回主分支</span></span><br><span class="line">$ git checkout master</span><br><span class="line">Switched to branch <span class="string">'master'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并分支，git merge命令用于合并指定分支(branch1)到当前分支(master)</span></span><br><span class="line">$ git merge branch1</span><br><span class="line">Updating d46f35e..b17d20e</span><br><span class="line">Fast-forward</span><br><span class="line"> readme.txt | 1 +</span><br><span class="line"> 1 file changed, 1 insertion(+)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 删除分支</span></span><br><span class="line">$ git branch -d branch1</span><br><span class="line">Deleted branch dev (was b17d20e).</span><br><span class="line"></span><br><span class="line"><span class="comment">######################################################3</span></span><br><span class="line"><span class="comment"># 当合并分支的时候出现冲突时</span></span><br><span class="line">$ git status</span><br><span class="line">On branch master</span><br><span class="line">Your branch is ahead of <span class="string">'origin/master'</span> by 2 commits.</span><br><span class="line">  (use <span class="string">"git push"</span> to publish your <span class="built_in">local</span> commits)</span><br><span class="line"></span><br><span class="line">You have unmerged paths.</span><br><span class="line">  (fix conflicts and run <span class="string">"git commit"</span>)</span><br><span class="line">  (use <span class="string">"git merge --abort"</span> to abort the merge)</span><br><span class="line"></span><br><span class="line">Unmerged paths:</span><br><span class="line">  (use <span class="string">"git add &lt;file&gt;..."</span> to mark resolution)</span><br><span class="line"></span><br><span class="line">    both modified:   readme.txt</span><br><span class="line"></span><br><span class="line">no changes added to commit (use <span class="string">"git add"</span> and/or <span class="string">"git commit -a"</span>)</span><br><span class="line"><span class="comment"># 查看文件内容出现</span></span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</span><br><span class="line">aaaaaaaaaaaaaaaaaaaaaaaa</span><br><span class="line">=======</span><br><span class="line">bbbbbbbbbbbbbbbbbbbbbbbb</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt; branch1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动修改后</span></span><br><span class="line">$ git add &lt;file&gt; </span><br><span class="line">$ git commit -m <span class="string">"conflict fixed"</span></span><br></pre></td></tr></table></figure><p>##　标签管理</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建标签</span></span><br><span class="line">$ git tag v1.0</span><br><span class="line"></span><br><span class="line">$ git tag</span><br><span class="line">v1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对历史版本打标签</span></span><br><span class="line">$ git tag v0.9 f52c633</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看标签信息</span></span><br><span class="line">$ git show v0.9</span><br><span class="line"></span><br><span class="line"><span class="comment"># 带有说明的标签</span></span><br><span class="line">$ git tag -a v0.1 -m <span class="string">"version 0.1 released"</span> 1094adb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除本地标签</span></span><br><span class="line">$ git tag -d v0.1</span><br><span class="line">Deleted tag <span class="string">'v0.1'</span> (was f15b0dd)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交标签到远程库</span></span><br><span class="line">$ git push origin v1.0</span><br><span class="line">Total 0 (delta 0), reused 0 (delta 0)</span><br><span class="line">To github.com:michaelliao/learngit.git</span><br><span class="line"> * [new tag]         v1.0 -&gt; v1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交所有标签</span></span><br><span class="line">$ git push origin --tags</span><br><span class="line">Total 0 (delta 0), reused 0 (delta 0)</span><br><span class="line">To github.com:michaelliao/learngit.git</span><br><span class="line"> * [new tag]         v0.9 -&gt; v0.9</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除远程标签</span></span><br><span class="line">$ git tag -d v0.9</span><br><span class="line">Deleted tag <span class="string">'v0.9'</span> (was f52c633)</span><br><span class="line"></span><br><span class="line">$ git push origin :refs/tags/v0.9</span><br><span class="line">To github.com:michaelliao/learngit.git</span><br><span class="line"> - [deleted]         v0.9</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">git 学习网站推荐</a></p><p><a href="https://github.com/github/gitignore" target="_blank" rel="noopener">gitignore 配置文件</a></p>]]></content>
      
      
      <categories>
          
          <category> git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>opencv GPU和CPUX实现直方图均衡差异</title>
      <link href="/2019/04/29/opencv-GPU%E5%92%8CCPUX%E5%AE%9E%E7%8E%B0%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%B7%AE%E5%BC%82/"/>
      <url>/2019/04/29/opencv-GPU%E5%92%8CCPUX%E5%AE%9E%E7%8E%B0%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%B7%AE%E5%BC%82/</url>
      
        <content type="html"><![CDATA[<p>opencv gpu和cpu实现直方图均衡会出现不同，版本3.3.1，代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testCPU</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//cpu</span></span><br><span class="line">    cv::Mat src = imread(<span class="string">"/home/ubuntu/Pictures/2.png"</span>);</span><br><span class="line">    <span class="comment">//cv::resize(src, src, cv::Size(0, 0), 0.5, 0.5);</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;Mat&gt; channels;</span><br><span class="line">    split(src, channels);</span><br><span class="line">    Mat B,G,R;</span><br><span class="line"><span class="comment">//#pragma omp parallel sections</span></span><br><span class="line">    &#123;</span><br><span class="line"><span class="comment">//#pragma omp section</span></span><br><span class="line">        &#123;</span><br><span class="line">            equalizeHist( channels[<span class="number">0</span>], B );</span><br><span class="line">            <span class="comment">//GaussianBlur(B,B,Size(3, 3), 2.0);</span></span><br><span class="line">            <span class="comment">//B = (B+ channels[0]) / 2;</span></span><br><span class="line">            <span class="comment">//addWeighted(B, 0.5, channels[0], 0.5, 0, B);</span></span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//#pragma omp section</span></span><br><span class="line">        &#123;</span><br><span class="line">            equalizeHist( channels[<span class="number">1</span>], G );</span><br><span class="line">            <span class="comment">//GaussianBlur(G,G,Size(3, 3), 2.0);</span></span><br><span class="line">            <span class="comment">//G = (G+ channels[1]) / 2;</span></span><br><span class="line">            <span class="comment">//addWeighted(G, 0.5, channels[1], 0.5, 0, G);</span></span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//#pragma omp section</span></span><br><span class="line">        &#123;</span><br><span class="line">            equalizeHist( channels[<span class="number">2</span>], R );</span><br><span class="line">            <span class="comment">//GaussianBlur(R,R,Size(3, 3), 2.0);</span></span><br><span class="line">            <span class="comment">//R = (R+ channels[2]) / 2;</span></span><br><span class="line">            <span class="comment">//addWeighted(R, 0.5, channels[2], 0.5, 0, R);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">vector</span>&lt;Mat&gt; combined;</span><br><span class="line">    combined.push_back(B);</span><br><span class="line">    combined.push_back(G);</span><br><span class="line">    combined.push_back(R);</span><br><span class="line">    Mat sample_single;</span><br><span class="line">    merge(combined, sample_single);</span><br><span class="line"></span><br><span class="line">    imwrite(<span class="string">"cpu.jpg"</span>, sample_single);</span><br><span class="line">    imshow(<span class="string">"cpu"</span>, sample_single);</span><br><span class="line">    <span class="comment">//waitKey(0);</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testGPU</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//gpu</span></span><br><span class="line">    cv::Mat src = imread(<span class="string">"/home/ubuntu/Pictures/2.png"</span>);</span><br><span class="line">    <span class="comment">//cv::resize(src, src, cv::Size(0, 0), 0.5, 0.5);</span></span><br><span class="line">    cv::cuda::GpuMat gpu_src;<span class="comment">// = cv::cuda::GpuMat(src.height, src.width, CV_8UC3, src.data);</span></span><br><span class="line">    gpu_src.upload(src);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cv::cuda::GpuMat&gt; channels;</span><br><span class="line">    cv::cuda::split(gpu_src, channels);</span><br><span class="line"></span><br><span class="line">    cv::cuda::GpuMat B, G, R;</span><br><span class="line">    cv::cuda::equalizeHist(channels[<span class="number">0</span>], B);</span><br><span class="line">    cv::cuda::equalizeHist(channels[<span class="number">1</span>], G);</span><br><span class="line">    cv::cuda::equalizeHist(channels[<span class="number">2</span>], R);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建高斯滤波器</span></span><br><span class="line">    cv::Ptr&lt;cv::cuda::Filter&gt; gauss = cv::cuda::createGaussianFilter(CV_8UC1, CV_8UC1, Size(<span class="number">3</span>, <span class="number">3</span>), <span class="number">2.0</span>);</span><br><span class="line">    <span class="comment">//高斯滤波</span></span><br><span class="line">    <span class="comment">//gauss-&gt;apply(B, B);</span></span><br><span class="line">    <span class="comment">//gauss-&gt;apply(G, G);</span></span><br><span class="line">    <span class="comment">//gauss-&gt;apply(R, R);</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    cv::cuda::addWeighted(B, 0.5, channels[0], 0.5, 0, B);</span></span><br><span class="line"><span class="comment">//    cv::cuda::addWeighted(G, 0.5, channels[1], 0.5, 0, G);</span></span><br><span class="line"><span class="comment">//    cv::cuda::addWeighted(R, 0.5, channels[2], 0.5, 0, R);</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;cv::cuda::GpuMat&gt; combined;</span><br><span class="line">    combined.push_back(B);</span><br><span class="line">    combined.push_back(G);</span><br><span class="line">    combined.push_back(R);</span><br><span class="line">    cv::cuda::GpuMat gpu_dst;</span><br><span class="line">    cv::cuda::merge(combined, gpu_dst);</span><br><span class="line"></span><br><span class="line">    Mat img;</span><br><span class="line">    gpu_dst.download(img);</span><br><span class="line">    imwrite(<span class="string">"gpu.jpg"</span>, img);</span><br><span class="line">    imshow(<span class="string">"gpu"</span>, img);</span><br><span class="line">    waitKey(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    testCPU();</span><br><span class="line">    testGPU();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="原图"><a href="#原图" class="headerlink" title="原图"></a>原图</h2><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/2.png" alt="原图"></p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/cpu.jpg" alt="cpu"></p><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p><img src="https://raw.githubusercontent.com/clancylian/blogpic/master/gpu.jpg" alt="gpu"></p>]]></content>
      
      
      <categories>
          
          <category> opencv </category>
          
      </categories>
      
      
        <tags>
            
            <tag> opencv </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NVIDIA NPP LIBRARY SDK</title>
      <link href="/2019/04/29/NVIDIA-NPP-LIBRARY-SDK/"/>
      <url>/2019/04/29/NVIDIA-NPP-LIBRARY-SDK/</url>
      
        <content type="html"><![CDATA[<h1 id="CUDA-NPP库使用"><a href="#CUDA-NPP库使用" class="headerlink" title="CUDA NPP库使用"></a>CUDA NPP库使用</h1><p>NPP库是英伟达提供的可用在实现GPU加速图像处理，详细SDK文档可以<a href="https://docs.nvidia.com/cuda/npp/index.html" target="_blank" rel="noopener">参考链接</a>，主要包含的库如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//图像处理基础库，类似opencv core</span></span><br><span class="line">nppc NPP core library which MUST be included when linking any application, functions are listed in nppCore.h</span><br><span class="line"><span class="comment">//算术逻辑操作</span></span><br><span class="line">nppial  arithmetic <span class="keyword">and</span> logical operation functions in nppi_arithmetic_and_logical_operations.h</span><br><span class="line"><span class="comment">//颜色转换操作</span></span><br><span class="line">nppicc  color conversion <span class="keyword">and</span> sampling functions in nppi_color_conversion.h</span><br><span class="line"><span class="comment">//图像压缩和解压</span></span><br><span class="line">nppicom JPEG compression <span class="keyword">and</span> decompression functions in nppi_compression_functions.h</span><br><span class="line"><span class="comment">//数据转换及初始化</span></span><br><span class="line">nppidei data exchange <span class="keyword">and</span> initialization functions in nppi_data_exchange_and_initialization.h</span><br><span class="line"><span class="comment">//滤波操作</span></span><br><span class="line">nppif   filtering <span class="keyword">and</span> computer vision functions in nppi_filter_functions.h</span><br><span class="line"><span class="comment">//几何变换</span></span><br><span class="line">nppig   geometry transformation functions found in nppi_geometry_transforms.h</span><br><span class="line"><span class="comment">//形态学操作</span></span><br><span class="line">nppim   morphological operation functions found in nppi_morphological_operations.h</span><br><span class="line"><span class="comment">//统计及线性变换</span></span><br><span class="line">nppist  statistics <span class="keyword">and</span> linear transform in nppi_statistics_functions.h <span class="keyword">and</span> nppi_linear_transforms.h</span><br><span class="line"><span class="comment">//内存支持函数</span></span><br><span class="line">nppisu  memory support functions in nppi_support_functions.h</span><br><span class="line"><span class="comment">//阈值及比较操作</span></span><br><span class="line">nppitc  threshold <span class="keyword">and</span> compare operation functions in nppi_threshold_and_compare_operations.h</span><br></pre></td></tr></table></figure><p>由于项目需求，这里主要介绍一些常用的操作，主要是opencv中基本图像处理操作，比如颜色空间转换，图像伸缩变换等等。</p><h2 id="RESIZE"><a href="#RESIZE" class="headerlink" title="RESIZE"></a>RESIZE</h2><p>resize操作支持单通道、３通道、４通道。8u、16u、16s、32f，接口一般是<em>nppiResizeSqrPixel_　_　</em>，其中可以选择对感兴趣区域进行resize。这里需要注意的是resize的一些插值方式，和opencv不太一样，并且官方文档没有详细说明，导致有一些坑在里面。比如之前使用<em>NPPI_INTER_SUPER</em>插值方式的时候发现factor大于１的时候会出错。后面找到答案说<em>NPPI_INTER_SUPER</em>只支持降采样操作，<a href="https://devtalk.nvidia.com/default/topic/1043307/general/npp-library-functions-nppiresize_8u_c3r-and-nppibgrtolab_8u_c3r-differ-from-cv-resize-output/post/5302888/#5302888" target="_blank" rel="noopener">参考链接</a>。这里举个BGR进行通道转换的栗子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">imageResize_8u_C3R</span><span class="params">(<span class="keyword">void</span> *src, <span class="keyword">int</span> srcWidth, <span class="keyword">int</span> srcHeight, <span class="keyword">void</span> *dst, <span class="keyword">int</span> dstWidth, <span class="keyword">int</span> dstHeight)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    NppiSize oSrcSize;</span><br><span class="line">    oSrcSize.width = srcWidth;</span><br><span class="line">    oSrcSize.height = srcHeight;</span><br><span class="line">    <span class="keyword">int</span> nSrcStep = srcWidth * <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">    NppiRect oSrcROI;</span><br><span class="line">    oSrcROI.x = <span class="number">0</span>;</span><br><span class="line">    oSrcROI.y = <span class="number">0</span>;</span><br><span class="line">    oSrcROI.width = srcWidth;</span><br><span class="line">    oSrcROI.height = srcHeight;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> nDstStep = dstWidth * <span class="number">3</span>;</span><br><span class="line">    NppiRect oDstROI;</span><br><span class="line">    oDstROI.x = <span class="number">0</span>;</span><br><span class="line">    oDstROI.y = <span class="number">0</span>;</span><br><span class="line">    oDstROI.width = dstWidth;</span><br><span class="line">    oDstROI.height = dstHeight;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Scale Factor</span></span><br><span class="line">    <span class="keyword">double</span> nXFactor = <span class="keyword">double</span>(dstWidth) / (oSrcROI.width);</span><br><span class="line">    <span class="keyword">double</span> nYFactor = <span class="keyword">double</span>(dstHeight) / (oSrcROI.height);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Scaled X/Y  Shift</span></span><br><span class="line">    <span class="keyword">double</span> nXShift = - oSrcROI.x * nXFactor ;</span><br><span class="line">    <span class="keyword">double</span> nYShift = - oSrcROI.y * nYFactor;</span><br><span class="line">    <span class="keyword">int</span> eInterpolation = NPPI_INTER_SUPER;</span><br><span class="line">    <span class="keyword">if</span> (nXFactor &gt;= <span class="number">1.f</span> || nYFactor &gt;= <span class="number">1.f</span>)</span><br><span class="line">        eInterpolation = NPPI_INTER_LANCZOS;</span><br><span class="line"></span><br><span class="line">    NppStatus ret = nppiResizeSqrPixel_8u_C3R((<span class="keyword">const</span> Npp8u *)src, oSrcSize, nSrcStep, oSrcROI, (Npp8u *)dst,</span><br><span class="line">                         nDstStep, oDstROI, nXFactor, nYFactor, nXShift, nYShift, eInterpolation );</span><br><span class="line">    <span class="keyword">if</span>(ret != NPP_SUCCESS) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"imageResize_8u_C3R failed %d.\n"</span>, ret);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>resize库包含在<strong>nppig</strong>库里面，其中还有各种操作，包括mirror、remap、rotate、warp等等，这些在平常使用过程中比较少用到，需要用的时候再参考文档。</p><p>##　颜色转换</p><h2 id="自己实现一些操作"><a href="#自己实现一些操作" class="headerlink" title="自己实现一些操作"></a>自己实现一些操作</h2><h3 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">imagePaddingKernel</span><span class="params">(float3 *ptr, float3 *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height, <span class="keyword">int</span> top,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   <span class="keyword">int</span> bottom, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">if</span>(x &lt; left || x &gt;= (width - right) || y &lt; top || y &gt; (height - bottom)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    float3 color = ptr[(y - top) * (width - top - right) + (x - left)];</span><br><span class="line"></span><br><span class="line">    dst[y * width + x] = color;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">imagePadding</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *src, <span class="keyword">void</span> *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height, <span class="keyword">int</span> top,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">int</span> bottom, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> dstW = width + left + right;</span><br><span class="line">    <span class="keyword">int</span> dstH = height + top + bottom;</span><br><span class="line"></span><br><span class="line">    cudaMemset(dst, <span class="number">0</span>, dstW * dstH * <span class="keyword">sizeof</span>(float3));</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">((dstW + <span class="number">31</span>) / <span class="number">32</span>, (dstH + <span class="number">31</span>) / <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    imagePaddingKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (float3 *)dst, dstW, dstH,</span><br><span class="line">                                          top, bottom, left, right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="split"><a href="#split" class="headerlink" title="split"></a>split</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">imageSplitKernel</span><span class="params">(float3 *ptr, <span class="keyword">float</span> *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">if</span> (x &gt;= width || y &gt;= height) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    float3 color = ptr[y * width + x];</span><br><span class="line"></span><br><span class="line">    dst[y * width + x] = color.x;</span><br><span class="line">    dst[y * width + x + width * height] = color.y;</span><br><span class="line">    dst[y * width + x + width * height * <span class="number">2</span>] = color.z;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">imageSplit</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *src, <span class="keyword">float</span> *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height, cudaStream_t stream)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">((width + <span class="number">31</span>) / <span class="number">32</span>, (height + <span class="number">31</span>) / <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    imageSplitKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)src, (<span class="keyword">float</span> *)dst, width, height);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="normalization"><a href="#normalization" class="headerlink" title="normalization"></a>normalization</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">imageNormalizationKernel</span><span class="params">(float3 *ptr, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">if</span> (x &gt;= width || y &gt;= height) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    float3 color = ptr[y * width + x];</span><br><span class="line">    color.x = (color.x - <span class="number">127.5</span>) * <span class="number">0.0078125</span>;</span><br><span class="line">    color.y = (color.y - <span class="number">127.5</span>) * <span class="number">0.0078125</span>;</span><br><span class="line">    color.z = (color.z - <span class="number">127.5</span>) * <span class="number">0.0078125</span>;</span><br><span class="line"></span><br><span class="line">    ptr[y * width + x] = make_float3(color.x, color.y, color.z);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">imageNormalization</span><span class="params">(<span class="keyword">void</span> *ptr, <span class="keyword">int</span> width, <span class="keyword">int</span> height, cudaStream_t stream)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">((width + <span class="number">31</span>) / <span class="number">32</span>, (height + <span class="number">31</span>) / <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    imageNormalizationKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((float3 *)ptr, width, height);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="BGR2RGBfloat"><a href="#BGR2RGBfloat" class="headerlink" title="BGR2RGBfloat"></a>BGR2RGBfloat</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">convertBGR2RGBfloatKernel</span><span class="params">(uchar3 *src, float3 *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">if</span> (x &gt;= width || y &gt;= height) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    uchar3 color = src[y * width + x];</span><br><span class="line">    dst[y * width + x] = make_float3(color.z, color.y, color.x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">convertBGR2RGBfloat</span><span class="params">(<span class="keyword">void</span> *src, <span class="keyword">void</span> *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height, cudaStream_t stream)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">((width + <span class="number">31</span>) / <span class="number">32</span>, (height + <span class="number">31</span>) / <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    convertBGR2RGBfloatKernel&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;((uchar3 *)src, (float3 *)dst, width, height);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="RGBA2Gray"><a href="#RGBA2Gray" class="headerlink" title="RGBA2Gray"></a>RGBA2Gray</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">convertRGBA2GrayKernel</span><span class="params">(uchar4 *src, uchar1 *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">if</span> (x &gt;= width || y &gt;= height) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    uchar4 color = src[y * width + x];</span><br><span class="line"></span><br><span class="line">    <span class="comment">//dst[y * width + x] = make_uchar1((color.x+color.y+color.z) * .333333f);</span></span><br><span class="line">    dst[y * width + x] = make_uchar1(<span class="number">0.114f</span> * color.x + <span class="number">0.587f</span> * color.y + <span class="number">0.299f</span> * color.z);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">convertRGBA2Gray</span><span class="params">(<span class="keyword">void</span> *src, <span class="keyword">void</span> *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height, cudaStream_t stream)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">((width + <span class="number">31</span>) / <span class="number">32</span>, (height + <span class="number">31</span>) / <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    convertRGBA2GrayKernel&lt;&lt;&lt;grids, blocks, <span class="number">0</span>, stream&gt;&gt;&gt;((uchar4 *)src, (uchar1 *)dst, width, height);</span><br><span class="line"><span class="comment">//    cudaDeviceSynchronize();</span></span><br><span class="line">    cudaStreamSynchronize(stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="RGBA2BGR"><a href="#RGBA2BGR" class="headerlink" title="RGBA2BGR"></a>RGBA2BGR</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">convertRGBA2BGRKernel</span><span class="params">(uchar4 *src, uchar3 *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">if</span> (x &gt;= width || y &gt;= height) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    uchar4 color = src[y * width + x];</span><br><span class="line">    dst[y * width + x] = make_uchar3(color.z, color.y, color.x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">convertRGBA2BGR</span><span class="params">(<span class="keyword">void</span> *src, <span class="keyword">void</span> *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height, cudaStream_t stream)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">((width + <span class="number">31</span>) / <span class="number">32</span>, (height + <span class="number">31</span>) / <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    convertRGBA2BGRKernel&lt;&lt;&lt;grids, blocks, <span class="number">0</span>, stream&gt;&gt;&gt;((uchar4 *)src, (uchar3 *)dst, width, height);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="TX2-nvx实现RGBA2YUVI420"><a href="#TX2-nvx实现RGBA2YUVI420" class="headerlink" title="TX2 nvx实现RGBA2YUVI420"></a>TX2 nvx实现RGBA2YUVI420</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">convertRGBA2YUVI420</span><span class="params">(<span class="keyword">void</span> *src, <span class="keyword">void</span> *dst, <span class="keyword">int</span> width, <span class="keyword">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">bool</span> inited = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">nvxcu_stream_exec_target_t</span> exec_target;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!inited) &#123;</span><br><span class="line">        <span class="keyword">int</span> deviceID;</span><br><span class="line">        <span class="comment">/*HANDLE_CUDA_ERROR*/</span>(cudaGetDevice(&amp;deviceID));</span><br><span class="line">        exec_target.base.exec_target_type = NVXCU_STREAM_EXEC_TARGET;</span><br><span class="line">        exec_target.stream = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="comment">/*HANDLE_CUDA_ERROR*/</span>(cudaGetDeviceProperties(&amp;exec_target.dev_prop, deviceID));</span><br><span class="line">        inited = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">nvxcu_pitch_linear_image_t</span> input, output;</span><br><span class="line">    input.base.format = NVXCU_DF_IMAGE_RGBX;</span><br><span class="line">    input.base.width = width;</span><br><span class="line">    input.base.height = height;</span><br><span class="line">    input.base.image_type = NVXCU_PITCH_LINEAR_IMAGE;</span><br><span class="line">    input.planes[<span class="number">0</span>].dev_ptr = src;</span><br><span class="line">    input.planes[<span class="number">0</span>].pitch_in_bytes = width * <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    output.base.format = NVXCU_DF_IMAGE_IYUV;</span><br><span class="line">    output.base.width = width;</span><br><span class="line">    output.base.height = height;</span><br><span class="line">    output.base.image_type = NVXCU_PITCH_LINEAR_IMAGE;</span><br><span class="line">    output.planes[<span class="number">0</span>].dev_ptr = dst;</span><br><span class="line">    output.planes[<span class="number">0</span>].pitch_in_bytes = width;</span><br><span class="line">    output.planes[<span class="number">1</span>].dev_ptr = (<span class="keyword">char</span> *)dst + width * height;</span><br><span class="line">    output.planes[<span class="number">1</span>].pitch_in_bytes = width / <span class="number">2</span>;</span><br><span class="line">    output.planes[<span class="number">2</span>].dev_ptr = (<span class="keyword">char</span> *)dst + width * height * <span class="number">5</span> / <span class="number">4</span>;</span><br><span class="line">    output.planes[<span class="number">2</span>].pitch_in_bytes = width / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">    nvxcu_error_status_e stat;</span><br><span class="line">    stat = nvxcuColorConvert(&amp;input.base, &amp;output.base, NVXCU_COLOR_SPACE_DEFAULT,</span><br><span class="line">                             NVXCU_CHANNEL_RANGE_FULL, &amp;exec_target.base);</span><br><span class="line">    <span class="keyword">if</span> (stat != NVXCU_SUCCESS) &#123;</span><br><span class="line">        dbgInfo(<span class="string">"Conver RGB to YUVI420 failed: %d.\n"</span>, stat);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="叠加图片"><a href="#叠加图片" class="headerlink" title="叠加图片"></a>叠加图片</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">cudaPutLogoToImageKernel</span><span class="params">(uchar4 *devImg, <span class="keyword">int</span> imgWidth, <span class="keyword">int</span> imgHeight,</span></span></span><br><span class="line"><span class="function"><span class="params">                    uchar3 *devLogo, <span class="keyword">int</span> width, <span class="keyword">int</span> height, <span class="keyword">int</span> offsetX, <span class="keyword">int</span> offsetY)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="keyword">int</span> y = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    <span class="keyword">if</span> (x &gt;= width || y &gt;= height) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    uchar3 devLogoColor = devLogo[y * width + x];</span><br><span class="line">    <span class="keyword">int</span> offset = (y + offsetY) * imgWidth + offsetX + x;</span><br><span class="line">    devImg[offset] = make_uchar4(devLogoColor.z, devLogoColor.y, devLogoColor.x, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cudaPutLogoToImage</span><span class="params">(<span class="keyword">void</span> *devImg, <span class="keyword">int</span> imgWidth, <span class="keyword">int</span> imgHeight, <span class="keyword">void</span> *devLogo, <span class="keyword">int</span> width,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">int</span> height, <span class="keyword">int</span> offsetX, <span class="keyword">int</span> offsetY, cudaStream_t stream)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">dim3 <span class="title">grids</span><span class="params">((width + <span class="number">31</span>) / <span class="number">32</span>, (height + <span class="number">31</span>) / <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">blocks</span><span class="params">(<span class="number">32</span>, <span class="number">32</span>)</span></span>;</span><br><span class="line">    <span class="comment">//if use stream, every time the result will be error. have to test!!!</span></span><br><span class="line">    cudaPutLogoToImageKernel&lt;&lt;&lt;grids, blocks, <span class="number">0</span>, stream&gt;&gt;&gt;((uchar4 *)devImg, imgWidth, imgHeight,</span><br><span class="line">                    (uchar3 *)devLogo, width, height, offsetX, offsetY);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>##　参考链接</p><p><a href="https://developer.nvidia.com/npp" target="_blank" rel="noopener">官网地址</a></p>]]></content>
      
      
      <categories>
          
          <category> NVIDIA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
            <tag> NPP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习之路</title>
      <link href="/2019/04/13/PyTorch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/"/>
      <url>/2019/04/13/PyTorch%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<p><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener">参考文档</a></p><h2 id="1-基础概念"><a href="#1-基础概念" class="headerlink" title="1. 基础概念"></a>1. 基础概念</h2><p>PyTorch类似于Numpy。它的优点在于可以充分利用GPU资源。它是一个深度学习框架，提供最大的灵活性和速度。</p><h3 id="1-1-张量概念"><a href="#1-1-张量概念" class="headerlink" title="1.1 张量概念"></a>1.1 张量概念</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造未初始化5x3的矩阵</span></span><br><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造随机初始化矩阵</span></span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造0矩阵，数据类型为long</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long)</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接用数据构造一个张量</span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>])</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于存在的张量构造，可以使用存在的张量的一些属性，比如数据类型，数据纬度，除非手动修改</span></span><br><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double)      <span class="comment"># new_* methods take in sizes</span></span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">x = torch.randn_like(x, dtype=torch.float)    <span class="comment"># override dtype!</span></span><br><span class="line">print(x)                                      <span class="comment"># result has the same size</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取张量大小.实际上torch.Size是一个元组类型，支持元组所有操作</span></span><br><span class="line">print(x.size())</span><br></pre></td></tr></table></figure><h3 id="1-2-张量操作"><a href="#1-2-张量操作" class="headerlink" title="1.2 张量操作"></a>1.2 张量操作</h3><p>关于张量的操作有100多种，包括转置、索引、切片、数值计算、线性代数、随机数等等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加法1</span></span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">print(x + y)</span><br><span class="line"><span class="comment"># 加法2</span></span><br><span class="line">print(torch.add(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出张量作为参数</span></span><br><span class="line">result = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">torch.add(x, y, out=result)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原地（in-place）加法</span></span><br><span class="line"><span class="comment"># adds x to y</span></span><br><span class="line">y.add_(x)</span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># 以 _ 作为后缀将会改变操作数，比如x.copy_(y), x.t_(),都会改变x的值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以像Numpy一样索引</span></span><br><span class="line">print(x[:, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># resize和reshape操作可以使用torch.view</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(<span class="number">-1</span>, <span class="number">8</span>)  <span class="comment"># the size -1 is inferred from other dimensions</span></span><br><span class="line">print(x.size(), y.size(), z.size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果你有一个只有一个元素的张量，可以使用.item()获取数值</span></span><br><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line">print(x)</span><br><span class="line">print(x.item())</span><br></pre></td></tr></table></figure><h3 id="1-3-与Numpy互操作"><a href="#1-3-与Numpy互操作" class="headerlink" title="1.3 与Numpy互操作"></a>1.3 与Numpy互操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tensor转为Numpy</span></span><br><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">b = a.numpy()</span><br><span class="line">print(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Numpy转为tensor</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.ones(<span class="number">5</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">np.add(a, <span class="number">1</span>, out=a)</span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><h3 id="1-4-CUDA-张量"><a href="#1-4-CUDA-张量" class="headerlink" title="1.4 CUDA 张量"></a>1.4 CUDA 张量</h3><p>可以使用 .to 方法把张量拷贝到设备内存(GPU)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># let us run this cell only if CUDA is available</span></span><br><span class="line"><span class="comment"># We will use ``torch.device`` objects to move tensors in and out of GPU</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">device = torch.device(<span class="string">"cuda"</span>)          <span class="comment"># a CUDA device object</span></span><br><span class="line">y = torch.ones_like(x, device=device)  <span class="comment"># directly create a tensor on GPU</span></span><br><span class="line">x = x.to(device)                       <span class="comment"># or just use strings ``.to("cuda")``</span></span><br><span class="line">z = x + y</span><br><span class="line">print(z)</span><br><span class="line">print(z.to(<span class="string">"cpu"</span>, torch.double))       <span class="comment"># ``.to`` can also change dtype together!</span></span><br></pre></td></tr></table></figure><h3 id="1-5-自动微分技术"><a href="#1-5-自动微分技术" class="headerlink" title="1.5 自动微分技术"></a>1.5 自动微分技术</h3><p>PyTorch中的反向传播中求导都是使用autograd包完成的。它提供了张量求导所有操作，它是一个define-by-run框架，意味着每一次反向传播都取决于你的代码是如何跑的，每一次迭代都可能不同。</p><p><code>torch.Tensor</code> 是pytorch一个最基础的类。如果你设置其属性 <code>.requires_grad</code> 为 <code>True</code>, 它将会跟踪它所有的操作，当你调用<code>.backward()</code>时，会自动计算梯度，可以使用 <code>.grad</code> 获取梯度值。可以使用<code>.detach()</code>来停止跟踪历史或者阻止将来的操作。也可以使用<code>with torch.no_grad():</code>。</p><p>除了<code>torch.Tensor</code> 还有一个很重要的类来实现自动求导——<code>Fucction</code>。每一个张量（除了用户创建的之外）都有<code>.grad_fn</code>属性。</p><p>当想要计算导数的时候只要调用<code>.backward()</code>。当输出张量是一个标量的时候，不需要特别指明参数，然而如果是一个向量就需要指明<code>gradient</code>参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置requires_grad为true</span></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">y = x + <span class="number">2</span></span><br><span class="line">print(y)</span><br><span class="line"><span class="comment"># 因为y是由操作得来的结果，所以有grad_fn属性</span></span><br><span class="line">print(y.grad_fn)</span><br><span class="line"></span><br><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line">print(z, out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为out输出为标量，相当于out.backward(torch.tensor(1.))</span></span><br><span class="line">out.backward()</span><br><span class="line">print(x.grad)</span><br></pre></td></tr></table></figure><h3 id="1-6-神经网络"><a href="#1-6-神经网络" class="headerlink" title="1.6 神经网络"></a>1.6 神经网络</h3><h4 id="1-6-1-定义网络结构"><a href="#1-6-1-定义网络结构" class="headerlink" title="1.6.1 定义网络结构"></a>1.6.1 定义网络结构</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">super(Net, self).__init__()</span><br><span class="line"><span class="comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span></span><br><span class="line"><span class="comment"># kernel</span></span><br><span class="line">self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"><span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">x = x.view(<span class="number">-1</span>, self.num_flat_features(x))</span><br><span class="line">x = F.relu(self.fc1(x))</span><br><span class="line">x = F.relu(self.fc2(x))</span><br><span class="line">x = self.fc3(x)</span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">num_features = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">num_features *= s</span><br><span class="line"><span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="comment"># 输出网络结构</span></span><br><span class="line">print(net)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型参数存在net.parameters()中</span></span><br><span class="line">params = list(net.parameters())</span><br><span class="line">print(len(params))</span><br><span class="line">print(params[<span class="number">0</span>].size())  <span class="comment"># conv1's .weight</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试输入</span></span><br><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(input)</span><br><span class="line">print(out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型梯度置0然后反向传播</span></span><br><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.randn(<span class="number">1</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><p><strong>注：torch.nn只支持最小批量</strong></p><h4 id="1-6-2-损失函数"><a href="#1-6-2-损失函数" class="headerlink" title="1.6.2 损失函数"></a>1.6.2 损失函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">output = net(input)</span><br><span class="line">target = torch.randn(<span class="number">10</span>)  <span class="comment"># a dummy target, for example</span></span><br><span class="line">target = target.view(<span class="number">1</span>, <span class="number">-1</span>)  <span class="comment"># make it the same shape as output</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure><p>由此可以得出计算图：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d</span><br><span class="line">-&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear</span><br><span class="line">-&gt; MSELoss</span><br><span class="line">-&gt; loss</span><br></pre></td></tr></table></figure><h4 id="1-6-3-反向传播"><a href="#1-6-3-反向传播" class="headerlink" title="1.6.3 反向传播"></a>1.6.3 反向传播</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad()     <span class="comment"># zeroes the gradient buffers of all parameters</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad before backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'conv1.bias.grad after backward'</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br></pre></td></tr></table></figure><h4 id="1-6-4-更新权重"><a href="#1-6-4-更新权重" class="headerlink" title="1.6.4 更新权重"></a>1.6.4 更新权重</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># create your optimizer</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># in your training loop:</span></span><br><span class="line">optimizer.zero_grad()   <span class="comment"># zero the gradient buffers</span></span><br><span class="line">output = net(input)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()    <span class="comment"># Does the update</span></span><br></pre></td></tr></table></figure><p><strong>注：每次<code>optimizer.zero_grad()</code>需要手动置0，因为梯度是累积的。</strong></p><h3 id="1-7-训练一个分类器"><a href="#1-7-训练一个分类器" class="headerlink" title="1.7 训练一个分类器"></a>1.7 训练一个分类器</h3><h4 id="1-7-1-加载数据"><a href="#1-7-1-加载数据" class="headerlink" title="1.7.1 加载数据"></a>1.7.1 加载数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">[transforms.ToTensor(),</span><br><span class="line">transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">True</span>,</span><br><span class="line">download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">4</span>,</span><br><span class="line">shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(root=<span class="string">'./data'</span>, train=<span class="literal">False</span>,</span><br><span class="line">download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">4</span>,</span><br><span class="line">shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">'plane'</span>, <span class="string">'car'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>,</span><br><span class="line"><span class="string">'deer'</span>, <span class="string">'dog'</span>, <span class="string">'frog'</span>, <span class="string">'horse'</span>, <span class="string">'ship'</span>, <span class="string">'truck'</span>)</span><br></pre></td></tr></table></figure><h4 id="1-7-2-定义卷积神经网络"><a href="#1-7-2-定义卷积神经网络" class="headerlink" title="1.7.2 定义卷积神经网络"></a>1.7.2 定义卷积神经网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">super(Net, self).__init__()</span><br><span class="line">self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">x = F.relu(self.fc1(x))</span><br><span class="line">x = F.relu(self.fc2(x))</span><br><span class="line">x = self.fc3(x)</span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = Net()</span><br></pre></td></tr></table></figure><h4 id="1-7-3-定义损失函数和优化器"><a href="#1-7-3-定义损失函数和优化器" class="headerlink" title="1.7.3 定义损失函数和优化器"></a>1.7.3 定义损失函数和优化器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h4 id="1-7-4-训练网络"><a href="#1-7-4-训练网络" class="headerlink" title="1.7.4 训练网络"></a>1.7.4 训练网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># loop over the dataset multiple times</span></span><br><span class="line"></span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(trainloader, <span class="number">0</span>):</span><br><span class="line"><span class="comment"># get the inputs</span></span><br><span class="line">inputs, labels = data</span><br><span class="line"></span><br><span class="line"><span class="comment"># zero the parameter gradients</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="comment"># forward + backward + optimize</span></span><br><span class="line">outputs = net(inputs)</span><br><span class="line">loss = criterion(outputs, labels)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print statistics</span></span><br><span class="line">running_loss += loss.item()</span><br><span class="line"><span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:    <span class="comment"># print every 2000 mini-batches</span></span><br><span class="line">print(<span class="string">'[%d, %5d] loss: %.3f'</span> %</span><br><span class="line">(epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Finished Training'</span>)</span><br></pre></td></tr></table></figure><h4 id="1-7-5-测试"><a href="#1-7-5-测试" class="headerlink" title="1.7.5 测试"></a>1.7.5 测试</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class_correct = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line">class_total = list(<span class="number">0.</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">images, labels = data</span><br><span class="line">outputs = net(images)</span><br><span class="line">_, predicted = torch.max(outputs, <span class="number">1</span>)</span><br><span class="line">c = (predicted == labels).squeeze()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">label = labels[i]</span><br><span class="line">class_correct[label] += c[i].item()</span><br><span class="line">class_total[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">print(<span class="string">'Accuracy of %5s : %2d %%'</span> % (</span><br><span class="line">classes[i], <span class="number">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Accuracy <span class="keyword">of</span> plane : 72 %</span><br><span class="line">Accuracy <span class="keyword">of</span>   car : 47 %</span><br><span class="line">Accuracy <span class="keyword">of</span>  bird : 41 %</span><br><span class="line">Accuracy <span class="keyword">of</span>   cat : 32 %</span><br><span class="line">Accuracy <span class="keyword">of</span>  deer : 42 %</span><br><span class="line">Accuracy <span class="keyword">of</span>   dog : 49 %</span><br><span class="line">Accuracy <span class="keyword">of</span>  frog : 70 %</span><br><span class="line">Accuracy <span class="keyword">of</span> horse : 62 %</span><br><span class="line">Accuracy <span class="keyword">of</span>  ship : 46 %</span><br><span class="line">Accuracy <span class="keyword">of</span> truck : 76 %</span><br></pre></td></tr></table></figure><h4 id="1-7-6-GPU训练"><a href="#1-7-6-GPU训练" class="headerlink" title="1.7.6 GPU训练"></a>1.7.6 GPU训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assuming that we are on a CUDA machine, this should print a CUDA device:</span></span><br><span class="line"></span><br><span class="line">print(device)</span><br><span class="line"></span><br><span class="line">net.to(device)</span><br><span class="line">inputs, labels = inputs.to(device), labels.to(device)</span><br></pre></td></tr></table></figure><h3 id="1-8-数据并行"><a href="#1-8-数据并行" class="headerlink" title="1.8 数据并行"></a>1.8 数据并行</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cuda设备</span></span><br><span class="line">device = torch.device(<span class="string">"cuda:0"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型移到GPU</span></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入拷贝到GPU</span></span><br><span class="line">mytensor = my_tensor.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数据并行</span></span><br><span class="line">model = nn.DataParallel(model)</span><br></pre></td></tr></table></figure><hr><h2 id="2-数据"><a href="#2-数据" class="headerlink" title="2. 数据"></a>2. 数据</h2><h2 id="3-模型"><a href="#3-模型" class="headerlink" title="3. 模型"></a>3. 模型</h2><h2 id="4-策略（损失函数）"><a href="#4-策略（损失函数）" class="headerlink" title="4. 策略（损失函数）"></a>4. 策略（损失函数）</h2><h2 id="5-算法"><a href="#5-算法" class="headerlink" title="5. 算法"></a>5. 算法</h2>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 深度学习框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux环境变量配置</title>
      <link href="/2019/04/02/Linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/"/>
      <url>/2019/04/02/Linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="设置文件为"><a href="#设置文件为" class="headerlink" title="设置文件为:"></a>设置文件为:</h1><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">//</span>全局设置文件</span><br><span class="line"><span class="string">/etc/profile</span></span><br><span class="line"></span><br><span class="line"><span class="string">//</span>针对某个用户设置</span><br><span class="line">~<span class="string">/.bashrc</span></span><br><span class="line">`</span><br></pre></td></tr></table></figure><h1 id="设置PATH"><a href="#设置PATH" class="headerlink" title="设置PATH:"></a>设置PATH:</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=/your/bin/path:$PATH</span><br></pre></td></tr></table></figure><p><strong>注意：</strong> PATH=中间不能有空格。</p><h1 id="设置LD-LIBRARY-PATH"><a href="#设置LD-LIBRARY-PATH" class="headerlink" title="设置LD_LIBRARY_PATH:"></a>设置LD_LIBRARY_PATH:</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">LD_LIBRARY_PATH</span>=/your/lib/path:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure><p>另：也可以在/etc/ld.so.conf.d/ 下设置目录，然后调用ldconfig生效。</p><h1 id="生效："><a href="#生效：" class="headerlink" title="生效："></a>生效：</h1><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> ~/.bashrc</span><br><span class="line"><span class="built_in">or</span></span><br><span class="line"><span class="keyword">source</span> /etc/<span class="keyword">profile</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GStreamer插件之自定义数据结构</title>
      <link href="/2019/04/01/GStreamer%E6%8F%92%E4%BB%B6%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
      <url>/2019/04/01/GStreamer%E6%8F%92%E4%BB%B6%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="GstMeta"><a href="#GstMeta" class="headerlink" title="GstMeta"></a>GstMeta</h1><h3 id="当我们需要添加自定义的数据结构到GstBuffer中时，需要使用GstMeta自定义数据结构。"><a href="#当我们需要添加自定义的数据结构到GstBuffer中时，需要使用GstMeta自定义数据结构。" class="headerlink" title="当我们需要添加自定义的数据结构到GstBuffer中时，需要使用GstMeta自定义数据结构。"></a>当我们需要添加自定义的数据结构到GstBuffer中时，需要使用GstMeta自定义数据结构。</h3><h3 id="GstMeta数据结构为："><a href="#GstMeta数据结构为：" class="headerlink" title="GstMeta数据结构为："></a>GstMeta数据结构为：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> _<span class="title">GstMeta</span> &#123;</span></span><br><span class="line">  GstMetaFlags       flags;</span><br><span class="line">  <span class="keyword">const</span> GstMetaInfo *info;    <span class="comment">/* tag and info for the meta item */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="其中-info-结构体为："><a href="#其中-info-结构体为：" class="headerlink" title="其中 info 结构体为："></a>其中 info 结构体为：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> _<span class="title">GstMetaInfo</span> &#123;</span></span><br><span class="line">  GType                      api;       <span class="comment">//api 类型</span></span><br><span class="line">  GType                      type;      <span class="comment">//具体实现类型</span></span><br><span class="line">  gsize                      size;      <span class="comment">//自定义数据结构体大小</span></span><br><span class="line"></span><br><span class="line">  GstMetaInitFunction        init_func; <span class="comment">//初始化函数</span></span><br><span class="line">  GstMetaFreeFunction        free_func; <span class="comment">//释放函数</span></span><br><span class="line">  GstMetaTransformFunction   transform_func; <span class="comment">//转换函数</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中api成员需要由<em>gst_meta_api_type_register()</em>函数注册生成，具体看下文实施例。</p><h3 id="GstMeta是我们自定义数据结构体的公共头，比如gstreamer自带时间信息结构体："><a href="#GstMeta是我们自定义数据结构体的公共头，比如gstreamer自带时间信息结构体：" class="headerlink" title="GstMeta是我们自定义数据结构体的公共头，比如gstreamer自带时间信息结构体："></a>GstMeta是我们自定义数据结构体的公共头，比如gstreamer自带时间信息结构体：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> _<span class="title">GstMetaTiming</span> &#123;</span></span><br><span class="line">  GstMeta        meta;        <span class="comment">/* common meta header */</span></span><br><span class="line"></span><br><span class="line">  GstClockTime   dts;         <span class="comment">/* decoding timestamp */</span></span><br><span class="line">  GstClockTime   pts;         <span class="comment">/* presentation timestamp */</span></span><br><span class="line">  GstClockTime   duration;    <span class="comment">/* duration of the data */</span></span><br><span class="line">  GstClockTime   clock_rate;  <span class="comment">/* clock rate for the above values */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="自定义的数据结构体由字段或者方法组成。一个典型的buffer可能是如以下结构："><a href="#自定义的数据结构体由字段或者方法组成。一个典型的buffer可能是如以下结构：" class="headerlink" title="自定义的数据结构体由字段或者方法组成。一个典型的buffer可能是如以下结构："></a>自定义的数据结构体由字段或者方法组成。一个典型的buffer可能是如以下结构：</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">                         +----------------------------------+</span><br><span class="line">GstMiniObject            |  GType (GstBuffer)               |</span><br><span class="line">                         |  refcount, flags, copy/disp/<span class="built_in">free</span> |</span><br><span class="line">                         +----------------------------------+</span><br><span class="line">GstBuffer                |  pool,pts,dts,duration,offsets   |</span><br><span class="line">                         |  &lt;<span class="keyword">private</span> data&gt;                  |</span><br><span class="line">                         +..................................+</span><br><span class="line">                         |  next                           ---+</span><br><span class="line">                      +- |  info                           ------&gt; GstMetaInfo</span><br><span class="line">GstMetaTiming         |  |                                  | |</span><br><span class="line">                      |  |  dts                             | |</span><br><span class="line">                      |  |  pts                             | |</span><br><span class="line">                      |  |  duration                        | |</span><br><span class="line">                      +- |  clock_rate                      | |</span><br><span class="line">                         +  . . . . . . . . . . . . . . . . + |</span><br><span class="line">                         |  next                           &lt;--+</span><br><span class="line">GstVideoMeta       +- +- |  info                           ------&gt; GstMetaInfo</span><br><span class="line">                   |  |  |                                  | |</span><br><span class="line">                   |  |  |  flags                           | |</span><br><span class="line">                   |  |  |  n_planes                        | |</span><br><span class="line">                   |  |  |  planes[]                        | |</span><br><span class="line">                   |  |  |  <span class="built_in">map</span>                             | |</span><br><span class="line">                   |  |  |  unmap                           | |</span><br><span class="line">                   +- |  |                                  | |</span><br><span class="line">                      |  |  <span class="keyword">private</span> fields                  | |</span><br><span class="line">GstVideoMetaImpl      |  |  ...                             | |</span><br><span class="line">                      |  |  ...                             | |</span><br><span class="line">                      +- |                                  | |</span><br><span class="line">                         +  . . . . . . . . . . . . . . . . + .</span><br></pre></td></tr></table></figure><h1 id="自定义meta实现"><a href="#自定义meta实现" class="headerlink" title="自定义meta实现"></a>自定义meta实现</h1><h2 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> GSTFACEPARAMMETA_H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GSTFACEPARAMMETA_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"gst/gst.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** Defines GStreamer metadata types. */</span></span><br><span class="line"><span class="comment">//定义枚举类型，用来指定meta_data指针所指向的数据类型</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span></span><br><span class="line">&#123;</span><br><span class="line">    META_INIT = <span class="number">0x0</span>,</span><br><span class="line">    FACE_PARAM,</span><br><span class="line">&#125; Meta_type;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">FaceParamMeta</span> <span class="title">FaceParamMeta</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//该结构体为要附加的元数据结构体</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> _<span class="title">FaceParamMeta</span> &#123;</span></span><br><span class="line">    <span class="comment">//公共头</span></span><br><span class="line">    GstMeta meta;</span><br><span class="line">    <span class="comment">//存储各种需要的自定义结构体，方便扩展</span></span><br><span class="line">    <span class="keyword">void</span> *meta_data;</span><br><span class="line">    <span class="comment">//meta_data指针指向的结构体类型</span></span><br><span class="line">    <span class="keyword">int</span> meta_type;</span><br><span class="line">    <span class="comment">//类似回调函数指针，在buffer销毁的时候会调用</span></span><br><span class="line">    GDestroyNotify destroy;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//注册api type的接口，返回api用于注册meta</span></span><br><span class="line"><span class="function">GType <span class="title">face_param_meta_api_get_type</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FACE_PARAM_META_API_TYPE (face_param_meta_api_get_type())</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//注册meta的时候返回GstMetaInfo</span></span><br><span class="line"><span class="function"><span class="keyword">const</span> GstMetaInfo *<span class="title">face_param_meta_get_info</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FACE_PARAM_META_INFO (face_param_meta_get_info())</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//往buffer中添加数据，返回FaceParamMeta*指针指向添加位置</span></span><br><span class="line"><span class="function">FaceParamMeta *<span class="title">gst_buffer_add_face_param_meta</span><span class="params">(GstBuffer *buffer, <span class="keyword">void</span> *metadata, <span class="keyword">int</span> metatype, GDestroyNotify destroy)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//从buffer中获取自定义meta数据</span></span><br><span class="line"><span class="function">FaceParamMeta *<span class="title">gst_buffer_get_face_param_meta</span><span class="params">(GstBuffer *buffer)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// GSTFACEPARAMMETA_H</span></span></span><br></pre></td></tr></table></figure><h2 id="实现文件"><a href="#实现文件" class="headerlink" title="实现文件"></a>实现文件</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"gstfaceparammeta.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">GType <span class="title">face_param_meta_api_get_type</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">volatile</span> GType type;</span><br><span class="line">    <span class="comment">//可以往api type加入标签，使用gst_meta_api_type_has_tag查找是否由我们自定义结构体</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> gchar *tags[] = &#123;<span class="string">"face"</span>, <span class="string">"detect"</span>, <span class="literal">NULL</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(g_once_init_enter(&amp;type)) &#123;</span><br><span class="line">        <span class="comment">//注册api type</span></span><br><span class="line">        GType _type = gst_meta_api_type_register(<span class="string">"FaceParamMetaAPI"</span>, tags);</span><br><span class="line">        g_once_init_leave(&amp;type, _type);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> type;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化函数实现</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> gboolean <span class="title">face_param_meta_init</span><span class="params">(GstMeta *meta, gpointer params, GstBuffer *buffer)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FaceParamMeta *emeta = (FaceParamMeta*) meta;</span><br><span class="line"></span><br><span class="line">    emeta-&gt;meta_type = META_INIT;</span><br><span class="line">    emeta-&gt;meta_data = <span class="literal">NULL</span>;</span><br><span class="line">    emeta-&gt;destroy = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> TRUE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//转换函数实现，具体复杂情况下怎么用还需琢磨</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> gboolean <span class="title">face_param_meta_transform</span><span class="params">(GstBuffer *transbuf, GstMeta *meta,</span></span></span><br><span class="line"><span class="function"><span class="params">                            GstBuffer *buffer, GQuark type, gpointer data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FaceParamMeta *emeta = (FaceParamMeta*) meta;</span><br><span class="line">    gst_buffer_add_face_param_meta(transbuf, emeta-&gt;meta_data, emeta-&gt;meta_type, emeta-&gt;destroy);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> TRUE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//释放函数</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">face_param_meta_free</span><span class="params">(GstMeta *meta, GstBuffer *buffer)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FaceParamMeta *emeta = (FaceParamMeta*) meta;</span><br><span class="line"></span><br><span class="line">    emeta-&gt;meta_type = META_INIT;</span><br><span class="line">    <span class="comment">//回调函数</span></span><br><span class="line">    emeta-&gt;destroy(emeta-&gt;meta_data);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//注册我们的meta函数</span></span><br><span class="line"><span class="function"><span class="keyword">const</span> GstMetaInfo *<span class="title">face_param_meta_get_info</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">const</span> GstMetaInfo *meta_info = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(g_once_init_enter(&amp;meta_info)) &#123;</span><br><span class="line">        <span class="comment">//注册返回GstMetaInfo</span></span><br><span class="line">        <span class="comment">//第二个参数可以在gst_meta_get_info（）函数使用</span></span><br><span class="line">        <span class="keyword">const</span> GstMetaInfo *mi = gst_meta_register(FACE_PARAM_META_API_TYPE,</span><br><span class="line">                                                  <span class="string">"FaceParamMeta"</span>,</span><br><span class="line">                                                  <span class="keyword">sizeof</span>(FaceParamMeta),</span><br><span class="line">                                                  face_param_meta_init,</span><br><span class="line">                                                  face_param_meta_free,</span><br><span class="line">                                                  face_param_meta_transform);</span><br><span class="line">        g_once_init_leave(&amp;meta_info, mi);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> meta_info;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//增加数据</span></span><br><span class="line"><span class="function">FaceParamMeta *<span class="title">gst_buffer_add_face_param_meta</span><span class="params">(GstBuffer *buffer, <span class="keyword">void</span> *metadata, <span class="keyword">int</span> metatype, GDestroyNotify destroy)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FaceParamMeta *meta;</span><br><span class="line">    g_return_val_if_fail(GST_IS_BUFFER(buffer), <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    meta = (FaceParamMeta *)gst_buffer_add_meta(buffer, FACE_PARAM_META_INFO, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">//指针简单赋值，需要注意外面传进来的指针必须不是局部变量，否则会自动释放</span></span><br><span class="line">    meta-&gt;meta_data = metadata;</span><br><span class="line">    <span class="comment">//meta_data指向类型</span></span><br><span class="line">    meta-&gt;meta_type = metatype;</span><br><span class="line">    <span class="comment">//回调函数，在free的时候使用</span></span><br><span class="line">    meta-&gt;destroy = destroy;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> meta;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取数据</span></span><br><span class="line"><span class="function">FaceParamMeta *<span class="title">gst_buffer_get_face_param_meta</span><span class="params">(GstBuffer *buffer)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FaceParamMeta *meta;</span><br><span class="line"></span><br><span class="line">    meta = (FaceParamMeta *)gst_buffer_get_meta(buffer, FACE_PARAM_META_API_TYPE);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> meta;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="具体使用"><a href="#具体使用" class="headerlink" title="具体使用"></a>具体使用</h1><h2 id="调用添加数据函数"><a href="#调用添加数据函数" class="headerlink" title="调用添加数据函数"></a>调用添加数据函数</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">faceParamMeta = gst_buffer_add_face_param_meta(outbuf, metadata, FACE_PARAM, free_face_param_meta);</span><br></pre></td></tr></table></figure><h2 id="释放函数为："><a href="#释放函数为：" class="headerlink" title="释放函数为："></a>释放函数为：</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Free the metadata allocated in attach_metadata_full_frame</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">free_face_param_meta (gpointer meta_data)</span><br><span class="line">&#123;</span><br><span class="line">     g_print (<span class="string">"free output buffer, free output buffer.\n"</span>);</span><br><span class="line">  MtcnnPluginOutput *output = (MtcnnPluginOutput *)meta_data;</span><br><span class="line">  g_free(output);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="获取数据可以使用如下方法："><a href="#获取数据可以使用如下方法：" class="headerlink" title="获取数据可以使用如下方法："></a>获取数据可以使用如下方法：</h2><h3 id="方法1："><a href="#方法1：" class="headerlink" title="方法1："></a>方法1：</h3><p>直接调用我们自己定义的函数<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">metadata = gst_buffer_get_face_param_meta();</span><br></pre></td></tr></table></figure></p><h3 id="方法2："><a href="#方法2：" class="headerlink" title="方法2："></a>方法2：</h3><p>因为我们可能在不同的element中添加很多个自定义数据结构，使用方法1只能取到最后一个添加的，需要使用以下方法进行遍历：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> GQuark _ivameta_quark = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (!_ivameta_quark) &#123;</span><br><span class="line">    <span class="comment">//注意参数时我们注册api type时添加的tag</span></span><br><span class="line">    <span class="comment">//类似键值对</span></span><br><span class="line">    _ivameta_quark = g_quark_from_static_string (<span class="string">"face"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">GstMeta *gst_meta;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Standard way of iterating through buffer metadata</span></span><br><span class="line"><span class="keyword">while</span> ((gst_meta = gst_buffer_iterate_meta (outbuf, &amp;state)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//可以获取GstMetaInfo，注意参数需要和注册时一致</span></span><br><span class="line">    <span class="keyword">const</span> GstMetaInfo *info = gst_meta_get_info(<span class="string">"FaceParamMeta"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查询是否有我们想要的api type</span></span><br><span class="line">    <span class="keyword">if</span> (!gst_meta_api_type_has_tag (gst_meta-&gt;info-&gt;api, _ivameta_quark)) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//如果是，转成我们的结构体</span></span><br><span class="line">    ivameta = (FaceParamMeta *) gst_meta;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if the metadata of IvaMeta contains object bounding boxes</span></span><br><span class="line">    <span class="keyword">if</span> (ivameta-&gt;meta_type != FACE_PARAM)</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//根据meta_type获取具体数据</span></span><br><span class="line">    meta_data = (MtcnnPluginOutput *) ivameta-&gt;meta_data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="参考官网链接"><a href="#参考官网链接" class="headerlink" title="参考官网链接:"></a>参考官网链接:</h1><p><a href="https://gstreamer.freedesktop.org/documentation/design/meta.html" target="_blank" rel="noopener">GstMeta</a><br><a href="https://gstreamer.freedesktop.org/documentation/plugin-development/advanced/allocation.html" target="_blank" rel="noopener">Memory allocation</a></p>]]></content>
      
      
      <categories>
          
          <category> GStreamer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GStreamer </tag>
            
            <tag> 插件 </tag>
            
            <tag> 视频流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2019学习计划</title>
      <link href="/2019/03/31/2019%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/"/>
      <url>/2019/03/31/2019%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GStreamer插件编写学习</title>
      <link href="/2019/03/29/GStreamer%E6%8F%92%E4%BB%B6%E7%BC%96%E5%86%99%E5%AD%A6%E4%B9%A0/"/>
      <url>/2019/03/29/GStreamer%E6%8F%92%E4%BB%B6%E7%BC%96%E5%86%99%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="下载插件模板"><a href="#下载插件模板" class="headerlink" title="下载插件模板"></a>下载插件模板</h1><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">shell $ git clone <span class="string">https:</span><span class="comment">//gitlab.freedesktop.org/gstreamer/gst-template.git</span></span><br><span class="line">Initialized empty Git repository <span class="keyword">in</span> <span class="regexp">/some/</span>path<span class="regexp">/gst-template/</span>.git/</span><br><span class="line"><span class="string">remote:</span> Counting <span class="string">objects:</span> <span class="number">373</span>, done.</span><br><span class="line"><span class="string">remote:</span> Compressing <span class="string">objects:</span> <span class="number">100</span>% (<span class="number">114</span>/<span class="number">114</span>), done.</span><br><span class="line"><span class="string">remote:</span> Total <span class="number">373</span> (delta <span class="number">240</span>), reused <span class="number">373</span> (delta <span class="number">240</span>)</span><br><span class="line">Receiving <span class="string">objects:</span> <span class="number">100</span>% (<span class="number">373</span><span class="regexp">/373), 75.16 KiB | 78 KiB/</span>s, done.</span><br><span class="line">Resolving <span class="string">deltas:</span> <span class="number">100</span>% (<span class="number">240</span>/<span class="number">240</span>), done.</span><br></pre></td></tr></table></figure><p><strong>以上方案有点过时，可到github下载gst-plugins-bad模块，使用里面的工具生成模板。</strong></p><h1 id="使用make-element生成模板"><a href="#使用make-element生成模板" class="headerlink" title="使用make_element生成模板"></a>使用make_element生成模板</h1><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd gst-template<span class="meta-keyword">/gst-plugin/</span>src</span><br><span class="line">..<span class="meta-keyword">/tools/</span>make_element MyFilter <span class="params">&lt;基类文件如:gsttransform&gt;</span></span><br></pre></td></tr></table></figure><h1 id="修改makefile-am文件"><a href="#修改makefile-am文件" class="headerlink" title="修改makefile.am文件"></a>修改makefile.am文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># Note: plugindir is set in configure</span><br><span class="line">##############################################################################</span><br><span class="line"># TODO: change libgstplugin.la to something else, e.g. libmysomething.la     #</span><br><span class="line">##############################################################################</span><br><span class="line">plugin_LTLIBRARIES = libgstplugin.la libgstaudiofilterexample.la</span><br><span class="line">##############################################################################</span><br><span class="line"># TODO: for the next set of variables, name the prefix if you named the .la, #</span><br><span class="line">#  e.g. libmysomething.la =&gt; libmysomething_la_SOURCES                       #</span><br><span class="line">#                            libmysomething_la_CFLAGS                        #</span><br><span class="line">#                            libmysomething_la_LIBADD                        #</span><br><span class="line">#                            libmysomething_la_LDFLAGS                       #</span><br><span class="line">##############################################################################</span><br><span class="line">## Plugin 1</span><br><span class="line"># sources used to compile this plug-in</span><br><span class="line">libgstplugin_la_SOURCES = gstplugin.c gstplugin.h</span><br><span class="line"># compiler and linker flags used to compile this plugin, set in configure.ac</span><br><span class="line">libgstplugin_la_CFLAGS = $(GST_CFLAGS)</span><br><span class="line">libgstplugin_la_LIBADD = $(GST_LIBS)</span><br><span class="line">libgstplugin_la_LDFLAGS = $(GST_PLUGIN_LDFLAGS)</span><br><span class="line">libgstplugin_la_LIBTOOLFLAGS = --tag=disable-static</span><br><span class="line"># headers we need but don&apos;t want installed</span><br><span class="line">noinst_HEADERS = gstplugin.h</span><br></pre></td></tr></table></figure><h1 id="生成makefile文件"><a href="#生成makefile文件" class="headerlink" title="生成makefile文件"></a>生成makefile文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./autogen.sh</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><p><strong>注意：需要修改configure.ac文件里面安装的路径，不然插件会被安装到/usr/local/lib/gstreamer-1.0中</strong> </p><h1 id="Example-Demo"><a href="#Example-Demo" class="headerlink" title="Example Demo"></a>Example Demo</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;gst/gst.h&gt;</span></span></span><br><span class="line"><span class="comment">/* Definition of structure storing data for this element. */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">GstMyFilter</span> &#123;</span></span><br><span class="line">  GstElement element;</span><br><span class="line">  GstPad *sinkpad, *srcpad;</span><br><span class="line">  gboolean silent;</span><br><span class="line">&#125; GstMyFilter;</span><br><span class="line">    </span><br><span class="line"><span class="comment">/* Standard definition defining a class for this element. */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">GstMyFilterClass</span> &#123;</span></span><br><span class="line">  GstElementClass parent_class;</span><br><span class="line">&#125; GstMyFilterClass;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Standard macros for defining types for this element.  */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GST_TYPE_MY_FILTER (gst_my_filter_get_type())</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GST_MY_FILTER(obj) \</span></span><br><span class="line">  (G_TYPE_CHECK_INSTANCE_CAST((obj),GST_TYPE_MY_FILTER,GstMyFilter))</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GST_MY_FILTER_CLASS(klass) \</span></span><br><span class="line">  (G_TYPE_CHECK_CLASS_CAST((klass),GST_TYPE_MY_FILTER,GstMyFilterClass))</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GST_IS_MY_FILTER(obj) \</span></span><br><span class="line">  (G_TYPE_CHECK_INSTANCE_TYPE((obj),GST_TYPE_MY_FILTER))</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> GST_IS_MY_FILTER_CLASS(klass) \</span></span><br><span class="line">  (G_TYPE_CHECK_CLASS_TYPE((klass),GST_TYPE_MY_FILTER))</span><br><span class="line">  </span><br><span class="line"><span class="comment">/* Standard function returning type information. */</span></span><br><span class="line"><span class="function">GType <span class="title">gst_my_filter_get_type</span> <span class="params">(<span class="keyword">void</span>)</span></span>;</span><br></pre></td></tr></table></figure><h1 id="Element-metadata"><a href="#Element-metadata" class="headerlink" title="Element metadata"></a>Element metadata</h1><p>元素元数据提供额外的元素信息，使用<em>gst_element_class_set_metadata</em>或者<em>gst_element_class_set_static_metadata</em>函数来设置，其参数包含：</p><ul><li>A long, English, name for the element.</li><li>The type of the element, see the docs/design/draft-klass.txt document<br>in the GStreamer core source tree for details and examples.</li><li>A brief description of the purpose of the element.</li><li>The name of the author of the element, optionally followed by a<br>contact email address in angle brackets.<h4 id="例如："><a href="#例如：" class="headerlink" title="例如："></a>例如：</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gst_element_class_set_static_metadata (klass,</span><br><span class="line"><span class="string">"An example plugin"</span>,</span><br><span class="line"><span class="string">"Example/FirstExample"</span>,</span><br><span class="line"><span class="string">"Shows the basic structure of a plugin"</span>,</span><br><span class="line"><span class="string">"your name &lt;your.name@your.isp&gt;"</span>);</span><br></pre></td></tr></table></figure></li></ul><h4 id="以上函数在初始化-class-init-插件的时候调用"><a href="#以上函数在初始化-class-init-插件的时候调用" class="headerlink" title="以上函数在初始化_class_init ()插件的时候调用"></a>以上函数在初始化<em>_class_init ()</em>插件的时候调用</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_class_init (GstMyFilterClass * klass)</span><br><span class="line">&#123;</span><br><span class="line">  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);</span><br><span class="line"></span><br><span class="line">[..]</span><br><span class="line">  gst_element_class_set_static_metadata (element_klass,</span><br><span class="line">    <span class="string">"An example plugin"</span>,</span><br><span class="line">    <span class="string">"Example/FirstExample"</span>,</span><br><span class="line">    <span class="string">"Shows the basic structure of a plugin"</span>,</span><br><span class="line">    <span class="string">"your name &lt;your.name@your.isp&gt;"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="GstStaticPadTemplate"><a href="#GstStaticPadTemplate" class="headerlink" title="GstStaticPadTemplate"></a>GstStaticPadTemplate</h1><p>GstStaticPadTemplate是用来描述将要创建的pad的信息，包含:</p><ul><li>A short name for the pad.</li><li>Pad direction.</li><li>Existence property. This indicates whether the pad exists always (an “always” pad), only in some cases (a “sometimes” pad) or only if the application requested such a pad (a “request” pad).</li><li>Supported types by this element (capabilities).<h4 id="例如：-1"><a href="#例如：-1" class="headerlink" title="例如："></a>例如：</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> GstStaticPadTemplate sink_factory =</span><br><span class="line">GST_STATIC_PAD_TEMPLATE (</span><br><span class="line">  <span class="string">"sink"</span>,         <span class="comment">//名称</span></span><br><span class="line">  GST_PAD_SINK,   <span class="comment">//方向sink or src</span></span><br><span class="line">  GST_PAD_ALWAYS,   <span class="comment">//availability</span></span><br><span class="line">  GST_STATIC_CAPS (<span class="string">"ANY"</span>)  <span class="comment">//capability</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure></li></ul><p>同样该<em>sink_factory</em>也是在初始化时候使用，通过<em>gst_element_class_add_pad_template ()</em>和<em>gst_static_pad_template_get ()</em>来调用<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> GstStaticPadTemplate sink_factory = [..],</span><br><span class="line">    src_factory = [..];</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_class_init (GstMyFilterClass * klass)</span><br><span class="line">&#123;</span><br><span class="line">  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);</span><br><span class="line">[..]</span><br><span class="line"></span><br><span class="line">  gst_element_class_add_pad_template (element_class,</span><br><span class="line">    gst_static_pad_template_get (&amp;src_factory));</span><br><span class="line">  gst_element_class_add_pad_template (element_class,</span><br><span class="line">    gst_static_pad_template_get (&amp;sink_factory));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>该pad将在构造函数<em>_init ()</em>函数中使用<em>gst_pad_new_from_static_template ()</em>来创建。</p><p><strong>注：对于每个element来说，有两个构造函数，其中<em>_class_init()</em>函数只调用一次，用来说明类所拥有的信号、参数、虚函数以及设置全局状态；<em>_init()</em>函数则用在初始化实例特定的实例。</strong></p><h1 id="插件初始化函数"><a href="#插件初始化函数" class="headerlink" title="插件初始化函数"></a>插件初始化函数</h1><p>当我们写完插件的所有部件之后，需要编写插件的初始化函数，这个函数在插件加载的时候调用，需要返回TRUE or FALSE来觉得是否正确加载。在这个函数中，任何支持的element插件应该被注册。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> gboolean</span><br><span class="line">plugin_init (GstPlugin *plugin)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">return</span> gst_element_register (plugin, <span class="string">"my_filter"</span>,</span><br><span class="line">                   GST_RANK_NONE,</span><br><span class="line">                   GST_TYPE_MY_FILTER);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GST_PLUGIN_DEFINE (</span><br><span class="line">  GST_VERSION_MAJOR,</span><br><span class="line">  GST_VERSION_MINOR,</span><br><span class="line">  my_filter,</span><br><span class="line">  <span class="string">"My filter plugin"</span>,</span><br><span class="line">  plugin_init,</span><br><span class="line">  VERSION,</span><br><span class="line">  <span class="string">"LGPL"</span>,</span><br><span class="line">  <span class="string">"GStreamer"</span>,</span><br><span class="line">  <span class="string">"http://gstreamer.net/"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><h1 id="pads具体说明"><a href="#pads具体说明" class="headerlink" title="pads具体说明"></a>pads具体说明</h1><p>PADS是数据流进出每个element的端口，在初始化<em>_init ()</em>函数中，你从pad template中创建了一个pad，这个pad template是在<em>_class_init ()</em>函数中注册的，创建了pad之后，你必须在sinkpad设置<em>_chain ()</em>函数指针用来接收和处理数据。可选的，你也可以设置<em>_event ()</em>和<em>_query ()</em>指针；pad亦可以使用循环模式，这意味着它们可以自己拉取数据。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_init (GstMyFilter *filter)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">/* pad through which data comes in to the element */</span></span><br><span class="line">  filter-&gt;sinkpad = gst_pad_new_from_static_template (</span><br><span class="line">    &amp;sink_template, <span class="string">"sink"</span>);</span><br><span class="line">  <span class="comment">/* pads are configured here with gst_pad_set_*_function () */</span></span><br><span class="line"></span><br><span class="line">  gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;sinkpad);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* pad through which data goes out of the element */</span></span><br><span class="line">  filter-&gt;srcpad = gst_pad_new_from_static_template (</span><br><span class="line">    &amp;src_template, <span class="string">"src"</span>);</span><br><span class="line">  <span class="comment">/* pads are configured here with gst_pad_set_*_function () */</span></span><br><span class="line">    </span><br><span class="line">  gst_element_add_pad (GST_ELEMENT (filter), filter-&gt;srcpad);</span><br><span class="line">    </span><br><span class="line">  <span class="comment">/* properties initial value */</span></span><br><span class="line">      filter-&gt;silent = FALSE;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><h2 id="Sometimes-Pad"><a href="#Sometimes-Pad" class="headerlink" title="Sometimes Pad"></a>Sometimes Pad</h2><p>Sometimes pad 只有在一些特定情况下才创建，这取决于流内容。比如demuxers解析流头。每个element可以创建多个sometimes pad，唯一限制就是都要有唯一的名字。当流数据被销毁时（比如从PAUSED到READY状态），pad也应该被销毁，但是在EOS状态不应该被销毁。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">GstMyFilter</span> &#123;</span></span><br><span class="line">[..]</span><br><span class="line">  gboolean firstrun;</span><br><span class="line">  GList *srcpadlist;</span><br><span class="line">&#125; GstMyFilter;</span><br><span class="line"></span><br><span class="line"><span class="comment">//静态目标类型sometimes</span></span><br><span class="line"><span class="keyword">static</span> GstStaticPadTemplate src_factory =</span><br><span class="line">GST_STATIC_PAD_TEMPLATE (</span><br><span class="line">  <span class="string">"src_%u"</span>,</span><br><span class="line">  GST_PAD_SRC,</span><br><span class="line">  GST_PAD_SOMETIMES,</span><br><span class="line">  GST_STATIC_CAPS (<span class="string">"ANY"</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_class_init (GstMyFilterClass *klass)</span><br><span class="line">&#123;</span><br><span class="line">  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);</span><br><span class="line">[..]</span><br><span class="line"><span class="comment">//注册pad</span></span><br><span class="line">  gst_element_class_add_pad_template (element_class,</span><br><span class="line">    gst_static_pad_template_get (&amp;src_factory));</span><br><span class="line">[..]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_init (GstMyFilter *filter)</span><br><span class="line">&#123;</span><br><span class="line">[..]</span><br><span class="line">  filter-&gt;firstrun = TRUE;</span><br><span class="line">  filter-&gt;srcpadlist = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Get one line of data - without newline.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> GstBuffer *</span><br><span class="line">gst_my_filter_getline (GstMyFilter *filter)</span><br><span class="line">&#123;</span><br><span class="line">  guint8 *data;</span><br><span class="line">  gint n, num;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* max. line length is 512 characters - for safety */</span></span><br><span class="line">  <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; <span class="number">512</span>; n++) &#123;</span><br><span class="line">    num = gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (num != n + <span class="number">1</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* newline? */</span></span><br><span class="line">    <span class="keyword">if</span> (data[n] == <span class="string">'\n'</span>) &#123;</span><br><span class="line">      GstBuffer *buf = gst_buffer_new_allocate (<span class="literal">NULL</span>, n + <span class="number">1</span>, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">      gst_bytestream_peek_bytes (filter-&gt;bs, &amp;data, n);</span><br><span class="line">      gst_buffer_fill (buf, <span class="number">0</span>, data, n);</span><br><span class="line">      gst_buffer_memset (buf, n, <span class="string">'\0'</span>, <span class="number">1</span>);</span><br><span class="line">      gst_bytestream_flush_fast (filter-&gt;bs, n + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> buf;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_loopfunc (GstElement *element)</span><br><span class="line">&#123;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (element);</span><br><span class="line">  GstBuffer *buf;</span><br><span class="line">  GstPad *pad;</span><br><span class="line">  GstMapInfo <span class="built_in">map</span>;</span><br><span class="line">  gint num, n;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* parse header */</span></span><br><span class="line">  <span class="keyword">if</span> (filter-&gt;firstrun) &#123;</span><br><span class="line">    gchar *padname;</span><br><span class="line">    guint8 id;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!(buf = gst_my_filter_getline (filter))) &#123;</span><br><span class="line">      gst_element_error (element, STREAM, READ, (<span class="literal">NULL</span>),</span><br><span class="line">             (<span class="string">"Stream contains no header"</span>));</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    gst_buffer_extract (buf, <span class="number">0</span>, &amp;id, <span class="number">1</span>);</span><br><span class="line">    num = atoi (id);</span><br><span class="line">    gst_buffer_unref (buf);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* for each of the streams, create a pad */</span></span><br><span class="line">    <span class="comment">//根据头的流个数，创建num个pad</span></span><br><span class="line">    <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; num; n++) &#123;</span><br><span class="line">      padname = g_strdup_printf (<span class="string">"src_%u"</span>, n);</span><br><span class="line">      pad = gst_pad_new_from_static_template (src_factory, padname);</span><br><span class="line">      g_free (padname);</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* here, you would set _event () and _query () functions */</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">/* need to activate the pad before adding */</span></span><br><span class="line">      gst_pad_set_active (pad, TRUE);</span><br><span class="line"></span><br><span class="line">      gst_element_add_pad (element, pad);</span><br><span class="line">      filter-&gt;srcpadlist = g_list_append (filter-&gt;srcpadlist, pad);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* and now, simply parse each line and push over */</span></span><br><span class="line">  <span class="keyword">if</span> (!(buf = gst_my_filter_getline (filter))) &#123;</span><br><span class="line">    GstEvent *event = gst_event_new (GST_EVENT_EOS);</span><br><span class="line">    GList *padlist;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (padlist = srcpadlist;</span><br><span class="line">         padlist != <span class="literal">NULL</span>; padlist = g_list_next (padlist)) &#123;</span><br><span class="line">      pad = GST_PAD (padlist-&gt;data);</span><br><span class="line">      gst_pad_push_event (pad, gst_event_ref (event));</span><br><span class="line">    &#125;</span><br><span class="line">    gst_event_unref (event);</span><br><span class="line">    <span class="comment">/* pause the task here */</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* parse stream number and go beyond the ':' in the data */</span></span><br><span class="line">  gst_buffer_map (buf, &amp;<span class="built_in">map</span>, GST_MAP_READ);</span><br><span class="line">  num = atoi (<span class="built_in">map</span>.data[<span class="number">0</span>]);</span><br><span class="line">  <span class="keyword">if</span> (num &gt;= <span class="number">0</span> &amp;&amp; num &lt; g_list_length (filter-&gt;srcpadlist)) &#123;</span><br><span class="line">  <span class="comment">//取第N个pad塞数据</span></span><br><span class="line">    pad = GST_PAD (g_list_nth_data (filter-&gt;srcpadlist, num);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* magic buffer parsing foo */</span></span><br><span class="line">    <span class="keyword">for</span> (n = <span class="number">0</span>; <span class="built_in">map</span>.data[n] != <span class="string">':'</span> &amp;&amp;</span><br><span class="line">                <span class="built_in">map</span>.data[n] != <span class="string">'\0'</span>; n++) ;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">map</span>.data[n] != <span class="string">'\0'</span>) &#123;</span><br><span class="line">      GstBuffer *sub;</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* create region copy that starts right past the space. The reason</span></span><br><span class="line"><span class="comment">       * that we don't just forward the data pointer is because the</span></span><br><span class="line"><span class="comment">       * pointer is no longer the start of an allocated block of memory,</span></span><br><span class="line"><span class="comment">       * but just a pointer to a position somewhere in the middle of it.</span></span><br><span class="line"><span class="comment">       * That cannot be freed upon disposal, so we'd either crash or have</span></span><br><span class="line"><span class="comment">       * a memleak. Creating a region copy is a simple way to solve that. */</span></span><br><span class="line">      sub = gst_buffer_copy_region (buf, GST_BUFFER_COPY_ALL,</span><br><span class="line">          n + <span class="number">1</span>, <span class="built_in">map</span>.size - n - <span class="number">1</span>);</span><br><span class="line">      gst_pad_push (pad, sub);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  gst_buffer_unmap (buf, &amp;<span class="built_in">map</span>);</span><br><span class="line">  gst_buffer_unref (buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Request-pad"><a href="#Request-pad" class="headerlink" title="Request pad"></a>Request pad</h2><p>Request pad 只有在外部需要的时候才创建而不是element内部。比如tee element可以根据需要拷贝多份数据到不同的分支。需要实现<em>request_new_pad</em>和<em>release_pad</em>两个虚函数<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> GstPad * <span class="title">gst_my_filter_request_new_pad</span>   <span class="params">(GstElement     *element,</span></span></span><br><span class="line"><span class="function"><span class="params">                         GstPadTemplate *templ,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                 <span class="keyword">const</span> gchar    *name,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                 <span class="keyword">const</span> GstCaps  *caps)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">gst_my_filter_release_pad</span> <span class="params">(GstElement *element,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       GstPad *pad)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> GstStaticPadTemplate sink_factory =</span><br><span class="line">GST_STATIC_PAD_TEMPLATE (</span><br><span class="line">  <span class="string">"sink_%u"</span>,</span><br><span class="line">  GST_PAD_SINK,</span><br><span class="line">  GST_PAD_REQUEST,</span><br><span class="line">  GST_STATIC_CAPS (<span class="string">"ANY"</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_class_init (GstMyFilterClass *klass)</span><br><span class="line">&#123;</span><br><span class="line">  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);</span><br><span class="line">[..]</span><br><span class="line">  gst_element_class_add_pad_template (klass,</span><br><span class="line">    gst_static_pad_template_get (&amp;sink_factory));</span><br><span class="line">[..]</span><br><span class="line">  element_class-&gt;request_new_pad = gst_my_filter_request_new_pad;</span><br><span class="line">  element_class-&gt;release_pad = gst_my_filter_release_pad;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> GstPad *</span><br><span class="line">gst_my_filter_request_new_pad (GstElement     *element,</span><br><span class="line">                   GstPadTemplate *templ,</span><br><span class="line">                   <span class="keyword">const</span> gchar    *name,</span><br><span class="line">                               <span class="keyword">const</span> GstCaps  *caps)</span><br><span class="line">&#123;</span><br><span class="line">  GstPad *pad;</span><br><span class="line">  GstMyFilterInputContext *context;</span><br><span class="line"></span><br><span class="line">  context = g_new0 (GstMyFilterInputContext, <span class="number">1</span>);</span><br><span class="line">  pad = gst_pad_new_from_template (templ, name);</span><br><span class="line">  gst_pad_set_element_private (pad, context);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* normally, you would set _chain () and _event () functions here */</span></span><br><span class="line"></span><br><span class="line">  gst_element_add_pad (element, pad);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> pad;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_release_pad (GstElement *element,</span><br><span class="line">                           GstPad *pad)</span><br><span class="line">&#123;</span><br><span class="line">  GstMyFilterInputContext *context;</span><br><span class="line"></span><br><span class="line">  context = gst_pad_get_element_private (pad);</span><br><span class="line">  g_free (context);</span><br><span class="line"></span><br><span class="line">  gst_element_remove_pad (element, pad);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="The-chain-function"><a href="#The-chain-function" class="headerlink" title="The chain function"></a>The chain function</h1><p>chain函数是处理数据的地方，记住buffers并不总是可写的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> GstFlowReturn <span class="title">gst_my_filter_chain</span> <span class="params">(GstPad    *pad,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          GstObject *parent,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          GstBuffer *buf)</span></span>;</span><br><span class="line"></span><br><span class="line">[..]</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_init (GstMyFilter * filter)</span><br><span class="line">&#123;</span><br><span class="line">[..]</span><br><span class="line">  <span class="comment">/* configure chain function on the pad before adding</span></span><br><span class="line"><span class="comment">   * the pad to the element */</span></span><br><span class="line">  gst_pad_set_chain_function (filter-&gt;sinkpad,</span><br><span class="line">      gst_my_filter_chain);</span><br><span class="line">[..]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> GstFlowReturn</span><br><span class="line">gst_my_filter_chain (GstPad    *pad,</span><br><span class="line">                     GstObject *parent,</span><br><span class="line">             GstBuffer *buf)</span><br><span class="line">&#123;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (parent);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!filter-&gt;silent)</span><br><span class="line">    g_print (<span class="string">"Have data of size %"</span> G_GSIZE_FORMAT<span class="string">" bytes!\n"</span>,</span><br><span class="line">        gst_buffer_get_size (buf));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> gst_pad_push (filter-&gt;srcpad, buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="The-event-function"><a href="#The-event-function" class="headerlink" title="The event function"></a>The event function</h1><p>在一些高级的element中，需要设置event处理函数。它通知一些发生在数据流中的特定事件，比如（caps, end-of-stream, newsegment, tags, etc.），事件可以传播到上游和下游，所以你可以在sink pads和source pads接收到。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_init (GstMyFilter * filter)</span><br><span class="line">&#123;</span><br><span class="line">[..]</span><br><span class="line">  gst_pad_set_event_function (filter-&gt;sinkpad,</span><br><span class="line">      gst_my_filter_sink_event);</span><br><span class="line">[..]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> gboolean</span><br><span class="line">gst_my_filter_sink_event (GstPad    *pad,</span><br><span class="line">                  GstObject *parent,</span><br><span class="line">                  GstEvent  *event)</span><br><span class="line">&#123;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (parent);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (GST_EVENT_TYPE (event)) &#123;</span><br><span class="line">    <span class="keyword">case</span> GST_EVENT_CAPS:</span><br><span class="line">      <span class="comment">/* we should handle the format here */</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> GST_EVENT_EOS:</span><br><span class="line">      <span class="comment">/* end-of-stream, we should close down all stream leftovers here */</span></span><br><span class="line">      gst_my_filter_stop_processing (filter);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> gst_pad_event_default (pad, parent, event);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> GstFlowReturn</span><br><span class="line">gst_my_filter_chain (GstPad    *pad,</span><br><span class="line">             GstObject *parent,</span><br><span class="line">             GstBuffer *buf)</span><br><span class="line">&#123;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (parent);</span><br><span class="line">  GstBuffer *outbuf;</span><br><span class="line"></span><br><span class="line">  outbuf = gst_my_filter_process_data (filter, buf);</span><br><span class="line">  gst_buffer_unref (buf);</span><br><span class="line">  <span class="keyword">if</span> (!outbuf) &#123;</span><br><span class="line">    <span class="comment">/* something went wrong - signal an error */</span></span><br><span class="line">    GST_ELEMENT_ERROR (GST_ELEMENT (filter), STREAM, FAILED, (<span class="literal">NULL</span>), (<span class="literal">NULL</span>));</span><br><span class="line">    <span class="keyword">return</span> GST_FLOW_ERROR;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> gst_pad_push (filter-&gt;srcpad, outbuf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="The-query-function"><a href="#The-query-function" class="headerlink" title="The query function"></a>The query function</h1><p>通过query函数，element可以接收查询事件并作出回复，比如（position, duration，supported formats，scheduling modes）。查询同样可以传播到上下游，你可以在sink pads和source pads接收到。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> gboolean <span class="title">gst_my_filter_src_query</span> <span class="params">(GstPad    *pad,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         GstObject *parent,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         GstQuery  *query)</span></span>;</span><br><span class="line"></span><br><span class="line">[..]</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_init (GstMyFilter * filter)</span><br><span class="line">&#123;</span><br><span class="line">[..]</span><br><span class="line">  <span class="comment">/* configure event function on the pad before adding</span></span><br><span class="line"><span class="comment">   * the pad to the element */</span></span><br><span class="line">  gst_pad_set_query_function (filter-&gt;srcpad,</span><br><span class="line">      gst_my_filter_src_query);</span><br><span class="line">[..]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> gboolean</span><br><span class="line">gst_my_filter_src_query (GstPad    *pad,</span><br><span class="line">                 GstObject *parent,</span><br><span class="line">                 GstQuery  *query)</span><br><span class="line">&#123;</span><br><span class="line">  gboolean ret;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (parent);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (GST_QUERY_TYPE (query)) &#123;</span><br><span class="line">    <span class="keyword">case</span> GST_QUERY_POSITION:</span><br><span class="line">      <span class="comment">/* we should report the current position */</span></span><br><span class="line">      [...]</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> GST_QUERY_DURATION:</span><br><span class="line">      <span class="comment">/* we should report the duration here */</span></span><br><span class="line">      [...]</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> GST_QUERY_CAPS:</span><br><span class="line">      <span class="comment">/* we should report the supported caps here */</span></span><br><span class="line">      [...]</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="comment">/* just call the default handler */</span></span><br><span class="line">      ret = gst_pad_query_default (pad, parent, query);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="element状态"><a href="#element状态" class="headerlink" title="element状态"></a>element状态</h1><p>状态可以用来描述element是否初始化，是否准备传送数据，是否正在处理数据。</p><ul><li>GST_STATE_NULL element默认状态，不分配任何资源，不加载任何库。</li><li>GST_STATE_READY 分配默认资源(runtime-libraries, runtime-memory)，不分配或者定义stream-specific相关的资源，当状态从NULL到READY时，分配任何non-stream-specific资源，加载运行时库。当状态从READY转到NULL时，卸载相关资源，比如硬件设备。注意文件也是流，所以在READY状态下不会分配。</li><li>GST_STATE_PAUSED element准备接收和处理数据，对于大部分elements来说PAUSED和PLAYING是一样的，唯一的区别是sink elements，它只接收一次数据然后阻塞住，这时候pipeline处于’prerolled’状态，准备渲染数据。</li><li>GST_STATE_PLAYING 在播放状态下sink elements渲染接收的数据，其他elements和PAUSED状态一样。</li></ul><h3 id="管理filter状态"><a href="#管理filter状态" class="headerlink" title="管理filter状态"></a>管理filter状态</h3><p>一般来说，elements继承一些基类，比如sources, sinks and filter/transformation elements。如果是继承这些基类，你就不需要亲自处理状态的改变。你只需继承基类的虚函数<em>start()</em>和<em>stop()</em>。如果不是继承基类，而是继承GstElement，你就必须自己处理状态的改变，比如像demuxer和muxer这种插件。通过虚函数，element可以被通知状态的改变然后初始化必要数据，也可以选择状态改变失败。</p><p><strong>注意，向上（NULL =&gt; READY，READY =&gt; PAUSED，PAUSED =&gt; PLAYING）和向下（PLAYING =&gt; PAUSED，PAUSED =&gt; READY，READY =&gt; NULL）状态更改在两个单独的块中处理，向下状态发生变化只有在我们链接到父类的状态更改函数之后才会处理。这是为了安全地处理多个线程的并发访问所必需的</strong>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> GstStateChangeReturn</span><br><span class="line">gst_my_filter_change_state (GstElement *element, GstStateChange transition);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_class_init (GstMyFilterClass *klass)</span><br><span class="line">&#123;</span><br><span class="line">  GstElementClass *element_class = GST_ELEMENT_CLASS (klass);</span><br><span class="line"></span><br><span class="line">  element_class-&gt;change_state = gst_my_filter_change_state;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> GstStateChangeReturn</span><br><span class="line">gst_my_filter_change_state (GstElement *element, GstStateChange transition)</span><br><span class="line">&#123;</span><br><span class="line">  GstStateChangeReturn ret = GST_STATE_CHANGE_SUCCESS;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (element);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (transition) &#123;</span><br><span class="line"><span class="keyword">case</span> GST_STATE_CHANGE_NULL_TO_READY:</span><br><span class="line">  <span class="keyword">if</span> (!gst_my_filter_allocate_memory (filter))</span><br><span class="line"><span class="keyword">return</span> GST_STATE_CHANGE_FAILURE;</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ret = GST_ELEMENT_CLASS (parent_class)-&gt;change_state (element, transition);</span><br><span class="line">  <span class="keyword">if</span> (ret == GST_STATE_CHANGE_FAILURE)</span><br><span class="line"><span class="keyword">return</span> ret;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (transition) &#123;</span><br><span class="line"><span class="keyword">case</span> GST_STATE_CHANGE_READY_TO_NULL:</span><br><span class="line">  gst_my_filter_free_memory (filter);</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="增加属性"><a href="#增加属性" class="headerlink" title="增加属性"></a>增加属性</h1><p>通过属性可以控制element的行为。属性在<em>_class_init ()</em>函数中定义，在<em>_get_property ()</em>和<em>a _set_property ()</em>函数中设置或者获取。可以在<em>_init ()</em>构造函数中初始化属性值。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* properties */</span></span><br><span class="line"><span class="keyword">enum</span> &#123;</span><br><span class="line">  PROP_0,</span><br><span class="line">  PROP_SILENT</span><br><span class="line">  <span class="comment">/* FILL ME */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">gst_my_filter_set_property</span>  <span class="params">(GObject      *object,</span></span></span><br><span class="line"><span class="function"><span class="params">                         guint         prop_id,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">const</span> GValue *value,</span></span></span><br><span class="line"><span class="function"><span class="params">                         GParamSpec   *pspec)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">gst_my_filter_get_property</span>  <span class="params">(GObject      *object,</span></span></span><br><span class="line"><span class="function"><span class="params">                         guint         prop_id,</span></span></span><br><span class="line"><span class="function"><span class="params">                         GValue       *value,</span></span></span><br><span class="line"><span class="function"><span class="params">                         GParamSpec   *pspec)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_class_init (GstMyFilterClass *klass)</span><br><span class="line">&#123;</span><br><span class="line">  GObjectClass *object_class = G_OBJECT_CLASS (klass);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* define virtual function pointers */</span></span><br><span class="line">  object_class-&gt;set_property = gst_my_filter_set_property;</span><br><span class="line">  object_class-&gt;get_property = gst_my_filter_get_property;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* define properties */</span></span><br><span class="line">  g_object_class_install_property (object_class, PROP_SILENT,</span><br><span class="line">    g_param_spec_boolean (<span class="string">"silent"</span>, <span class="string">"Silent"</span>,</span><br><span class="line">              <span class="string">"Whether to be very verbose or not"</span>,</span><br><span class="line">              FALSE, G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_set_property (GObject      *object,</span><br><span class="line">                guint         prop_id,</span><br><span class="line">                <span class="keyword">const</span> GValue *value,</span><br><span class="line">                GParamSpec   *pspec)</span><br><span class="line">&#123;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (object);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (prop_id) &#123;</span><br><span class="line">    <span class="keyword">case</span> PROP_SILENT:</span><br><span class="line">      filter-&gt;silent = g_value_get_boolean (value);</span><br><span class="line">      g_print (<span class="string">"Silent argument was changed to %s\n"</span>,</span><br><span class="line">           filter-&gt;silent ? <span class="string">"true"</span> : <span class="string">"false"</span>);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">gst_my_filter_get_property (GObject    *object,</span><br><span class="line">                guint       prop_id,</span><br><span class="line">                GValue     *value,</span><br><span class="line">                GParamSpec *pspec)</span><br><span class="line">&#123;</span><br><span class="line">  GstMyFilter *filter = GST_MY_FILTER (object);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (prop_id) &#123;</span><br><span class="line">    <span class="keyword">case</span> PROP_SILENT:</span><br><span class="line">      g_value_set_boolean (value, filter-&gt;silent);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      G_OBJECT_WARN_INVALID_PROPERTY_ID (object, prop_id, pspec);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="两种调度模式"><a href="#两种调度模式" class="headerlink" title="两种调度模式"></a>两种调度模式</h1><p>Gstreamer 有两种调度模式</p><ul><li>push mode</li><li>pull mode</li></ul><p>我们之前讨论的<em>_chain ()</em>函数属于push mode，通过调用<em>gst_pad_push ()</em>，使得下游的element的<em>_chain ()</em>被调用。</p><p>后续补充</p>]]></content>
      
      
      <categories>
          
          <category> GStreamer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GStreamer </tag>
            
            <tag> 插件 </tag>
            
            <tag> 视频流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GStreamer插件之Transform elements</title>
      <link href="/2019/03/29/GStreamer%E6%8F%92%E4%BB%B6%E4%B9%8BTransform-elements/"/>
      <url>/2019/03/29/GStreamer%E6%8F%92%E4%BB%B6%E4%B9%8BTransform-elements/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>写了个gstreamer插件继承于基类Transform element. 其中有些概念需要理解一下，特此做下笔记。参考<a href="https://gstreamer.freedesktop.org/documentation/design/element-transform.html" target="_blank" rel="noopener">官网链接</a></p><p>Transform elements基于sink和src pad的caps将输入的buffer转换为输出buffer。而输出的caps完全由输入的caps所定义，这表明像解码器这种组件不能够由Transform elements来实现，因为其输出的视频帧的宽高在输入时是被压缩在流当中的，所以输入是没有宽高这种属性的。如下所示的avdec_h264解码组件所示：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Pad Templates:</span><br><span class="line">  SRC template: 'src'</span><br><span class="line">    Availability: Always</span><br><span class="line">    Capabilities:</span><br><span class="line">      video/x-raw</span><br><span class="line">                 format: &#123; (<span class="built_in">string</span>)I420, (<span class="built_in">string</span>)YUY2, (<span class="built_in">string</span>)RGB, (<span class="built_in">string</span>)BGR,</span><br><span class="line"> (<span class="built_in">string</span>)Y42B, (<span class="built_in">string</span>)Y444, (<span class="built_in">string</span>)YUV9, (<span class="built_in">string</span>)Y41B, (<span class="built_in">string</span>)GRAY8,</span><br><span class="line"> (<span class="built_in">string</span>)RGB8P, (<span class="built_in">string</span>)I420, (<span class="built_in">string</span>)Y42B, (<span class="built_in">string</span>)Y444, (<span class="built_in">string</span>)UYVY,</span><br><span class="line"> (<span class="built_in">string</span>)NV12, (<span class="built_in">string</span>)NV21, (<span class="built_in">string</span>)ARGB, (<span class="built_in">string</span>)RGBA, (<span class="built_in">string</span>)ABGR, </span><br><span class="line"> (<span class="built_in">string</span>)BGRA, (<span class="built_in">string</span>)GRAY16_BE, (<span class="built_in">string</span>)GRAY16_LE, (<span class="built_in">string</span>)A420, </span><br><span class="line"> (<span class="built_in">string</span>)RGB16, (<span class="built_in">string</span>)RGB15, (<span class="built_in">string</span>)I420_10BE, (<span class="built_in">string</span>)I420_10LE, </span><br><span class="line"> (<span class="built_in">string</span>)I422_10BE, (<span class="built_in">string</span>)I422_10LE, (<span class="built_in">string</span>)Y444_10BE, (<span class="built_in">string</span>)Y444_10LE, </span><br><span class="line"> (<span class="built_in">string</span>)GBR, (<span class="built_in">string</span>)GBR_10BE, (<span class="built_in">string</span>)GBR_10LE, (<span class="built_in">string</span>)A420_10BE,</span><br><span class="line"> (<span class="built_in">string</span>)A420_10LE, (<span class="built_in">string</span>)A422_10BE, (<span class="built_in">string</span>)A422_10LE, (<span class="built_in">string</span>)A444_10BE,</span><br><span class="line"> (<span class="built_in">string</span>)A444_10LE, (<span class="built_in">string</span>)GBRA, (<span class="built_in">string</span>)xRGB, (<span class="built_in">string</span>)RGBx, (<span class="built_in">string</span>)xBGR, </span><br><span class="line"> (<span class="built_in">string</span>)BGRx, (<span class="built_in">string</span>)I420_12BE, (<span class="built_in">string</span>)I420_12LE, (<span class="built_in">string</span>)I422_12BE, </span><br><span class="line"> (<span class="built_in">string</span>)I422_12LE, (<span class="built_in">string</span>)Y444_12BE, (<span class="built_in">string</span>)Y444_12LE, (<span class="built_in">string</span>)GBR_12BE,</span><br><span class="line"> (<span class="built_in">string</span>)GBR_12LE, (<span class="built_in">string</span>)GBRA_12BE, (<span class="built_in">string</span>)GBRA_12LE &#125;</span><br><span class="line"></span><br><span class="line">  SINK template: 'sink'</span><br><span class="line">    Availability: Always</span><br><span class="line">    Capabilities:</span><br><span class="line">      video/x-h264</span><br><span class="line">              alignment: au</span><br><span class="line">          stream-format: &#123; (<span class="built_in">string</span>)avc, (<span class="built_in">string</span>)byte-stream &#125;</span><br></pre></td></tr></table></figure></p><p>典型transform elements包含：</p><ul><li>audio convertors (audioconvert, audioresample,…)</li><li>video convertors (colorspace, videoscale, …)</li><li>filters (capsfilter, volume, colorbalance, …)</li></ul><p>要实现transform elements必须关心的是：</p><ul><li>efficient negotiation both up and downstream</li><li>efficient buffer alloc and other buffer management</li></ul><p>transform elements可以使用不同模式：</p><ul><li>passthrough (no changes are done on the input buffers)</li><li>in-place (changes made directly to the incoming buffers without requiring a copy or new buffer allocation)</li><li>metadata changes only</li></ul><p>transform元素通常也会处理以下事项：</p><ul><li>flushing, seeking</li><li>state changes</li><li>timestamping, this is typically done by copying the input timestamps to the output buffers but subclasses should be able to override this.</li><li>QoS, avoiding calls to the subclass transform function</li><li>handle scheduling issues such as push and pull based operation.</li></ul><p>transform element应在任何时候可以重新协商sink和src caps，并改变操作模式。根据不同的模式，buffer的分配可能采用不同策略。</p><h1 id="transform-element-behaviour"><a href="#transform-element-behaviour" class="headerlink" title="transform element behaviour"></a>transform element behaviour</h1><h2 id="Processing"><a href="#Processing" class="headerlink" title="Processing"></a>Processing</h2><p>transform主要由两种处理函数：</p><ul><li>transform(): Transform the input buffer to the output buffer. The output buffer is guaranteed to be writable and different from the input buffer.</li><li>transform_ip(): Transform the input buffer in-place. The input buffer is writable and of bigger or equal size than the output buffer.</li></ul><p>转换操作有以下模式：</p><ul><li>passthrough: The element will not make changes to the buffers, buffers are pushed straight through, caps on both sides need to be the same. The element can optionally implement a transform_ip() function to take a look at the data, the buffer does not have to be writable.</li><li>in-place: Changes can be made to the input buffer directly to obtain the output buffer. The transform must implement a transform_ip() function.</li><li>copy-transform: The transform is performed by copying and transforming the input buffer to a new output buffer. The transform must implement a transform() function.</li></ul><p>当没有使用<em>transform()</em>函数的时候，只有in-place 和 passthrough模式可以使用，这意味着sinkpad和srcpad要一样或者src buffer大于等于sink buffer。</p><p>当没有使用<em>transform_ip()</em>函数的时候，只允许passthrough和copy-transforms两种模式，提供这个函数可以避免内存的拷贝。</p><p>当没有使用以上两种函数时，只使用passthrough模式。</p><h2 id="Negotiation"><a href="#Negotiation" class="headerlink" title="Negotiation"></a>Negotiation</h2><p>在push mode下transform element的协商总是从sink到src：</p><ul><li>sinkpad接收到新的caps事件</li><li>transform函数算出它可以将此caps转化成什么</li><li>尝试不做任何修改，因为我们倾向于不做任何事情</li><li>transform配置自身使得可以将sink caps转换到模板src caps</li><li>transform在srcpad上设置处理输出caps<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">          sinkpad              transform               srcpad</span><br><span class="line">CAPS event   |                    |                      |</span><br><span class="line">------------&gt;|  find_transform()  |                      |</span><br><span class="line">             |-------------------&gt;|                      |</span><br><span class="line">             |                    |       CAPS event     |</span><br><span class="line">             |                    |---------------------&gt;|</span><br><span class="line">             | &lt;configure caps&gt; &lt;-|                      |</span><br></pre></td></tr></table></figure></li></ul><p>transform 有三个函数执行协商：</p><ul><li>transform_caps(): Transform the caps on a certain pad to all the possible supported caps on the other pad. The input caps are guaranteed to be a simple caps with just one structure. The caps do not have to be fixed.</li><li>fixate_caps(): Given a caps on one pad, fixate the caps on the other pad. The target caps are writable.</li><li>set_caps(): Configure the transform for a transformation between src caps and dest caps. Both caps are guaranteed to be fixed caps.</li></ul><p>如果<em>transform_caps()</em>未定义，默认只执行同样的转换。<br>如果<em>set_caps()</em>未定义，我们不关心caps，在这种情况下我们假设没有任何内容写到缓冲区，我们不会为该<em>transform_ip()</em>函数强制执行可写缓冲区（如果存在）。</p><p>我们对transform元素需要的一个常见函数是找到从一种格式（src）到另一种格式（dest）的最佳转换。该函数的一些要求是：</p><ul><li>有一个固定的src caps</li><li>找到一个固定的transform element可以转换成的dest caps </li><li>dest caps是兼容的并且可被peer elements接受</li><li>transform函数倾向于使src caps == dest caps</li><li>transform函数可以选择性固定dest caps</li></ul><p><em>find_transform()</em>函数执行如下:</p><ul><li>从一个固定的src caps开始；</li><li>检测这些caps是否可以被用作src caps，这通常由元素的padtemplate强制执行；</li><li>使用<em>transform_caps()</em>计算所有的可以转换生成的caps</li><li>如果原始的caps是transforms的一个子集，尝试caps是否能被peer接受。如果可行，我们可以执行passthrough然后设置src == dest。这只要简单调用<em>gst_pad_peer_query_accept_caps()</em>即可。</li><li>如果caps不是固定的，我们需要固定它们。</li><li><em>transform_caps()</em>检索每个转换的caps</li><li>使用<em>fixate_caps()</em>固定caps</li><li>如果caps是固定的，使用<em>_peer_query_accept_caps()</em>检测peer是否接受他们，如果接受，我们就找到了dest caps。</li><li>如果找遍caps还没发现可转换的caps就表明失败了。</li><li>如果找到dest caps，使用<em>set_caps()</em>进行配置。</li></ul><p>在协商过程之后，transform元素通常是一个稳定的状态。我们可以确定这个状态：</p><h3 id="src和sink-pads有同样的caps"><a href="#src和sink-pads有同样的caps" class="headerlink" title="src和sink pads有同样的caps"></a>src和sink pads有同样的caps</h3><ul><li><p>passthrough: buffers are inspected but no metadata or buffer data is changed. The input buffers don’t need to be writable. The input buffer is simply pushed out again without modifications. (SCP)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">          sinkpad              transform               srcpad</span><br><span class="line">  chain()    |                    |                      |</span><br><span class="line">------------&gt;|   handle_buffer()  |                      |</span><br><span class="line">             |-------------------&gt;|      pad_push()      |</span><br><span class="line">             |                    |---------------------&gt;|</span><br><span class="line">             |                    |                      |</span><br></pre></td></tr></table></figure></li><li><p>in-place: buffers are modified in-place, this means that the input buffer is modified to produce a new output buffer. This requires the input buffer to be writable. If the input buffer is not writable, a new buffer has to be allocated from the bufferpool. (SCI)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">          sinkpad              transform               srcpad</span><br><span class="line">  chain()    |                    |                      |</span><br><span class="line">------------&gt;|   handle_buffer()  |                      |</span><br><span class="line">             |-------------------&gt;|                      |</span><br><span class="line">             |                    |   [!writable]        |</span><br><span class="line">             |                    |   alloc buffer       |</span><br><span class="line">             |                  .-|                      |</span><br><span class="line">             |  &lt;transform_ip&gt;  | |                      |</span><br><span class="line">             |                  '&gt;|                      |</span><br><span class="line">             |                    |      pad_push()      |</span><br><span class="line">             |                    |---------------------&gt;|</span><br><span class="line">             |                    |                      |</span><br></pre></td></tr></table></figure></li><li><p>copy transform: a new output buffer is allocate from the bufferpool and data from the input buffer is transformed into the output buffer. (SCC)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">         sinkpad              transform               srcpad</span><br><span class="line">  chain()    |                    |                      |</span><br><span class="line">------------&gt;|   handle_buffer()  |                      |</span><br><span class="line">             |-------------------&gt;|                      |</span><br><span class="line">             |                    |     alloc buffer     |</span><br><span class="line">             |                  .-|                      |</span><br><span class="line">             |     &lt;transform&gt;  | |                      |</span><br><span class="line">             |                  '&gt;|                      |</span><br><span class="line">             |                    |      pad_push()      |</span><br><span class="line">             |                    |---------------------&gt;|</span><br><span class="line">             |                    |                      |</span><br></pre></td></tr></table></figure></li></ul><h3 id="src和sink-pads有不一样的样的caps"><a href="#src和sink-pads有不一样的样的caps" class="headerlink" title="src和sink pads有不一样的样的caps"></a>src和sink pads有不一样的样的caps</h3><ul><li><p>in-place: input buffers are modified in-place. This means that the input buffer has a size that is larger or equal to the output size. The input buffer will be resized to the size of the output buffer. If the input buffer is not writable or the output size is bigger than the input size, we need to pad-alloc a new buffer. (DCI)</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">          sinkpad              transform               srcpad</span><br><span class="line">  chain()    |                    |                      |</span><br><span class="line">------------&gt;|   handle_buffer()  |                      |</span><br><span class="line">             |-------------------&gt;|                      |</span><br><span class="line">             |                    | [!writable || !size] |</span><br><span class="line">             |                    |     alloc buffer     |</span><br><span class="line">             |                  .-|                      |</span><br><span class="line">             |  &lt;transform_ip&gt;  | |                      |</span><br><span class="line">             |                  '&gt;|                      |</span><br><span class="line">             |                    |      pad_push()      |</span><br><span class="line">             |                    |---------------------&gt;|</span><br><span class="line">             |                    |                      |</span><br></pre></td></tr></table></figure></li><li><p>copy transform: a new output buffer is allocated and the data from the input buffer is transformed into the output buffer. The flow is exactly the same as the case with the same-caps negotiation. (DCC)</p></li></ul><h2 id="Allocation"><a href="#Allocation" class="headerlink" title="Allocation"></a>Allocation</h2><p>当transform element配置完成之后，缓冲池需要根据caps开辟内存，主要有两种情况：</p><ul><li>当使用passthrough模式的时候不需要在transform element中开辟内存。</li><li>当不使用passthrough，并且需要开辟输出buffer。</li></ul><p>对于第一种情况，我们不需要查询和配置pool。我们让upstream自动决定是否需要bufferpool，然后我们将从下游到上游进行代理。</p><p>对于第二种情况，我们在srcpad设置分配内存池。</p><p>为了分配内存，我们还需要知道输出空间的大小，这里有两个函数获取大小：</p><ul><li><p>transform_size(): Given a caps and a size on one pad, and a caps on the other pad, calculate the size of the other buffer. This function is able to perform all size transforms and is the preferred method of transforming a size.</p></li><li><p>get_unit_size(): When the input size and output size are always a multiple of each other (audio conversion, ..) we can define a more simple get_unit_size() function. The transform will use this function to get the same amount of units in the source and destination buffers. For performance reasons, the mapping between caps and size is kept in a cache.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> GStreamer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GStreamer </tag>
            
            <tag> 插件 </tag>
            
            <tag> 视频流 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
